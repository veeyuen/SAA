{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224c908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd485df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import usual modules\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import datetime\n",
    "from scipy.stats import lognorm\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import unicodedata # for removing accented characters\n",
    "\n",
    "import pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee7db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/veesheenyuen/code/veeyuen/SAA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir(\"/Users/veesheen/Desktop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711e01e",
   "metadata": {},
   "source": [
    "# Development Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "847d2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Disqualified' in fragment:\n",
    "    fragment.insert(7, ' ')\n",
    "    \n",
    "else:\n",
    "    fragment.insert(len(fragment), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "3a3a3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <re.Match object; span=(0, 4), match='CHIJ'>\n",
      "1\n",
      "6 <re.Match object; span=(0, 3), match='SNG'>\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern='[A-Z]{2,5}'\n",
    "\n",
    "for i in range(len(fragment)):\n",
    "\n",
    "    if re.search(pattern, fragment[i]):\n",
    "        print(i, re.search(pattern, fragment[i]))\n",
    "        index=i  # set index to second value if there are two uppercase values encountered\n",
    "        print(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4e651b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Regex pattern testing\n",
    "\n",
    "#pattern='([A-Z][a-z]+\\s){2,4}'\n",
    "\n",
    "#pattern='\\d{1,3}{(?<=\\s)[A-Z]{3,5}'\n",
    "\n",
    "#pattern='[A-Z]{2,4}'\n",
    "#pattern='\\d\\s.{5,40}?\\s(Q\\s|q\\s|\\d)'\n",
    "\n",
    "\n",
    "pattern='\\d\\s\\[A-Z]{3,}(?=Q|q|[0-9]{2,3})'\n",
    "\n",
    "\n",
    "#string='8 CHIJ Sec (Toa Payoh) HIJ 2 7 00:54.31'\n",
    "#string='999 Chestnut Drive Sec CDS 2 3 Withdrawal'\n",
    "#string='7 CHIJ Katong Convent KC 5 7 00:54.10'\n",
    "#string = '1 XIN BOWEN 587 HCI Finals 6 40.15 9'\n",
    "\n",
    "\n",
    "\n",
    "#string='2 GUOK XUE QIAN 143 SNG Finals 6 8.91 7'\n",
    "\n",
    "\n",
    "#matches=re.finditer(pattern, string)\n",
    "\n",
    "matches=re.findall(pattern, string)\n",
    "\n",
    "print(matches)\n",
    "\n",
    "#print(type(matches))\n",
    "\n",
    "#for match in matches:\n",
    "#    print(match)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2440127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMASEK SECONDARY SCHOOL \n"
     ]
    }
   ],
   "source": [
    "# Test splicing and extracting name\n",
    "\n",
    "#s = \"4 PHOEBE ANG KE WEI Q 800 CGS h4 2 01:05.62\"\n",
    "#s=\"2 Sarah Chong Xin RI 1 12 4.78 7\"\n",
    "#s='7 CHIJ Katong Convent KC 5 7 00:54.10'\n",
    "#s='4 WANG HANCHEN 584 HCI Finals 1 36.79 5'\n",
    "#s='1 XIN BOWEN 587 HCI Finals 6 40.15 9'\n",
    "#s='3 SINGAPORE SPORTS SCHOOL Q 598 SSP h1 3 04:32.84'\n",
    "s='16 TEMASEK SECONDARY SCHOOL 873 TMS h4 3 05:08.64'\n",
    "\n",
    "lpos = re.search('\\s', s)\n",
    "#rpos = re.search('\\b[A-Z]{2-4}\\b\\d', s)\n",
    "\n",
    "#rpos = re.search('\\sQ\\s', s)\n",
    "#rpos = re.search('\\s[A-Z]{2,4}?', s)\n",
    "#rpos = re.search('\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?|\\s[A-Z]{2,4}\\s\\d?', s)\n",
    "rpos = re.search('\\d\\s.{5,40}?\\s(Q|q|\\d)', s)\n",
    "\n",
    "\n",
    "\n",
    "split_pos_end=rpos.end()-1\n",
    "split_pos_start=lpos.start()+1\n",
    "\n",
    "\n",
    "\n",
    "l = s[:lpos.start()]\n",
    "r = s[rpos.start():]\n",
    "\n",
    "#name=s[lpos.start():rpos.start()]\n",
    "\n",
    "name=s[split_pos_start:split_pos_end]\n",
    "\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d736dba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 22), match=': S13-09 Discus -'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test regex for event name extraction\n",
    "\n",
    "s='Event: S13-09 Discus - B DIVISION BOYS Finals'\n",
    "event_pattern=':\\s.{5,20}\\s\\-'\n",
    "\n",
    "\n",
    "re.search(event_pattern, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63116962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ba09444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Singapore Athletics Assoc.-Open Champ - Organization License Hy-Tek's MEET MANAGER 9:03 PM 19 Apr 2024 Page 1\",\n",
       " '84th Singapore Open Track & Field - 18 Apr 2024 to 19 Apr 2024',\n",
       " 'Championships 2024',\n",
       " 'Singapore Sportshub',\n",
       " 'Results',\n",
       " 'Event 101 Women Shot Put Open',\n",
       " '=========================================================================',\n",
       " 'Name Age Team Seed Finals',\n",
       " '=========================================================================',\n",
       " 'Flight 1',\n",
       " '1 # 154 Intadis, Areerat 28 Thailand 16.71m 14.66m',\n",
       " '13.78m 14.41m X 14.29m 14.34m 14.66m',\n",
       " '2 # 84 Yee Wai Teng, Mel 26 Singapore 12.01m 10.60m',\n",
       " 'X 10.33m X 10.16m 10.60m 10.44m',\n",
       " '3 # 172 Neo, Ee Nin 18 Wings Athlet 9.21m 9.32m',\n",
       " '8.31m 9.30m 9.17m 8.56m 9.32m 8.59m',\n",
       " 'Event 102 Women 1500 Meter Run Open',\n",
       " '=========================================================================',\n",
       " 'Name Age Team Seed Finals',\n",
       " '=========================================================================',\n",
       " 'Section 1',\n",
       " '1 # 41 Nur Nirwani, Novi 25 Indonesia 4:35.82 4:28.03',\n",
       " '2 # 176 Soh, Romaine 30 Wings Athlet 5:00.17 4:44.13',\n",
       " '3 # 77 Lee, Vanessa 26 Singapore 5:18.63 4:51.73',\n",
       " '4 # 76 Ford, Faith 19 Singapore 5:00.45 4:53.11',\n",
       " '5 # 48 Kuchenbuch, Natal 17 JS Athletics 5:03.97 4:57.92',\n",
       " '6 # 137 Lum Wai Yan, Jane 19 T360 5:21.00 5:13.81',\n",
       " '7 # 49 Gan, Steffi 25 Lacticbuds 5:13.67 5:15.14',\n",
       " 'Event 103 Men 1500 Meter Run Open',\n",
       " '=========================================================================',\n",
       " 'Name Age Team Seed Finals',\n",
       " '=========================================================================',\n",
       " '1 # 138 Kumar Bohara, Pra 23 T360 4:14.50 4:17.61',\n",
       " '2 # 51 Ong, Jacky 27 Lacticbuds 4:16.30 4:18.98',\n",
       " '3 # 89 Fayiz, Mohamed Ha 35 Singapore 4:10.49 4:22.73',\n",
       " '-- # 116 Goh, Aldrich 23 Singapore In 4:18.00 DNS TR4.4.1',\n",
       " 'Event 104 Women Javelin Throw Open',\n",
       " '=========================================================================',\n",
       " 'Name Age Team Seed Finals',\n",
       " '=========================================================================',\n",
       " 'Flight 1',\n",
       " '1 # 156 Wichaidit, Jiraya 28 Thailand 52.60m 53.65m',\n",
       " '53.65m 48.44m X 51.48m 52.34m X',\n",
       " '2 # 132 Lee, Gahui 26 South Korea 54.68m 51.11m',\n",
       " '45.61m 41.12m 45.58m 51.11m 48.85m X',\n",
       " '3 # 75 Feng, Han QI 18 Singapore 34.55m 34.16m',\n",
       " '32.53m 30.16m 31.97m 31.72m 34.16m 28.60m',\n",
       " '4 # 27 Seah, Michelle 25 Flash Athletic Club 30.35m 29.62m',\n",
       " '29.62m 25.75m 27.99m 26.49m 29.47m 29.35m',\n",
       " 'Event 105 Men 400 Meter Dash Open',\n",
       " '=========================================================================',\n",
       " 'Name Age Team Seed Prelims',\n",
       " '=========================================================================',\n",
       " 'Heat 1 Preliminaries',\n",
       " '1 # 157 Yuyamadu, Lakki 20 Thailand 47.97 49.10Q',\n",
       " '2 # 126 Muthukumaran, Raa 20 Singapore Sp 50.24 49.59Q',\n",
       " '3 # 149 Ibrahim Molokwu, 18 TeamFabian 50.99 50.04Q']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pdfplumber\n",
    "\n",
    "#os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/sectrack_audit_2010_1-1')\n",
    "#os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/')\n",
    "#os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6_1-1/') \n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/MM/') \n",
    "\n",
    "\n",
    "import pdfplumber\n",
    "\n",
    "#file=\"sectrack_audit_2010_211-211.pdf\"\n",
    "#file=\"Session 13_13-end.pdf\"\n",
    "#file=\"Session 13_1-4.pdf\"\n",
    "#file=\"sectrack_audit_2010_28-28.pdf\"\n",
    "#file=\"Session 13_5-6.pdf\"\n",
    "#file='Session 13_5-6_2-end.pdf'   # stranded pdf\n",
    "file='SGO24.pdf'\n",
    "\n",
    "\n",
    "#table_settings = {\n",
    "#    \"vertical_strategy\": \"text\",\n",
    "#    \"horizontal_strategy\": \"text\",\n",
    "#    }\n",
    "\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "    page = pdf.pages[0]\n",
    "    table=page.extract_table()\n",
    "    text=page.extract_text()\n",
    "\n",
    "\n",
    "splitted=text.splitlines()\n",
    "\n",
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3a3b0dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23 BUKIT VIEW SECONDARY 999 BTV h3 4 05:51.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCHOOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "0  23 BUKIT VIEW SECONDARY 999 BTV h3 4 05:51.77\n",
       "1                                         SCHOOL\n",
       "2                                              /"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2806eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_assign(table):\n",
    "\n",
    "    global index\n",
    "    \n",
    "    exclusions=[]\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "    columns=df.iloc[6,0]\n",
    "    names=columns.split(' ')\n",
    "\n",
    "    df2 = pd.DataFrame(columns=names)\n",
    "    \n",
    "    new_df = df2.iloc[:, :-2]    # remove last 2 extraneous columns\n",
    "     \n",
    "    \n",
    "    for i in range(7,(len(df)-1)):\n",
    "            \n",
    "            \n",
    "        if not re.search('^\\d', table[i]): # skip row if disqualified or withdrawn (does not begin with a digit)\n",
    "\n",
    "            \n",
    "            continue\n",
    "\n",
    "            \n",
    "        s=table[i]\n",
    "        \n",
    "        lpos = re.search('\\s', s)\n",
    "        #rpos = re.search('\\sQ\\s', s)\n",
    "        #rpos = re.search('\\s[A-Z]{2,4}', s)\n",
    "        \n",
    "        matches=re.findall('\\s[A-Z]{2,4}', s)  # find how many uppercase shortforms for school\n",
    "        \n",
    "        if len(matches)==2:\n",
    "            rpos=re.search(matches[1], s)\n",
    "        else:\n",
    "            rpos = re.search('\\s[A-Z]{2,4}', s)\n",
    "\n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            \n",
    "        l = s[:lpos.start()] # left string post splicing\n",
    "        r = s[rpos.start():] # right string post slicing\n",
    "         \n",
    "        name=s[lpos.start():rpos.start()] # extract competitor name\n",
    "                \n",
    "        list=r.split(' ')        \n",
    "\n",
    "        combined=l+ ',' + name + ', '.join(list)\n",
    "\n",
    "        row=combined.split(\",\")\n",
    "                        \n",
    "        if len(row)!=6:\n",
    "            \n",
    "            n=len(row)-6\n",
    "            row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns                 \n",
    "                    \n",
    "        new_df.loc[len(new_df)] = row\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d622762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/484862590.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Ln</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Shawn Poh Zhi Kang</td>\n",
       "      <td>SKS</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>00:24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Liaw Jian Hui</td>\n",
       "      <td>AMK</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>00:24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zubin Percy Muncherji</td>\n",
       "      <td>ACS(BR)</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>00:24.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Terence Loh Junheng</td>\n",
       "      <td>ACS(I)</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>00:24.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Md Nur Syahirran</td>\n",
       "      <td>SSP</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>00:24.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ong Sin Yao</td>\n",
       "      <td>CCH</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>00:24.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Wu Chee Keen Daniel</td>\n",
       "      <td>DSS</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>00:25.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Jonathan Lew Lian Xin</td>\n",
       "      <td>RI</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>00:25.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Ang Li Sheng</td>\n",
       "      <td>AND</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>00:25.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Teo Yu Ming</td>\n",
       "      <td>RI</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>00:25.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Clyde Tan Jin Shuen</td>\n",
       "      <td>ACS(I)</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>00:25.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chua Cheng Ying</td>\n",
       "      <td>SJI</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>00:25.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Puah Li An</td>\n",
       "      <td>NTS</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>00:25.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Raymond Scott Lee Chian Hoong</td>\n",
       "      <td>SJI</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>00:25.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Ridwan Bin Yahya</td>\n",
       "      <td>TMS</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>00:25.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Tan Hui Ming Zac</td>\n",
       "      <td>NSS</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>00:25.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Daryl Shane Lee</td>\n",
       "      <td>TMS</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>00:25.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chin Yew Chung Kennard</td>\n",
       "      <td>SJI</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:26.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Amos Tan</td>\n",
       "      <td>SAS</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>00:26.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Ryan Leong Jun Yan</td>\n",
       "      <td>SKS</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>00:26.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Muhammad Firman B Jumat</td>\n",
       "      <td>AMK</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>00:26.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Tiew Zi Hao Andrew</td>\n",
       "      <td>SPS</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>00:26.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Abdul Halim</td>\n",
       "      <td>SKS</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>00:26.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Aryobimo Wibowoputro</td>\n",
       "      <td>AMK</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>00:26.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Ong Kai Ming</td>\n",
       "      <td>CCK</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>00:26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Gabriel Lau Yu Sheng</td>\n",
       "      <td>HY</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>00:26.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Nian Ding Chao</td>\n",
       "      <td>AIS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Zuhairi Bin Anuar</td>\n",
       "      <td>SSP</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>00:26.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Shafeeq</td>\n",
       "      <td>NAS</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>00:26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Ong Shao Ming</td>\n",
       "      <td>BTV</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>00:26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Ng Zin Tiao</td>\n",
       "      <td>Brent</td>\n",
       "      <td>SPS</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Richmond Sugita Tadayoshi</td>\n",
       "      <td>SSP</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>00:26.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Wang Xian Yang</td>\n",
       "      <td>Jerrel</td>\n",
       "      <td>CH</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Aloysius Yeo Rui Sen</td>\n",
       "      <td>TMS</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:26.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Tan Qin Xiang</td>\n",
       "      <td>HCI</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:26.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Tobias Tan Ning</td>\n",
       "      <td>DHS</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>00:26.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>Benjamin Ong</td>\n",
       "      <td>BV</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>00:26.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Phang Yong Kang</td>\n",
       "      <td>CCH</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>00:26.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Jerald Saw</td>\n",
       "      <td>SAS</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>00:27.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Daniel Boey Kai Sheng</td>\n",
       "      <td>RI</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>00:27.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos                      Competitor      Team    Ht  Ln     Result\n",
       "0    1              Shawn Poh Zhi Kang       SKS    13   7   00:24.20\n",
       "1    2                   Liaw Jian Hui       AMK     3   7   00:24.68\n",
       "2    3           Zubin Percy Muncherji   ACS(BR)     8   7   00:24.77\n",
       "3    4             Terence Loh Junheng    ACS(I)     2   4   00:24.84\n",
       "4    5                Md Nur Syahirran       SSP    10   3   00:24.90\n",
       "5    6                     Ong Sin Yao       CCH     2   7   00:24.97\n",
       "6    7             Wu Chee Keen Daniel       DSS     9   1   00:25.05\n",
       "7    8           Jonathan Lew Lian Xin        RI    11   5   00:25.06\n",
       "8    9                    Ang Li Sheng       AND     2   6   00:25.16\n",
       "9   10                     Teo Yu Ming        RI     6   6   00:25.62\n",
       "10  11             Clyde Tan Jin Shuen    ACS(I)     8   6   00:25.68\n",
       "11  12                 Chua Cheng Ying       SJI    13   6   00:25.69\n",
       "12  13                      Puah Li An       NTS     4   5   00:25.70\n",
       "13  14   Raymond Scott Lee Chian Hoong       SJI     2   5   00:25.84\n",
       "14  15                Ridwan Bin Yahya       TMS     1   8   00:25.85\n",
       "15  16                Tan Hui Ming Zac       NSS     5   8   00:25.89\n",
       "16  17                 Daryl Shane Lee       TMS     5   5   00:25.93\n",
       "17  18          Chin Yew Chung Kennard       SJI     4   7   00:26.08\n",
       "18  19                        Amos Tan       SAS     9   2   00:26.09\n",
       "19  20              Ryan Leong Jun Yan       SKS     3   4   00:26.10\n",
       "20  21         Muhammad Firman B Jumat       AMK     7   6   00:26.17\n",
       "21  22              Tiew Zi Hao Andrew       SPS     5   7   00:26.21\n",
       "22  23                     Abdul Halim       SKS     7   7   00:26.23\n",
       "23  24            Aryobimo Wibowoputro       AMK     8   4   00:26.24\n",
       "24  25                    Ong Kai Ming       CCK     1   3   00:26.26\n",
       "25  26            Gabriel Lau Yu Sheng        HY     3   8   00:26.30\n",
       "26  27                  Nian Ding Chao       AIS     2   3   00:26.37\n",
       "27  28               Zuhairi Bin Anuar       SSP     8   1   00:26.46\n",
       "28  29                         Shafeeq       NAS     5   2   00:26.50\n",
       "29  30                   Ong Shao Ming       BTV    12   3   00:26.53\n",
       "30  31                     Ng Zin Tiao     Brent   SPS   4          2\n",
       "31  32       Richmond Sugita Tadayoshi       SSP     9   7   00:26.58\n",
       "32  33                  Wang Xian Yang    Jerrel    CH   9          3\n",
       "33  34            Aloysius Yeo Rui Sen       TMS     4   4   00:26.84\n",
       "34  35                   Tan Qin Xiang       HCI     1   2   00:26.90\n",
       "35  36                 Tobias Tan Ning       DHS    10   4   00:26.92\n",
       "36  37                    Benjamin Ong        BV    11   3   00:26.99\n",
       "37  37                 Phang Yong Kang       CCH     9   4   00:26.99\n",
       "38  39                      Jerald Saw       SAS     3   3   00:27.02\n",
       "39  40           Daniel Boey Kai Sheng        RI     1   4   00:27.04"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_assign(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "753d7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version- does not capture REMARKS and NR columns\n",
    "\n",
    "def new_format_parser(row_index, names, table, master_df):\n",
    "            \n",
    "    # Define regex patterns\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Q|q|\\d)'\n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "    \n",
    "    stranded = \"no\"  # flag for stranded pdf pages\n",
    "\n",
    "        \n",
    "    # Put table that has been processed into a dataframe\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "            \n",
    "    columns=[]\n",
    "    \n",
    "    \n",
    "    # Initialize new df and remove unnecessary columns\n",
    "    \n",
    "    if row_index!=0 and names is not None: #check that its coming from not a stranded pdf with no header\n",
    "            \n",
    "        df2 = pd.DataFrame(columns=names)        \n",
    "    \n",
    "        new_df = df2.iloc[:, :-2]    # remove 'Remarks' and 'NR' columns\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('reached this first point for a stranded pdf')\n",
    "        \n",
    "        stranded=\"yes\"\n",
    "        \n",
    "        new_df = master_df.iloc[:0] # new_df columns to come from the master df\n",
    "        \n",
    "        row_index=-1  # move back row_index for a stranded pdf\n",
    "        \n",
    "    \n",
    "#    for i in range(row_index+1,(len(df)-1)):  # iterate over df - only stranded pdf should start from zero. Previous code - revert to original  \n",
    "\n",
    "\n",
    "#  check for stranded pdfs with stranded names\n",
    "\n",
    "    for i in range(row_index+1,(len(df))):  # iterate over df - only stranded pdf should start from zero        \n",
    "\n",
    "        \n",
    "        if 'DNM' in table[i]:\n",
    "                    \n",
    "            continue # skip row if DNM, DQ, DNF etc.\n",
    "                                    \n",
    "        if not re.search('^\\d', table[i]): # look for stranded parts of names (does not begin with a digit). But need to test for standed names in stranded pdf\n",
    "        \n",
    "        \n",
    "            try:  # remove try block to revert back to previous working state\n",
    "                \n",
    "                row[1]=row[1]+table[i] # retrieve previous row and add back stranded string to name. Stranded pdf will throw and error here\n",
    "                \n",
    "                new_df.drop(new_df.tail(1).index,inplace=True) # drop last row with incomplete name\n",
    "                                        \n",
    "                new_df.loc[len(new_df)] = row  # add back amended row\n",
    "                \n",
    "                print(row)\n",
    "                                    \n",
    "                continue  # then skip to next row\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                print('reached this second point for a stranded pdf')\n",
    "                \n",
    "                pass                 # move on if it is actually a stranded pdf\n",
    "                              \n",
    "                \n",
    "        string=table[i] \n",
    "        \n",
    "        print(string)\n",
    "                                \n",
    "        lpos = re.search('\\s', string)\n",
    "        rpos = re.search(new_pattern, string)\n",
    "                                            \n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "        split_pos_end=rpos.end()-1      # adjust the splicing position to only capture the name\n",
    "        split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "        left_string = string[:lpos.start()] # left string post splicing\n",
    "        right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "        name=string[split_pos_start:split_pos_end]  # extract competitor name\n",
    "                                        \n",
    "        list=right_string.split(' ')        # put everything coming after the name into a list   \n",
    "                \n",
    "                \n",
    "        if len(list)==6:    # check length of list. If less than 7, append blank fields for Pos and W/G \n",
    "                    \n",
    "            list.extend([' ', ' '])\n",
    "                    \n",
    "        elif len(list)==5:\n",
    "                    \n",
    "            list.extend([' ', ' '])\n",
    "                                                            \n",
    "                \n",
    "        combined=left_string+ ';' + name +'; '+ '; '.join(list)  # use ';' in case names have a ','\n",
    "\n",
    "        row=combined.split(';')        \n",
    "                                                                             \n",
    "\n",
    "        # check if Q or q between tag and name. If not, fill in with empty space.\n",
    "        # don't overwrite master df if there is a stranded pdf\n",
    "                \n",
    "        if row[2].strip()=='Q' or row[2].strip()=='q' or row[2] is None :\n",
    "                    \n",
    "            new_df.loc[len(new_df)] = row\n",
    "                        \n",
    "#            master_df=new_df      # previous\n",
    "\n",
    "        else:\n",
    "                    \n",
    "            row.insert(2, ' ')  # insert a blank field if no Q or q    \n",
    "            \n",
    "            print(row)\n",
    "                \n",
    "            new_df.loc[len(new_df)] = row\n",
    "            \n",
    "            \n",
    "# QAed to this point for a stranded pdf. Need to figure out how to attach stranded row to master df\n",
    "            \n",
    "            \n",
    "#            master_df=new_df      # previous   \n",
    "\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad94dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(table, master_df):  # second latest version\n",
    "\n",
    "    global index, row_index\n",
    "        \n",
    "        \n",
    "    # Regex patterns to extract competitor names, event name etc.\n",
    "    \n",
    "    #new_pattern='\\d\\s.{5,20}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='\\d\\s[A-Z\\s\\,]{5,30}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='^[A-Z\\s]*$'\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Q|q|\\d)'\n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "    \n",
    "    session_pattern='\\d\\d-\\d\\d'\n",
    "    \n",
    "    event = None\n",
    "    \n",
    "    names = None\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # Put extracted info from pdf into a df and extract event information\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "    \n",
    "    columns=[]\n",
    "    \n",
    "        \n",
    "    for index, row in df.iterrows(): # find row containing event details and column names\n",
    "                \n",
    "        \n",
    "        if 'Event' in row[0]:\n",
    "                                                \n",
    "            epos = re.search(event_pattern, row[0])\n",
    "                        \n",
    "            split_end=epos.end()-1      # adjust the splicing position to only capture the event name\n",
    "            split_start=epos.start()+1\n",
    "\n",
    "            event=event[split_start:split_end]\n",
    "                                    \n",
    "            \n",
    "            if 'BOYS' in event or 'Boys' in event:\n",
    "                gender='Male'\n",
    "                \n",
    "            if 'GIRLS' in event or 'Girls' in event:\n",
    "                gender='Female'    \n",
    "                \n",
    "            \n",
    "            if 'Finals' in event:\n",
    "                round='Finals'\n",
    "            \n",
    "            region='Local'\n",
    "            \n",
    "            \n",
    "            session=re.findall(session_patttern, row[0])\n",
    "            \n",
    "            print('session', session)\n",
    "                  \n",
    "            \n",
    "        if 'Competitor' in row[0]: # extract column names\n",
    "            \n",
    "            row_index=index\n",
    "            columns=df.iloc[row_index,0]\n",
    "            names=columns.split(' ')\n",
    "            \n",
    "    \n",
    "    if (event and names) is None:  # if it is a stranded page (no header) that is cutoff from the main pdf\n",
    "                                # Change this code to add iteration over pages. Just append splitted 2nd page.\n",
    "                                \n",
    "            temp_df = master_df.iloc[:0]  # initiate empty df and copy column names\n",
    "                                    \n",
    "            row_index=0   # if no header \n",
    "            \n",
    "            names = None  # retrieve master df and append instead\n",
    "            \n",
    "            print('here')\n",
    "            \n",
    "            print(table)\n",
    "                                            \n",
    "            temp_df=new_format_parser(row_index, names, table, master_df) # need to concat master_df and temp df\n",
    "            \n",
    "            print('reached this 3rd point for a stranded pdf')\n",
    "            \n",
    "            master_df= pd.concat([master_df, temp_df])  # this concat is not working as temp_df is empty\n",
    "                    \n",
    "            return master_df # exit function\n",
    "\n",
    "            \n",
    "    \n",
    "    # Check pdf format and begin extraction of results\n",
    "    \n",
    "    if 'W/G' not in columns:  # if older pdf format without a 'W/G column'\n",
    "            \n",
    "        df2 = pd.DataFrame(columns=names)        \n",
    "    \n",
    "        new_df = df2.iloc[:, :-2]    # remove Remarks and N/R columns\n",
    "         \n",
    "        for i in range(row_index+1,(len(df)-1)):                    \n",
    "            \n",
    "            if not re.search('^\\d', table[i]): # skip row if disqualified or withdrawn (does not begin with a digit)\n",
    "            \n",
    "                continue\n",
    "       \n",
    "            string=table[i]\n",
    "                                \n",
    "            lpos = re.search('\\s', string)\n",
    "                #rpos = re.search('\\sQ\\s', s)\n",
    "                #rpos = re.search('\\s[A-Z]{2,4}', s)\n",
    "            \n",
    "            matches=re.findall(school_pattern, string)  # find how many uppercase shortforms for school\n",
    "                                \n",
    "            if len(matches)==2:\n",
    "                \n",
    "                rpos=re.search(matches[1], string) # choose second match if there are two \n",
    "                    \n",
    "            else:\n",
    "                    \n",
    "                rpos = re.search(old_pattern, string)\n",
    "                \n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            \n",
    "            l = string[:lpos.start()] # left string post splicing\n",
    "            r = string[rpos.start():] # right string post slicing\n",
    "         \n",
    "            name=string[lpos.start():rpos.start()] # extract competitor name\n",
    "                                \n",
    "            list=r.split(' ')   # split the parts after the name    \n",
    "            \n",
    "            combined=l+ ',' + name + ', '.join(list)\n",
    "\n",
    "            row=combined.split(\",\")\n",
    "                        \n",
    "                        \n",
    "            if ('W/G' not in names) and len(row)!=6:  # if W/G not in list of columns\n",
    "            \n",
    "                n=len(row)-6\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "            \n",
    "            elif ('W/G' in names) and len(row)>8:\n",
    "            \n",
    "                n=len(row)-8\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "                                        \n",
    "            new_df.loc[len(new_df)] = row\n",
    "            \n",
    "            \n",
    "        return new_df\n",
    "            \n",
    "    elif 'W/G' in columns: # new format \n",
    "    \n",
    "            \n",
    "        master_df=new_format_parser(row_index, names, table, master_df) \n",
    "     \n",
    "    ##        master_df= pd.concat([temp_df, master_df])\n",
    "        \n",
    "#        print(master_df)\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f0c1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_old(table, master_df):  # old version without calling new_format_parser function\n",
    "\n",
    "    global index\n",
    "        \n",
    "        \n",
    "    # Regex patterns to extract competitor names, event name etc.\n",
    "    \n",
    "    #new_pattern='\\d\\s.{5,20}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='\\d\\s[A-Z\\s\\,]{5,30}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='^[A-Z\\s]*$'\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Q|q|\\d)'\n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "\n",
    "    \n",
    "    # Initialize new df and extract event information\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "    \n",
    "    columns=[]\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows(): # find row containing event details and column names\n",
    "        \n",
    "        \n",
    "        if 'Event' in row[0]: # data is in column '0' \n",
    "            \n",
    "            event=row[0]   # set string for extraction of event info\n",
    "            \n",
    "                        \n",
    "            epos = re.search(event_pattern, event)\n",
    "                        \n",
    "            split_end=epos.end()-1      # adjust the splicing position to only capture the event name\n",
    "            split_start=epos.start()+1\n",
    "\n",
    "            event=event[split_start:split_end]\n",
    "                                    \n",
    "            \n",
    "            if 'BOYS' in event or 'Boys' in event:\n",
    "                gender='Male'\n",
    "                \n",
    "            if 'GIRLS' in event or 'Girls' in event:\n",
    "                gender='Female'    \n",
    "                \n",
    "            \n",
    "            if 'Finals' in event:\n",
    "                round='Finals'\n",
    "            \n",
    "            region='Local'  \n",
    "            \n",
    "       \n",
    "            \n",
    "        if 'Competitor' in row[0]: # extract column names\n",
    "            \n",
    "            row_index=index\n",
    "            columns=df.iloc[row_index,0]\n",
    "            names=columns.split(' ')\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Check pdf format and begin extraction of results\n",
    "    \n",
    "    if 'W/G' not in columns:  # if older pdf format without a 'W/G column'\n",
    "            \n",
    "        df2 = pd.DataFrame(columns=names)        \n",
    "    \n",
    "        new_df = df2.iloc[:, :-2]    # remove Remarks and N/R columns\n",
    "         \n",
    "        for i in range(row_index+1,(len(df)-1)):                    \n",
    "            \n",
    "            if not re.search('^\\d', table[i]): # skip row if disqualified or withdrawn (does not begin with a digit)\n",
    "            \n",
    "                continue\n",
    "       \n",
    "            string=table[i]\n",
    "                                \n",
    "            lpos = re.search('\\s', string)\n",
    "                #rpos = re.search('\\sQ\\s', s)\n",
    "                #rpos = re.search('\\s[A-Z]{2,4}', s)\n",
    "            \n",
    "            matches=re.findall(school_pattern, string)  # find how many uppercase shortforms for school\n",
    "                                \n",
    "            if len(matches)==2:\n",
    "                \n",
    "                rpos=re.search(matches[1], string) # choose second match if there are two \n",
    "                    \n",
    "            else:\n",
    "                    \n",
    "                rpos = re.search(old_pattern, string)\n",
    "                \n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            \n",
    "            l = string[:lpos.start()] # left string post splicing\n",
    "            r = string[rpos.start():] # right string post slicing\n",
    "         \n",
    "            name=string[lpos.start():rpos.start()] # extract competitor name\n",
    "                                \n",
    "            list=r.split(' ')   # split the parts after the name    \n",
    "            \n",
    "            combined=l+ ',' + name + ', '.join(list)\n",
    "\n",
    "            row=combined.split(\",\")\n",
    "                        \n",
    "                        \n",
    "            if ('W/G' not in names) and len(row)!=6:  # if W/G not in list of columns\n",
    "            \n",
    "                n=len(row)-6\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "            \n",
    "            elif ('W/G' in names) and len(row)>8:\n",
    "            \n",
    "                n=len(row)-8\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "                                        \n",
    "            new_df.loc[len(new_df)] = row\n",
    "            \n",
    "        return new_df\n",
    "            \n",
    "    elif 'W/G' in columns: # new format \n",
    "            \n",
    "            df2 = pd.DataFrame(columns=names)        \n",
    "    \n",
    "            new_df = df2.iloc[:, :-2]    # remove 'Remarks' and 'NR' columns        \n",
    "\n",
    "         \n",
    "            for i in range(row_index+1,(len(df)-1)):\n",
    "                                \n",
    "                if 'DNM' in table[i]:\n",
    "                    \n",
    "                    continue # skip row if DNM, DQ, DNF etc.\n",
    "                            \n",
    "                if not re.search('^\\d', table[i]): # look for stranded parts of names (does not begin with a digit)\n",
    "            \n",
    "                    row[1]=row[1]+table[i] # retrieve previous row and add back stranded string to name\n",
    "                \n",
    "                    new_df.drop(new_df.tail(1).index,inplace=True) # drop last row with incomplete name\n",
    "                                        \n",
    "                    new_df.loc[len(new_df)] = row  # add back amended row\n",
    "                    \n",
    "                    continue  # then skip to next row\n",
    "                              \n",
    "\n",
    "                string=table[i]\n",
    "                                \n",
    "                lpos = re.search('\\s', string)\n",
    "                rpos = re.search(new_pattern, string)\n",
    "                                            \n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "                split_pos_end=rpos.end()-1      # adjust the splicing position to only capture the name\n",
    "                split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "                left_string = string[:lpos.start()] # left string post splicing\n",
    "                right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "                name=string[split_pos_start:split_pos_end]  # extract competitor name            \n",
    "                                \n",
    "                list=right_string.split(' ')        # put everything coming after the name into a list   \n",
    "                \n",
    "                \n",
    "                if len(list)==6:    # check length of list. If less than 7, append blank fields for Pos and W/G \n",
    "                    \n",
    "                    list.extend([' ', ' '])\n",
    "                    \n",
    "                elif len(list)==5:\n",
    "                    \n",
    "                    list.extend([' ', ' '])\n",
    "                                                            \n",
    "                \n",
    "                combined=left_string+ ';' + name +'; '+ '; '.join(list)  # use ';' in case names have a ','\n",
    "\n",
    "                row=combined.split(';')\n",
    "                                                                                \n",
    "                \n",
    "        # check if Q or q between tag and name. If not, fill in with empty space.\n",
    "        \n",
    "                \n",
    "                if row[2].strip()=='Q' or row[2] is None:\n",
    "                    \n",
    "                    pass\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    row.insert(2, ' ')  # insert a blank field if no Q or q\n",
    "                    \n",
    "                                            \n",
    "                new_df.loc[len(new_df)] = row\n",
    "                \n",
    "                print(row)\n",
    "                    \n",
    "                    \n",
    "            return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71cf5822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Singapore Schools Sports Council 14-04-2010\n",
      "1 51st National Inter-School Track and Field Championships 2010 10:02 PM\n",
      "2 Audit List Page 28\n",
      "3 Event : 200 Metres (C-Boys) Type : All Heats\n",
      "4 02-03\n",
      "5 Record : Mohd Yusof Bin Azhari SJI 2003 ET 00:22.99s\n",
      "6 Pos Competitor Team Ht Ln Result Pts Remark\n",
      "7 1 Shawn Poh Zhi Kang SKS 13 7 00:24.20\n",
      "8 2 Liaw Jian Hui AMK 3 7 00:24.68\n",
      "9 3 Zubin Percy Muncherji ACS(BR) 8 7 00:24.77\n",
      "10 4 Terence Loh Junheng ACS(I) 2 4 00:24.84\n",
      "11 5 Md Nur Syahirran SSP 10 3 00:24.90\n",
      "12 6 Ong Sin Yao CCH 2 7 00:24.97\n",
      "13 7 Wu Chee Keen Daniel DSS 9 1 00:25.05\n",
      "14 8 Jonathan Lew Lian Xin RI 11 5 00:25.06\n",
      "15 9 Ang Li Sheng AND 2 6 00:25.16\n",
      "16 10 Teo Yu Ming RI 6 6 00:25.62\n",
      "17 11 Clyde Tan Jin Shuen ACS(I) 8 6 00:25.68\n",
      "18 12 Chua Cheng Ying SJI 13 6 00:25.69\n",
      "19 13 Puah Li An NTS 4 5 00:25.70\n",
      "20 14 Raymond Scott Lee Chian Hoong SJI 2 5 00:25.84\n",
      "21 15 Ridwan Bin Yahya TMS 1 8 00:25.85\n",
      "22 16 Tan Hui Ming Zac NSS 5 8 00:25.89\n",
      "23 17 Daryl Shane Lee TMS 5 5 00:25.93\n",
      "24 18 Chin Yew Chung Kennard SJI 4 7 00:26.08\n",
      "25 19 Amos Tan SAS 9 2 00:26.09\n",
      "26 20 Ryan Leong Jun Yan SKS 3 4 00:26.10\n",
      "27 21 Muhammad Firman B Jumat AMK 7 6 00:26.17\n",
      "28 22 Tiew Zi Hao Andrew SPS 5 7 00:26.21\n",
      "29 23 Abdul Halim SKS 7 7 00:26.23\n",
      "30 24 Aryobimo Wibowoputro AMK 8 4 00:26.24\n",
      "31 25 Ong Kai Ming CCK 1 3 00:26.26\n",
      "32 26 Gabriel Lau Yu Sheng HY 3 8 00:26.30\n",
      "33 27 Nian Ding Chao AIS 2 3 00:26.37\n",
      "34 28 Zuhairi Bin Anuar SSP 8 1 00:26.46\n",
      "35 29 Shafeeq NAS 5 2 00:26.50\n",
      "36 30 Ong Shao Ming BTV 12 3 00:26.53\n",
      "37 31 Ng Zin Tiao, Brent SPS 4 2 00:26.55\n",
      "38 32 Richmond Sugita Tadayoshi SSP 9 7 00:26.58\n",
      "39 33 Wang Xian Yang, Jerrel CH 9 3 00:26.73\n",
      "40 34 Aloysius Yeo Rui Sen TMS 4 4 00:26.84\n",
      "41 35 Tan Qin Xiang HCI 1 2 00:26.90\n",
      "42 36 Tobias Tan Ning DHS 10 4 00:26.92\n",
      "43 37 Benjamin Ong BV 11 3 00:26.99\n",
      "44 37 Phang Yong Kang CCH 9 4 00:26.99\n",
      "45 39 Jerald Saw SAS 3 3 00:27.02\n",
      "46 40 Daniel Boey Kai Sheng RI 1 4 00:27.04\n",
      "47 AppName : Flash2000 Master 2010.04.14a RptName : fmRptA4ListAuditSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n",
      "/var/folders/q5/yf8g5p896_b94gkbhqcjx3t40000gn/T/ipykernel_67368/2665074277.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df.loc[len(new_df)] = row\n"
     ]
    }
   ],
   "source": [
    "master_df=None\n",
    "\n",
    "master_df=extraction_old(splitted, master_df)  # using old extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f8a71d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Ln</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Singapore Sports School</td>\n",
       "      <td>SSP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>00:49.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CHIJ St Nicholas Girls' School</td>\n",
       "      <td>SNG</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>00:51.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nanyang Girls' High School</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>00:52.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cedar Girls' Sec School</td>\n",
       "      <td>CG</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>00:52.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CHIJ Sec (Toa Payoh)</td>\n",
       "      <td>HIJ</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>00:53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CHIJ Katong Convent</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:55.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>North Vista Sec School</td>\n",
       "      <td>NV</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>00:55.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Raffles Girls' School (Sec)</td>\n",
       "      <td>RGS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:57.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos                       Competitor   Team  Ht  Ln     Result\n",
       "0   1          Singapore Sports School    SSP   1   4   00:49.67\n",
       "1   2   CHIJ St Nicholas Girls' School    SNG   1   5   00:51.41\n",
       "2   3       Nanyang Girls' High School   NYGH   1   6   00:52.25\n",
       "3   4          Cedar Girls' Sec School     CG   1   3   00:52.90\n",
       "4   5             CHIJ Sec (Toa Payoh)    HIJ   1   7   00:53.88\n",
       "5   6              CHIJ Katong Convent     KC   1   2   00:55.58\n",
       "6   7           North Vista Sec School     NV   1   8   00:55.69\n",
       "7   8      Raffles Girls' School (Sec)    RGS   1   1   00:57.27"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8833aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test iteration over more than one page\n",
    "\n",
    "#os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\n",
    "\n",
    "file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/Deconstructed/S01-01_TO_11_deconstructed.pdf\"\n",
    "\n",
    " \n",
    "# Iterate over files in directory\n",
    "\n",
    "#sorted_items=sort_directory(directory)\n",
    "\n",
    "master_df=pd.DataFrame()  # initialize empty master df\n",
    "\n",
    "splitted=None\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "    for i in range(len(pdf.pages)):\n",
    "        \n",
    "        temp=splitted\n",
    "        \n",
    "        page = pdf.pages[i]  # can iterate over different pages\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()\n",
    "        \n",
    "        if i==0:\n",
    "        \n",
    "            splitted=text.splitlines()            \n",
    "            \n",
    "        else: # stitch list from second page\n",
    "            \n",
    "            temp=text.splitlines()\n",
    "            \n",
    "            splitted.extend(temp)\n",
    "            \n",
    "    master_df=extraction(splitted, master_df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65062e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "# 1. code old_format_parser function for old format pdfs\n",
    "# 2. Test iteration over several pages using pdf.pages[0]\n",
    "# 3. Modify code to iterate over second stranded page and add data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2262677",
   "metadata": {},
   "source": [
    "# Extract list of schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a9821864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of primary and secondary schools\n",
    "# Using BS4\n",
    "\n",
    "URL ='https://en.wikipedia.org/wiki/List_of_secondary_schools_in_Singapore'\n",
    "page=requests.get(URL)\n",
    "\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "1c14f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list with all tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "#  Looking for the table with the classes 'wikitable' and 'sortable'\n",
    "table = soup.find('table', class_='wikitable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4ece7143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Name\n",
      "Type\n",
      "SchoolCode\n",
      "Area[4]\n",
      "Notes / Affiliations (Admissions / Academic Programmes)\n",
      "Website\n",
      "\n",
      "\n",
      "Admiralty Secondary School\n",
      "Government\n",
      "3072\n",
      "Woodlands\n",
      "\n",
      "[1]\n",
      "\n",
      "\n",
      "Ahmad Ibrahim Secondary School\n",
      "Government\n",
      "3201\n",
      "Yishun\n",
      "\n",
      "[2]\n",
      "\n",
      "\n",
      "Anderson Secondary School\n",
      "GovernmentAutonomous\n",
      "3001\n",
      "Ang Mo Kio\n",
      "\n",
      "[3]\n",
      "\n",
      "\n",
      "Anglican High School\n",
      "Government-aidedAutonomousSAP\n",
      "\n",
      "7101\n",
      "Bedok\n",
      "\n",
      "[4]\n",
      "\n",
      "\n",
      "Anglo-Chinese School (Barker Road)\n",
      "Government-aided\n",
      "7032\n",
      "Newton\n",
      "Affiliated to:\n",
      "Methodist Girls' School (Secondary)\n",
      "\n",
      "[5]\n",
      "\n",
      "\n",
      "Anglo-Chinese School (Independent)\n",
      "IndependentIP\n",
      "IP:9161Express:7001\n",
      "\n",
      "Queenstown\n",
      "\n",
      "Offers the International Baccalaureate certificate\n",
      "Affiliated to:\n",
      "Methodist Girls' School (Secondary) (IP)\n",
      "\n",
      "[6]\n",
      "\n",
      "\n",
      "Ang Mo Kio Secondary School\n",
      "Government\n",
      "3026\n",
      "Ang Mo Kio\n",
      "\n",
      "[7]\n",
      "\n",
      "\n",
      "Assumption English School\n",
      "Government-aided\n",
      "7002\n",
      "Bukit Panjang\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)[5]\n",
      "\n",
      "[8]\n",
      "\n",
      "\n",
      "Bartley Secondary School\n",
      "Government\n",
      "3002\n",
      "Toa Payoh\n",
      "\n",
      "[9]\n",
      "\n",
      "\n",
      "Beatty Secondary School\n",
      "Government\n",
      "3003\n",
      "Toa Payoh\n",
      "\n",
      "[10]\n",
      "\n",
      "\n",
      "Bedok Green Secondary School\n",
      "Government\n",
      "3069\n",
      "Bedok\n",
      "\n",
      "[11]\n",
      "\n",
      "\n",
      "Bedok South Secondary School\n",
      "Government\n",
      "3027\n",
      "Bedok\n",
      "\n",
      "[12]\n",
      "\n",
      "\n",
      "Bedok View Secondary School\n",
      "Government\n",
      "3225\n",
      "Bedok\n",
      "\n",
      "[13]\n",
      "\n",
      "\n",
      "Bendemeer Secondary School\n",
      "Government\n",
      "3021\n",
      "Kallang\n",
      "\n",
      "[14]\n",
      "\n",
      "\n",
      "Boon Lay Secondary School\n",
      "Government\n",
      "3224\n",
      "Jurong West\n",
      "\n",
      "[15]\n",
      "\n",
      "\n",
      "Bowen Secondary School\n",
      "Government\n",
      "3043\n",
      "Hougang\n",
      "\n",
      "[16]\n",
      "\n",
      "\n",
      "Broadrick Secondary School\n",
      "Government\n",
      "3202\n",
      "Geylang\n",
      "\n",
      "[17]\n",
      "\n",
      "\n",
      "Bukit Batok Secondary School\n",
      "Government\n",
      "3044\n",
      "Bukit Batok\n",
      "\n",
      "[18]\n",
      "\n",
      "\n",
      "Bukit Merah Secondary School\n",
      "Government\n",
      "3203\n",
      "Bukit Merah\n",
      "\n",
      "[19]\n",
      "\n",
      "\n",
      "Bukit Panjang Government High School\n",
      "GovernmentAutonomous\n",
      "3204\n",
      "Choa Chu Kang\n",
      "\n",
      "[20]\n",
      "\n",
      "\n",
      "Bukit View Secondary School\n",
      "Government\n",
      "3040\n",
      "Bukit Batok\n",
      "\n",
      "[21]\n",
      "\n",
      "\n",
      "Catholic High School\n",
      "Government-aidedAutonomousSAPIP\n",
      "\n",
      "IP:9131Special:7102\n",
      "\n",
      "Bishan\n",
      "\n",
      "Affiliated to:\n",
      "Eunoia Junior College (IP)\n",
      "Singapore Chinese Girls' School (IP), CHIJ Saint Nicholas Girls' School (IP)\n",
      "Catholic Junior College (Non-IP)\n",
      "\n",
      "[22]\n",
      "\n",
      "\n",
      "Canberra Secondary School\n",
      "Government\n",
      "3621\n",
      "Sembawang\n",
      "\n",
      "[23]\n",
      "\n",
      "\n",
      "Cedar Girls' Secondary School\n",
      "GovernmentAutonomousIP\n",
      "\n",
      "IP:9152Express:3004\n",
      "\n",
      "Toa Payoh\n",
      "\n",
      "Affiliated to:\n",
      "Victoria Junior College (IP)\n",
      "Victoria School (IP)\n",
      "\n",
      "[24]\n",
      "\n",
      "\n",
      "Changkat Changi Secondary School\n",
      "Government\n",
      "3402\n",
      "Simei\n",
      "\n",
      "[25]\n",
      "\n",
      "\n",
      "CHIJ Katong Convent (Secondary)\n",
      "Government-aidedAutonomous\n",
      "7008\n",
      "Marine Parade\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "CHIJ Katong (Primary)\n",
      "\n",
      "[26]\n",
      "\n",
      "\n",
      "CHIJ Secondary (Toa Payoh)\n",
      "Government-aidedAutonomous\n",
      "7004\n",
      "Toa Payoh\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "CHIJ Primary (Toa Payoh)\n",
      "\n",
      "[27]\n",
      "\n",
      "\n",
      "CHIJ St. Joseph's Convent\n",
      "Government-aided\n",
      "7019\n",
      "Sengkang\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "CHIJ Our Lady of the Nativity & CHIJ Our Lady of Good Counsel\n",
      "\n",
      "[28]\n",
      "\n",
      "\n",
      "CHIJ St. Nicholas Girls' School\n",
      "Government-aidedAutonomousSAPIP\n",
      "\n",
      "IP:9134Special:7118\n",
      "\n",
      "Ang Mo Kio\n",
      "\n",
      "Affiliated to:\n",
      "Eunoia Junior College (IP), Singapore Chinese Girls' School (IP) & Catholic High School (IP)\n",
      "Catholic Junior College (Non-IP)\n",
      "CHIJ St. Nicholas Girls' School (Primary)\n",
      "\n",
      "[29]\n",
      "\n",
      "\n",
      "CHIJ St. Theresa's Convent\n",
      "Government-aided\n",
      "7023\n",
      "Bukit Merah\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "CHIJ (Kellock), CHIJ Our Lady Queen of Peace\n",
      "\n",
      "[30]\n",
      "\n",
      "\n",
      "Chua Chu Kang Secondary School\n",
      "Government\n",
      "3055\n",
      "Choa Chu Kang\n",
      "\n",
      "[31]\n",
      "\n",
      "\n",
      "Christ Church Secondary School\n",
      "Government-aided\n",
      "7025\n",
      "Woodlands\n",
      "\n",
      "Affiliated to:\n",
      "St. Andrews Junior College (Non-IP)\n",
      "\n",
      "[32]\n",
      "\n",
      "\n",
      "Chung Cheng High School (Main)\n",
      "Government-aidedAutonomousSAP\n",
      "\n",
      "7104\n",
      "Marine Parade\n",
      "\n",
      "Affiliated to:\n",
      "Nanyang Junior College (Non-IP)\n",
      "Chung Cheng High School (Yishun) (Non-IP)\n",
      "\n",
      "[33]\n",
      "\n",
      "\n",
      "Chung Cheng High School (Yishun)\n",
      "Government-aided\n",
      "7105\n",
      "Yishun\n",
      "\n",
      "Affiliated to:\n",
      "Nanyang Junior College (Non-IP)\n",
      "Chung Cheng High School (Main) (Non-IP)\n",
      "\n",
      "[34]\n",
      "\n",
      "\n",
      "Clementi Town Secondary School\n",
      "Government\n",
      "3029\n",
      "Clementi\n",
      "\n",
      "[35]\n",
      "\n",
      "\n",
      "Commonwealth Secondary School\n",
      "GovernmentAutonomous\n",
      "\n",
      "3012\n",
      "Jurong East\n",
      "\n",
      "[36]\n",
      "\n",
      "\n",
      "Compassvale Secondary School\n",
      "Government\n",
      "3622\n",
      "Sengkang\n",
      "\n",
      "[37]\n",
      "\n",
      "\n",
      "Crescent Girls' School\n",
      "GovernmentAutonomous\n",
      "3005\n",
      "Bukit Merah\n",
      "\n",
      "[38]\n",
      "\n",
      "\n",
      "Damai Secondary School\n",
      "Government\n",
      "3056\n",
      "Bedok\n",
      "\n",
      "[39]\n",
      "\n",
      "\n",
      "Deyi Secondary School\n",
      "Government\n",
      "3228\n",
      "Ang Mo Kio\n",
      "\n",
      "[40]\n",
      "\n",
      "\n",
      "Dunearn Secondary School\n",
      "Government\n",
      "3503\n",
      "Bukit Batok\n",
      "\n",
      "[41]\n",
      "\n",
      "\n",
      "Dunman High School\n",
      "GovernmentAutonomousSAPIP\n",
      "\n",
      "3101\n",
      "Kallang\n",
      "\n",
      "[42]\n",
      "\n",
      "\n",
      "Dunman Secondary School\n",
      "GovernmentAutonomous\n",
      "3207\n",
      "Tampines\n",
      "\n",
      "[43]\n",
      "\n",
      "\n",
      "East Spring Secondary School\n",
      "Government\n",
      "3609\n",
      "Tampines\n",
      "\n",
      "[44]\n",
      "\n",
      "\n",
      "Edgefield Secondary School\n",
      "Government\n",
      "3075\n",
      "Punggol\n",
      "\n",
      "[45]\n",
      "\n",
      "\n",
      "Evergreen Secondary School\n",
      "Government\n",
      "3623\n",
      "Woodlands\n",
      "\n",
      "[46]\n",
      "\n",
      "\n",
      "Fairfield Methodist Secondary School\n",
      "Government-aidedAutonomous\n",
      "7309\n",
      "Queenstown\n",
      "\n",
      "Affiliated to:\n",
      "Anglo-Chinese Junior College (Non-IP)\n",
      "Fairfield Methodist School (Primary)\n",
      "\n",
      "[47]\n",
      "\n",
      "\n",
      "Fuchun Secondary School\n",
      "Government\n",
      "3024\n",
      "Woodlands\n",
      "\n",
      "[48]\n",
      "\n",
      "\n",
      "Fuhua Secondary School\n",
      "Government\n",
      "3614\n",
      "Jurong West\n",
      "\n",
      "[49]\n",
      "\n",
      "\n",
      "Gan Eng Seng School\n",
      "Government\n",
      "3006\n",
      "Bukit Merah\n",
      "\n",
      "[50]\n",
      "\n",
      "\n",
      "Geylang Methodist School (Secondary)\n",
      "Government-aided\n",
      "7005\n",
      "Geylang\n",
      "\n",
      "Affiliated to:\n",
      "Anglo-Chinese Junior College (Non-IP)\n",
      "Geylang Methodist School (Primary)\n",
      "\n",
      "[51]\n",
      "\n",
      "\n",
      "Greendale Secondary School\n",
      "Government\n",
      "3074\n",
      "Punggol\n",
      "\n",
      "[52]\n",
      "\n",
      "\n",
      "Greenridge Secondary School\n",
      "Government\n",
      "3051\n",
      "Bukit Panjang\n",
      "\n",
      "[53]\n",
      "\n",
      "\n",
      "Guangyang Secondary School\n",
      "Government\n",
      "3238\n",
      "Bishan\n",
      "\n",
      "[54]\n",
      "\n",
      "\n",
      "Hai Sing Catholic School\n",
      "Government-aided\n",
      "7031\n",
      "Pasir Ris\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "\n",
      "[55]\n",
      "\n",
      "\n",
      "Hillgrove Secondary School\n",
      "Government\n",
      "3048\n",
      "Bukit Batok\n",
      "\n",
      "[56]\n",
      "\n",
      "\n",
      "Holy Innocents' High School\n",
      "Government-aided\n",
      "7108\n",
      "Hougang\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "Holy Innocents' Primary School\n",
      "\n",
      "[57]\n",
      "\n",
      "\n",
      "Hougang Secondary School\n",
      "Government\n",
      "3046\n",
      "Hougang\n",
      "\n",
      "[58]\n",
      "\n",
      "\n",
      "Hua Yi Secondary School\n",
      "Government\n",
      "3226\n",
      "Jurong West\n",
      "\n",
      "[59]\n",
      "\n",
      "\n",
      "Hwa Chong Institution\n",
      "IndependentSAPIP\n",
      "\n",
      "0806\n",
      "\n",
      "Bukit Timah\n",
      "\n",
      "Offers the Hwa Chong Diploma\n",
      "Affiliated to:\n",
      "Nanyang Girls' High School (IP)\n",
      "\n",
      "[60]\n",
      "\n",
      "\n",
      "Junyuan Secondary School\n",
      "Government\n",
      "3608\n",
      "Tampines\n",
      "\n",
      "[61]\n",
      "\n",
      "\n",
      "Jurong Secondary School\n",
      "Government\n",
      "3211\n",
      "Jurong West\n",
      "\n",
      "[62]\n",
      "\n",
      "\n",
      "Jurong West Secondary School\n",
      "Government\n",
      "3068\n",
      "Jurong West\n",
      "\n",
      "[63]\n",
      "\n",
      "\n",
      "Jurongville Secondary School\n",
      "Government\n",
      "3063\n",
      "Jurong East\n",
      "\n",
      "[64]\n",
      "\n",
      "\n",
      "Juying Secondary School\n",
      "Government\n",
      "3066\n",
      "Jurong West\n",
      "\n",
      "[65]\n",
      "\n",
      "\n",
      "Kent Ridge Secondary School\n",
      "Government\n",
      "3619\n",
      "Clementi\n",
      "\n",
      "[66]\n",
      "\n",
      "\n",
      "Kranji Secondary School\n",
      "Government\n",
      "3065\n",
      "Choa Chu Kang\n",
      "\n",
      "[67]\n",
      "\n",
      "\n",
      "Kuo Chuan Presbyterian Secondary School\n",
      "Government-aided\n",
      "7028\n",
      "Bishan\n",
      "\n",
      "Affiliated to:\n",
      "St. Andrews Junior College (Non-IP)\n",
      "Kuo Chuan Presbyterian Primary School\n",
      "\n",
      "[68]\n",
      "\n",
      "\n",
      "Loyang View Secondary School\n",
      "Government\n",
      "3049\n",
      "Pasir Ris\n",
      "\n",
      "[69]\n",
      "\n",
      "\n",
      "Manjusri Secondary School\n",
      "Government-aided\n",
      "7307\n",
      "Geylang\n",
      "\n",
      "Affiliated to:\n",
      "Mee Toh School, Maha Bodhi School\n",
      "\n",
      "[70]\n",
      "\n",
      "\n",
      "Maris Stella High School\n",
      "Government-aidedAutonomousSAP\n",
      "\n",
      "7111\n",
      "Toa Payoh\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "Maris Stella High School (Primary)\n",
      "\n",
      "[71]\n",
      "\n",
      "\n",
      "Marsiling Secondary School\n",
      "Government\n",
      "3615\n",
      "Woodlands\n",
      "\n",
      "[72]\n",
      "\n",
      "\n",
      "Mayflower Secondary School\n",
      "Government\n",
      "3031\n",
      "Ang Mo Kio\n",
      "\n",
      "[73]\n",
      "\n",
      "\n",
      "Meridian Secondary School\n",
      "\n",
      "Government\n",
      "\n",
      "3076\n",
      "\n",
      "Pasir Ris\n",
      "\n",
      "\n",
      "\n",
      "[74]\n",
      "\n",
      "\n",
      "Methodist Girls' School (Secondary)\n",
      "IndependentIP\n",
      "\n",
      "IP:9162Express:7030\n",
      "\n",
      "Bukit Timah\n",
      "\n",
      "Affiliated to:\n",
      "Anglo-Chinese School (Independent) (IP)\n",
      "Methodist Girls' School (Primary)\n",
      "\n",
      "[75]\n",
      "\n",
      "\n",
      "Montfort Secondary School\n",
      "Government-aided\n",
      "7011\n",
      "Hougang\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "Montfort Junior School\n",
      "\n",
      "[76]\n",
      "\n",
      "\n",
      "Nan Chiau High School\n",
      "Government-aidedSAP\n",
      "\n",
      "7112\n",
      "Sengkang\n",
      "\n",
      "Affiliated to:\n",
      "Singapore Hokkien Huay Kuan\n",
      "\n",
      "[77]\n",
      "\n",
      "\n",
      "Nan Hua High School\n",
      "GovernmentAutonomousSAP\n",
      "\n",
      "3047\n",
      "Clementi\n",
      "\n",
      "[78]\n",
      "\n",
      "\n",
      "Nanyang Girls' High School\n",
      "IndependentSAPIP\n",
      "\n",
      "7114\n",
      "Bukit Timah\n",
      "\n",
      "Offers the Hwa Chong Diploma\n",
      "Affiliated to:\n",
      "Hwa Chong Institution (IP)\n",
      "Nanyang Primary School\n",
      "\n",
      "[79]\n",
      "\n",
      "\n",
      "National Junior College\n",
      "Government\n",
      "IP\n",
      "\n",
      "\n",
      "0701\n",
      "Bukit Timah\n",
      "\n",
      "[80]\n",
      "\n",
      "\n",
      "Naval Base Secondary School\n",
      "Government\n",
      "3214\n",
      "Yishun\n",
      "\n",
      "[81]\n",
      "\n",
      "\n",
      "New Town Secondary School\n",
      "Government\n",
      "3507\n",
      "Queenstown\n",
      "\n",
      "[82]\n",
      "\n",
      "\n",
      "Ngee Ann Secondary School\n",
      "Government-aidedAutonomous\n",
      "\n",
      "7310\n",
      "Tampines\n",
      "\n",
      "Affiliated to:\n",
      "Ngee Ann Primary School\n",
      "\n",
      "[83]\n",
      "\n",
      "\n",
      "North Vista Secondary School\n",
      "Government\n",
      "3071\n",
      "Sengkang\n",
      "\n",
      "[84]\n",
      "\n",
      "\n",
      "Northbrooks Secondary School\n",
      "Government\n",
      "3612\n",
      "Yishun\n",
      "\n",
      "[85]\n",
      "\n",
      "\n",
      "Northland Secondary School\n",
      "Government\n",
      "3058\n",
      "Yishun\n",
      "\n",
      "[86]\n",
      "\n",
      "\n",
      "NUS High School of Mathematics and Science\n",
      "IndependentSpecialisedIP\n",
      "\n",
      "7801\n",
      "\n",
      "Clementi\n",
      "\n",
      "Offers the NUS High School Diploma\n",
      "Admit students through DSA and/or Independent Intake\n",
      "\n",
      "[87]\n",
      "\n",
      "\n",
      "Orchid Park Secondary School\n",
      "Government\n",
      "3605\n",
      "Yishun\n",
      "\n",
      "[88]\n",
      "\n",
      "\n",
      "Outram Secondary School\n",
      "Government\n",
      "3215\n",
      "Central\n",
      "\n",
      "[89]\n",
      "\n",
      "\n",
      "Pasir Ris Crest Secondary School\n",
      "Government\n",
      "3613\n",
      "Pasir Ris\n",
      "\n",
      "[90]\n",
      "\n",
      "\n",
      "Pasir Ris Secondary School\n",
      "Government\n",
      "3235\n",
      "Tampines\n",
      "\n",
      "[91]\n",
      "\n",
      "\n",
      "Paya Lebar Methodist Girls' School (Secondary)\n",
      "Government-aidedAutonomous\n",
      "7026\n",
      "Hougang\n",
      "\n",
      "Affiliated to:\n",
      "Anglo-Chinese Junior College (Non-IP)\n",
      "Paya Lebar Methodist Girls' School (Primary)\n",
      "\n",
      "[92]\n",
      "\n",
      "\n",
      "Pei Hwa Secondary School\n",
      "Government-aided\n",
      "3073\n",
      "Sengkang\n",
      "\n",
      "[93]\n",
      "\n",
      "\n",
      "Peicai Secondary School\n",
      "Government\n",
      "3232\n",
      "Serangoon\n",
      "\n",
      "[94]\n",
      "\n",
      "\n",
      "Peirce Secondary School\n",
      "Government\n",
      "3061\n",
      "Bishan\n",
      "\n",
      "[95]\n",
      "\n",
      "\n",
      "Presbyterian High School\n",
      "Government-aided\n",
      "7308\n",
      "Ang Mo Kio\n",
      "\n",
      "Affiliated to:\n",
      "St. Andrews Junior College (Non-IP)\n",
      "\n",
      "[96]\n",
      "\n",
      "\n",
      "Punggol Secondary School\n",
      "Government\n",
      "3070\n",
      "Punggol\n",
      "\n",
      "[97]\n",
      "\n",
      "\n",
      "Queenstown Secondary School\n",
      "Government\n",
      "3508\n",
      "Queenstown\n",
      "\n",
      "[98]\n",
      "\n",
      "\n",
      "Queensway Secondary School\n",
      "Government\n",
      "3007\n",
      "Queenstown\n",
      "\n",
      "[99]\n",
      "\n",
      "\n",
      "Raffles Girls' School (Secondary)\n",
      "IndependentIP\n",
      "\n",
      "3008\n",
      "Bishan\n",
      "\n",
      "Offers the Raffles Diploma\n",
      "Affiliated to:\n",
      "Raffles Institution (IP)\n",
      "\n",
      "[100]\n",
      "\n",
      "\n",
      "Raffles Institution\n",
      "IndependentIP\n",
      "\n",
      "3009\n",
      "Bishan\n",
      "\n",
      "Offers the Raffles Diploma\n",
      "Affiliated to:\n",
      "Raffles Girls' School (IP)\n",
      "\n",
      "[101]\n",
      "\n",
      "\n",
      "Regent Secondary School\n",
      "Government\n",
      "3618\n",
      "Choa Chu Kang\n",
      "\n",
      "[102]\n",
      "\n",
      "\n",
      "Riverside Secondary School\n",
      "Government\n",
      "3239\n",
      "Woodlands\n",
      "\n",
      "[103]\n",
      "\n",
      "\n",
      "River Valley High School\n",
      "GovernmentAutonomousSAPIP\n",
      "\n",
      "3103\n",
      "Boon Lay\n",
      "\n",
      "[104]\n",
      "\n",
      "\n",
      "St. Andrew's Secondary School\n",
      "Government-aided\n",
      "7015\n",
      "Potong Pasir\n",
      "\n",
      "[105]\n",
      "\n",
      "\n",
      "St. Patrick's School\n",
      "Government-aided\n",
      "7022\n",
      "Bedok\n",
      "\n",
      "[106]\n",
      "\n",
      "\n",
      "School of Science and Technology, Singapore\n",
      "IndependentSpecialised\n",
      "7805\n",
      "\n",
      "Commonwealth West\n",
      "\n",
      "Admit students through DSA and/or Independent Intake\n",
      "Offers GCE O' Level certificate via the Special/Express course\n",
      "Affiliated to:\n",
      "Ngee Ann Polytechnic (IDP)\n",
      "\n",
      "[107]\n",
      "\n",
      "\n",
      "School of the Arts\n",
      "IndependentSpecialised\n",
      "7802\n",
      "\n",
      "Dhoby Ghaut\n",
      "\n",
      "\n",
      "Admit students through DSA and/or Independent Intake\n",
      "Offers the International Baccalaureate certificate\n",
      "\n",
      "[108]\n",
      "\n",
      "\n",
      "Sembawang Secondary School\n",
      "Government\n",
      "3606\n",
      "Sembawang\n",
      "\n",
      "[109]\n",
      "\n",
      "\n",
      "Sengkang Secondary School\n",
      "Government\n",
      "3607\n",
      "Sengkang\n",
      "\n",
      "[110]\n",
      "\n",
      "\n",
      "Serangoon Garden Secondary School\n",
      "Government\n",
      "3509\n",
      "Serangoon\n",
      "\n",
      "[111]\n",
      "\n",
      "\n",
      "Serangoon Secondary School\n",
      "Government\n",
      "3010\n",
      "Hougang\n",
      "\n",
      "[112]\n",
      "\n",
      "\n",
      "Singapore Chinese Girls' School\n",
      "IndependentIP\n",
      "\n",
      "IP:9132Express:7014\n",
      "\n",
      "Novena\n",
      "\n",
      "Affiliated to:\n",
      "Eunoia Junior College (IP), CHIJ St Nicholas Girls' School (IP) & Catholic High School (IP)\n",
      "Singapore Chinese Girls' School (Primary)\n",
      "\n",
      "[113]\n",
      "\n",
      "\n",
      "Singapore Sports School\n",
      "IndependentSpecialised\n",
      "\n",
      "7800\n",
      "\n",
      "Woodlands\n",
      "\n",
      "\n",
      "Admit students through DSA and/or Independent Intake\n",
      "\n",
      "[114]\n",
      "\n",
      "\n",
      "Springfield Secondary School\n",
      "Government\n",
      "3053\n",
      "Tampines\n",
      "\n",
      "[115]\n",
      "\n",
      "\n",
      "St. Anthony's Canossian Secondary School\n",
      "Government-aidedAutonomous\n",
      "7016\n",
      "Bedok\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "Canossa Convent Primary School, St Anthony's Canossian Primary School\n",
      "\n",
      "[116]\n",
      "\n",
      "\n",
      "St. Gabriel's Secondary School\n",
      "Government-aided\n",
      "7017\n",
      "Serangoon\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "St. Gabriel's Primary School\n",
      "\n",
      "[117]\n",
      "\n",
      "\n",
      "St. Hilda's Secondary School\n",
      "Government-aided\n",
      "7029\n",
      "Tampines\n",
      "\n",
      "Affiliated to:\n",
      "St. Andrews Junior College (Non-IP)\n",
      "St. Hilda's Primary School\n",
      "\n",
      "[118]\n",
      "\n",
      "\n",
      "St. Margaret's Secondary School\n",
      "Government-aidedAutonomous\n",
      "7021\n",
      "Bukit Timah\n",
      "\n",
      "[119]\n",
      "\n",
      "\n",
      "St. Joseph's Institution\n",
      "IndependentIP\n",
      "\n",
      "IP:9141Express:7020\n",
      "\n",
      "Novena\n",
      "\n",
      "Affiliated to:\n",
      "Catholic Junior College (Non-IP)\n",
      "De la Salle School, St. Joseph's Institution Junior, St. Stephen's School, St. Anthony's Primary School\n",
      "\n",
      "[120]\n",
      "\n",
      "\n",
      "Swiss Cottage Secondary School\n",
      "Government\n",
      "3304\n",
      "Bukit Batok\n",
      "\n",
      "[121]\n",
      "\n",
      "\n",
      "Tanglin Secondary School\n",
      "Government\n",
      "3511\n",
      "Clementi\n",
      "\n",
      "[122]\n",
      "\n",
      "\n",
      "Tampines Secondary School\n",
      "Government\n",
      "3037\n",
      "Tampines\n",
      "\n",
      "[123]\n",
      "\n",
      "\n",
      "Tanjong Katong Girls' School\n",
      "GovernmentAutonomous\n",
      "3013\n",
      "Marine Parade\n",
      "\n",
      "[124]\n",
      "\n",
      "\n",
      "Tanjong Katong Secondary School\n",
      "GovernmentAutonomous\n",
      "3512\n",
      "Marine Parade\n",
      "\n",
      "[125]\n",
      "\n",
      "\n",
      "Temasek Junior College\n",
      "Government\n",
      "IP\n",
      "\n",
      "\n",
      "0702\n",
      "Bedok\n",
      "\n",
      "[126]\n",
      "\n",
      "\n",
      "Temasek Secondary School\n",
      "GovernmentAutonomous\n",
      "3030\n",
      "Bedok\n",
      "\n",
      "[127]\n",
      "\n",
      "\n",
      "Unity Secondary School\n",
      "Government\n",
      "3611\n",
      "Choa Chu Kang\n",
      "\n",
      "[128]\n",
      "\n",
      "\n",
      "Victoria School\n",
      "GovernmentAutonomousIP\n",
      "\n",
      "IP:9151Express:3014\n",
      "\n",
      "Marine Parade\n",
      "Affiliated to:\n",
      "Victoria Junior College (IP)\n",
      "Cedar Girls' Secondary School (IP)\n",
      "\n",
      "[129]\n",
      "\n",
      "\n",
      "West Spring Secondary School\n",
      "Government\n",
      "3067\n",
      "Bukit Panjang\n",
      "\n",
      "[130]\n",
      "\n",
      "\n",
      "Westwood Secondary School\n",
      "Government\n",
      "3620\n",
      "Jurong West\n",
      "\n",
      "[131]\n",
      "\n",
      "\n",
      "Whitley Secondary School\n",
      "Government\n",
      "3015\n",
      "Bishan\n",
      "\n",
      "[132]\n",
      "\n",
      "\n",
      "Woodgrove Secondary School\n",
      "Government\n",
      "3616\n",
      "Woodlands\n",
      "\n",
      "[133]\n",
      "\n",
      "\n",
      "Woodlands Ring Secondary School\n",
      "Government\n",
      "3604\n",
      "Woodlands\n",
      "\n",
      "[134]\n",
      "\n",
      "\n",
      "Woodlands Secondary School\n",
      "Government\n",
      "3041\n",
      "Woodlands\n",
      "\n",
      "[135]\n",
      "\n",
      "\n",
      "Xinmin Secondary School\n",
      "GovernmentAutonomous\n",
      "3050\n",
      "Hougang\n",
      "\n",
      "[136]\n",
      "\n",
      "\n",
      "Yio Chu Kang Secondary School\n",
      "Government\n",
      "3222\n",
      "Ang Mo Kio\n",
      "\n",
      "[137]\n",
      "\n",
      "\n",
      "Yishun Secondary School\n",
      "Government\n",
      "3020\n",
      "Yishun\n",
      "\n",
      "[138]\n",
      "\n",
      "\n",
      "Yishun Town Secondary School\n",
      "GovernmentAutonomous\n",
      "3045\n",
      "Yishun\n",
      "\n",
      "[139]\n",
      "\n",
      "\n",
      "Yuan Ching Secondary School\n",
      "Government\n",
      "3223\n",
      "Jurong West\n",
      "\n",
      "[140]\n",
      "\n",
      "\n",
      "Yuhua Secondary School\n",
      "Government\n",
      "3019\n",
      "Jurong West\n",
      "\n",
      "[141]\n",
      "\n",
      "\n",
      "Yusof Ishak Secondary School\n",
      "Government\n",
      "3307\n",
      "Punggol\n",
      "\n",
      "[142]\n",
      "\n",
      "\n",
      "Yuying Secondary School\n",
      "Government-aided\n",
      "7027\n",
      "Hougang\n",
      "\n",
      "[143]\n",
      "\n",
      "\n",
      "Zhenghua Secondary School\n",
      "Government\n",
      "3617\n",
      "Bukit Panjang\n",
      "\n",
      "[144]\n",
      "\n",
      "\n",
      "Zhonghua Secondary School\n",
      "GovernmentAutonomous\n",
      "3240\n",
      "Serangoon\n",
      "\n",
      "[145]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name\n",
      "\n",
      "Type\n",
      "\n",
      "Area\n",
      "\n",
      "Affiliated Denomination\n",
      "\n",
      "Notes\n",
      "\n",
      "Website\n",
      "\n",
      "\n",
      "San Yu Adventist School\n",
      "\n",
      "Private\n",
      "\n",
      "Novena\n",
      "\n",
      "Seventh-day Adventist Church\n",
      "\n",
      "\n",
      "\n",
      "[146]\n",
      "\n",
      "\n",
      "\n",
      "Name\n",
      "Type\n",
      "Area\n",
      "Notes\n",
      "Website\n",
      "\n",
      "\n",
      "Madrasah Aljunied Al-Islamiah\n",
      "Independent\n",
      "Rochor\n",
      "\n",
      "\n",
      "[147]\n",
      "\n",
      "\n",
      "Madrasah Irsyad Zuhri Al-Islamiah\n",
      "Independent\n",
      "Braddell\n",
      "\n",
      "[148]\n",
      "\n",
      "\n",
      "Madrasah Al-Arabiah Al-Islamiah\n",
      "Independent\n",
      "Toa Payoh\n",
      "\n",
      "[149]\n",
      "\n",
      "\n",
      "Madrasah Al-Maarif Al-Islamiah\n",
      "Independent\n",
      "Geylang\n",
      "\n",
      "[150]\n",
      "\n",
      "\n",
      "Madrasah Alsagoff Al-Arabiah\n",
      "Independent\n",
      "Rochor\n",
      "\n",
      "[151]\n",
      "\n",
      "\n",
      "Madrasah Wak Tanjong Al-Islamiah\n",
      "Independent\n",
      "Paya Lebar\n",
      "\n",
      "\n",
      "[152]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name\n",
      "Type\n",
      "Area\n",
      "Notes\n",
      "Website\n",
      "\n",
      "\n",
      "Crest Secondary School\n",
      "Government\n",
      "Jurong East\n",
      "\n",
      "[153]\n",
      "\n",
      "\n",
      "Spectra Secondary School\n",
      "Government\n",
      "Woodlands\n",
      "\n",
      "[154]\n",
      "\n",
      "\n",
      "vteEducation in SingaporeSchools\n",
      "Primary schools\n",
      "Secondary schools\n",
      "list\n",
      "Pre-University Centres\n",
      "Junior Colleges\n",
      "Centralised Institutes\n",
      "Institute of Technical Education\n",
      "Polytechnics\n",
      "Autonomous universities\n",
      "International schools\n",
      "Madrasahs\n",
      "Programmes\n",
      "Direct School Admission\n",
      "Edusave\n",
      "Gifted Education Programme\n",
      "Integrated Programme\n",
      "President's Scholar\n",
      "Programme for Rebuilding and Improving Existing schools\n",
      "Provisional Admission Exercise\n",
      "Special Assistance Plan\n",
      "Third Language\n",
      "Trim and Fit\n",
      "Examinations\n",
      "Singapore Examinations and Assessment Board\n",
      "Primary School Leaving Examination\n",
      "Singapore-Cambridge GCE N-Level\n",
      "Singapore-Cambridge GCE O-Level\n",
      " Singapore-Cambridge GCE A-Level\n",
      "International Baccalaureate\n",
      "Co-curriculars\n",
      "Co-curricular activity\n",
      "Singapore Youth Festival\n",
      "List of youth organisations\n",
      "Outward Bound Singapore\n",
      "Uniformed Groups\n",
      "Boys' Brigade\n",
      "Girl Guides Singapore\n",
      "Infocomm Club\n",
      "National Cadet Corps\n",
      "National Civil Defence Cadet Corps\n",
      "National Police Cadet Corps\n",
      "Red Cross Youth\n",
      "Singapore Scout Association\n",
      "St. John Ambulance Brigade\n",
      "\n",
      "Libraries\n",
      "National Library Board\n",
      "Others\n",
      "National Physical Fitness Award\n",
      "Ten year series\n",
      "\n",
      "Early Childhood Development Agency\n",
      "Ministry of Education\n",
      "\n",
      "Uniformed Groups\n",
      "Boys' Brigade\n",
      "Girl Guides Singapore\n",
      "Infocomm Club\n",
      "National Cadet Corps\n",
      "National Civil Defence Cadet Corps\n",
      "National Police Cadet Corps\n",
      "Red Cross Youth\n",
      "Singapore Scout Association\n",
      "St. John Ambulance Brigade\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in soup.find_all('table'):\n",
    "    print(a.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "4846a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of schools using Pandas read_html\n",
    "\n",
    "sschool_html = pd.read_html(\"List of secondary schools in Singapore - Wikipedia.html\")\n",
    "pschool_html = pd.read_html(\"List of primary schools in Singapore - Wikipedia.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d75d9de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Admiralty Secondary School\n",
       "1          Ahmad Ibrahim Secondary School\n",
       "2               Anderson Secondary School\n",
       "3                    Anglican High School\n",
       "4      Anglo-Chinese School (Barker Road)\n",
       "                      ...                \n",
       "140                Yuhua Secondary School\n",
       "141          Yusof Ishak Secondary School\n",
       "142               Yuying Secondary School\n",
       "143             Zhenghua Secondary School\n",
       "144             Zhonghua Secondary School\n",
       "Name: Name, Length: 145, dtype: object"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sschool_html[0]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b5a9afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_schools=sschool_html[0]['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "fc15139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Admiralty Secondary School',\n",
       " 'Ahmad Ibrahim Secondary School',\n",
       " 'Anderson Secondary School',\n",
       " 'Anglican High School',\n",
       " 'Anglo-Chinese School (Barker Road)',\n",
       " 'Anglo-Chinese School (Independent)',\n",
       " 'Ang Mo Kio Secondary School',\n",
       " 'Assumption English School',\n",
       " 'Bartley Secondary School',\n",
       " 'Beatty Secondary School',\n",
       " 'Bedok Green Secondary School',\n",
       " 'Bedok South Secondary School',\n",
       " 'Bedok View Secondary School',\n",
       " 'Bendemeer Secondary School',\n",
       " 'Boon Lay Secondary School',\n",
       " 'Bowen Secondary School',\n",
       " 'Broadrick Secondary School',\n",
       " 'Bukit Batok Secondary School',\n",
       " 'Bukit Merah Secondary School',\n",
       " 'Bukit Panjang Government High School',\n",
       " 'Bukit View Secondary School',\n",
       " 'Catholic High School',\n",
       " 'Canberra Secondary School',\n",
       " \"Cedar Girls' Secondary School\",\n",
       " 'Changkat Changi Secondary School',\n",
       " 'CHIJ Katong Convent (Secondary)',\n",
       " 'CHIJ Secondary (Toa Payoh)',\n",
       " \"CHIJ St. Joseph's Convent\",\n",
       " \"CHIJ St. Nicholas Girls' School\",\n",
       " \"CHIJ St. Theresa's Convent\",\n",
       " 'Chua Chu Kang Secondary School',\n",
       " 'Christ Church Secondary School',\n",
       " 'Chung Cheng High School (Main)',\n",
       " 'Chung Cheng High School (Yishun)',\n",
       " 'Clementi Town Secondary School',\n",
       " 'Commonwealth Secondary School',\n",
       " 'Compassvale Secondary School',\n",
       " \"Crescent Girls' School\",\n",
       " 'Damai Secondary School',\n",
       " 'Deyi Secondary School',\n",
       " 'Dunearn Secondary School',\n",
       " 'Dunman High School',\n",
       " 'Dunman Secondary School',\n",
       " 'East Spring Secondary School',\n",
       " 'Edgefield Secondary School',\n",
       " 'Evergreen Secondary School',\n",
       " 'Fairfield Methodist Secondary School',\n",
       " 'Fuchun Secondary School',\n",
       " 'Fuhua Secondary School',\n",
       " 'Gan Eng Seng School',\n",
       " 'Geylang Methodist School (Secondary)',\n",
       " 'Greendale Secondary School',\n",
       " 'Greenridge Secondary School',\n",
       " 'Guangyang Secondary School',\n",
       " 'Hai Sing Catholic School',\n",
       " 'Hillgrove Secondary School',\n",
       " \"Holy Innocents' High School\",\n",
       " 'Hougang Secondary School',\n",
       " 'Hua Yi Secondary School',\n",
       " 'Hwa Chong Institution',\n",
       " 'Junyuan Secondary School',\n",
       " 'Jurong Secondary School',\n",
       " 'Jurong West Secondary School',\n",
       " 'Jurongville Secondary School',\n",
       " 'Juying Secondary School',\n",
       " 'Kent Ridge Secondary School',\n",
       " 'Kranji Secondary School',\n",
       " 'Kuo Chuan Presbyterian Secondary School',\n",
       " 'Loyang View Secondary School',\n",
       " 'Manjusri Secondary School',\n",
       " 'Maris Stella High School',\n",
       " 'Marsiling Secondary School',\n",
       " 'Mayflower Secondary School',\n",
       " 'Meridian Secondary School',\n",
       " \"Methodist Girls' School (Secondary)\",\n",
       " 'Montfort Secondary School',\n",
       " 'Nan Chiau High School',\n",
       " 'Nan Hua High School',\n",
       " \"Nanyang Girls' High School\",\n",
       " 'National Junior College',\n",
       " 'Naval Base Secondary School',\n",
       " 'New Town Secondary School',\n",
       " 'Ngee Ann Secondary School',\n",
       " 'North Vista Secondary School',\n",
       " 'Northbrooks Secondary School',\n",
       " 'Northland Secondary School',\n",
       " 'NUS High School of Mathematics and Science',\n",
       " 'Orchid Park Secondary School',\n",
       " 'Outram Secondary School',\n",
       " 'Pasir Ris Crest Secondary School',\n",
       " 'Pasir Ris Secondary School',\n",
       " \"Paya Lebar Methodist Girls' School (Secondary)\",\n",
       " 'Pei Hwa Secondary School',\n",
       " 'Peicai Secondary School',\n",
       " 'Peirce Secondary School',\n",
       " 'Presbyterian High School',\n",
       " 'Punggol Secondary School',\n",
       " 'Queenstown Secondary School',\n",
       " 'Queensway Secondary School',\n",
       " \"Raffles Girls' School (Secondary)\",\n",
       " 'Raffles Institution',\n",
       " 'Regent Secondary School',\n",
       " 'Riverside Secondary School',\n",
       " 'River Valley High School',\n",
       " \"St. Andrew's Secondary School\",\n",
       " \"St. Patrick's School\",\n",
       " 'School of Science and Technology, Singapore',\n",
       " 'School of the Arts',\n",
       " 'Sembawang Secondary School',\n",
       " 'Sengkang Secondary School',\n",
       " 'Serangoon Garden Secondary School',\n",
       " 'Serangoon Secondary School',\n",
       " \"Singapore Chinese Girls' School\",\n",
       " 'Singapore Sports School',\n",
       " 'Springfield Secondary School',\n",
       " \"St. Anthony's Canossian Secondary School\",\n",
       " \"St. Gabriel's Secondary School\",\n",
       " \"St. Hilda's Secondary School\",\n",
       " \"St. Margaret's Secondary School\",\n",
       " \"St. Joseph's Institution\",\n",
       " 'Swiss Cottage Secondary School',\n",
       " 'Tanglin Secondary School',\n",
       " 'Tampines Secondary School',\n",
       " \"Tanjong Katong Girls' School\",\n",
       " 'Tanjong Katong Secondary School',\n",
       " 'Temasek Junior College',\n",
       " 'Temasek Secondary School',\n",
       " 'Unity Secondary School',\n",
       " 'Victoria School',\n",
       " 'West Spring Secondary School',\n",
       " 'Westwood Secondary School',\n",
       " 'Whitley Secondary School',\n",
       " 'Woodgrove Secondary School',\n",
       " 'Woodlands Ring Secondary School',\n",
       " 'Woodlands Secondary School',\n",
       " 'Xinmin Secondary School',\n",
       " 'Yio Chu Kang Secondary School',\n",
       " 'Yishun Secondary School',\n",
       " 'Yishun Town Secondary School',\n",
       " 'Yuan Ching Secondary School',\n",
       " 'Yuhua Secondary School',\n",
       " 'Yusof Ishak Secondary School',\n",
       " 'Yuying Secondary School',\n",
       " 'Zhenghua Secondary School',\n",
       " 'Zhonghua Secondary School']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "74a2fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Funding</th>\n",
       "      <th>Type</th>\n",
       "      <th>Area[3]</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Website</th>\n",
       "      <th>School Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admiralty Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmad Ibrahim Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Yishun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ai Tong School</td>\n",
       "      <td>Government-aided, SAP</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>Affiliated to Singapore Hokkien Huay Kuan[4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexandra Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Bukit Merah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4]</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anchor Green Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Sengkang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5]</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Yuhua Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Jurong East</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[180]</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Yumin Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[181]</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Zhangde Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Bukit Merah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[182]</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Zhenghua Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[183]</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Zhonghua Primary School</td>\n",
       "      <td>Government</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Serangoon</td>\n",
       "      <td>Used to be South Serangoon Gardens Primary School</td>\n",
       "      <td>[184]</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name                Funding   Type  \\\n",
       "0        Admiralty Primary School             Government  Mixed   \n",
       "1    Ahmad Ibrahim Primary School             Government  Mixed   \n",
       "2                  Ai Tong School  Government-aided, SAP  Mixed   \n",
       "3        Alexandra Primary School             Government  Mixed   \n",
       "4     Anchor Green Primary School             Government  Mixed   \n",
       "..                            ...                    ...    ...   \n",
       "180          Yuhua Primary School             Government  Mixed   \n",
       "181          Yumin Primary School             Government  Mixed   \n",
       "182        Zhangde Primary School             Government  Mixed   \n",
       "183       Zhenghua Primary School             Government  Mixed   \n",
       "184       Zhonghua Primary School             Government  Mixed   \n",
       "\n",
       "           Area[3]                                              Notes Website  \\\n",
       "0        Woodlands                                                NaN     [1]   \n",
       "1           Yishun                                                NaN     [2]   \n",
       "2           Bishan       Affiliated to Singapore Hokkien Huay Kuan[4]     [3]   \n",
       "3      Bukit Merah                                                NaN     [4]   \n",
       "4         Sengkang                                                NaN     [5]   \n",
       "..             ...                                                ...     ...   \n",
       "180    Jurong East                                                NaN   [180]   \n",
       "181       Tampines                                                NaN   [181]   \n",
       "182    Bukit Merah                                                NaN   [182]   \n",
       "183  Bukit Panjang                                                NaN   [183]   \n",
       "184      Serangoon  Used to be South Serangoon Gardens Primary School   [184]   \n",
       "\n",
       "     School Code  \n",
       "0           1744  \n",
       "1           1738  \n",
       "2           5625  \n",
       "3           1266  \n",
       "4           1254  \n",
       "..           ...  \n",
       "180         1656  \n",
       "181         1219  \n",
       "182         1199  \n",
       "183         1240  \n",
       "184         1235  \n",
       "\n",
       "[185 rows x 7 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pschool_html[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "691c996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_schools=pschool_html[1]['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9fe6d330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Admiralty Primary School',\n",
       " 'Ahmad Ibrahim Primary School',\n",
       " 'Ai Tong School',\n",
       " 'Alexandra Primary School',\n",
       " 'Anchor Green Primary School',\n",
       " 'Anderson Primary School',\n",
       " 'Anglo-Chinese School (Junior)',\n",
       " 'Anglo-Chinese School (Primary)',\n",
       " 'Angsana Primary School',\n",
       " 'Ang Mo Kio Primary School',\n",
       " 'Beacon Primary School',\n",
       " 'Bedok Green Primary School',\n",
       " 'Bendemeer Primary School',\n",
       " 'Blangah Rise Primary School',\n",
       " 'Boon Lay Garden Primary School',\n",
       " 'Bukit Panjang Primary School',\n",
       " 'Bukit Timah Primary School',\n",
       " 'Bukit View Primary School',\n",
       " 'Canberra Primary School',\n",
       " 'Canossa Catholic Primary School',\n",
       " 'Cantonment Primary School',\n",
       " 'Casuarina Primary School',\n",
       " 'Catholic High School (Primary)',\n",
       " 'Cedar Primary School',\n",
       " 'Changkat Primary School',\n",
       " 'CHIJ (Katong) Primary',\n",
       " 'CHIJ (Kellock)',\n",
       " 'CHIJ Our Lady of Good Counsel',\n",
       " 'CHIJ Our Lady of the Nativity',\n",
       " 'CHIJ Our Lady Queen of Peace',\n",
       " 'CHIJ Primary (Toa Payoh)',\n",
       " \"CHIJ St. Nicholas Girls' School (Primary Section)\",\n",
       " 'Chongfu School',\n",
       " 'Chongzheng Primary School',\n",
       " 'Chua Chu Kang Primary School',\n",
       " 'Clementi Primary School',\n",
       " 'Compassvale Primary School',\n",
       " 'Concord Primary School',\n",
       " 'Coral Primary School',\n",
       " 'Corporation Primary School',\n",
       " 'Da Qiao Primary School',\n",
       " 'Damai Primary School',\n",
       " 'Dazhong Primary School',\n",
       " 'De La Salle School',\n",
       " 'East Coast Primary School',\n",
       " 'East Spring Primary School',\n",
       " 'East View Primary School',\n",
       " 'Edgefield Primary School',\n",
       " 'Elias Park Primary School',\n",
       " 'Endeavour Primary School',\n",
       " 'Evergreen Primary School',\n",
       " 'Fairfield Methodist School (Primary)',\n",
       " 'Farrer Park Primary School',\n",
       " 'Fengshan Primary School',\n",
       " 'Fernvale Primary School',\n",
       " 'First Toa Payoh Primary School',\n",
       " 'Frontier Primary School',\n",
       " 'Fuchun Primary School',\n",
       " 'Fuhua Primary School',\n",
       " 'Gan Eng Seng Primary School',\n",
       " 'Geylang Methodist School (Primary)',\n",
       " 'Gongshang Primary School',\n",
       " 'Greendale Primary School',\n",
       " 'Greenridge Primary School',\n",
       " 'Greenwood Primary School',\n",
       " \"Haig Girls' School\",\n",
       " \"Holy Innocents' Primary School\",\n",
       " 'Henry Park Primary School',\n",
       " 'Hong Wen School',\n",
       " 'Horizon Primary School',\n",
       " 'Hougang Primary School',\n",
       " 'Huamin Primary School',\n",
       " 'Innova Primary School',\n",
       " 'Jiemin Primary School',\n",
       " 'Jing Shan Primary School\\xa0[zh]',\n",
       " 'Junyuan Primary School',\n",
       " 'Jurong Primary School',\n",
       " 'Jurong West Primary School',\n",
       " 'Juying Primary School',\n",
       " 'Keming Primary School',\n",
       " 'Kheng Cheng School',\n",
       " 'Kong Hwa School',\n",
       " 'Kranji Primary School',\n",
       " 'Kuo Chuan Presbyterian Primary School',\n",
       " 'Lakeside Primary School',\n",
       " 'Lianhua Primary School',\n",
       " 'Maha Bodhi School',\n",
       " 'Maris Stella High School (Primary Section)',\n",
       " 'Marsiling Primary School',\n",
       " 'Marymount Convent School',\n",
       " 'Mayflower Primary School',\n",
       " 'Mee Toh School',\n",
       " 'Meridian Primary School',\n",
       " \"Methodist Girls' School (Primary)\",\n",
       " 'Montfort Junior School',\n",
       " 'Nan Chiau Primary School',\n",
       " 'Nan Hua Primary School',\n",
       " 'Nanyang Primary School',\n",
       " 'Ngee Ann Primary School',\n",
       " 'Naval Base Primary School',\n",
       " 'New Town Primary School',\n",
       " 'Northland Primary School',\n",
       " 'Northoaks Primary School',\n",
       " 'North Spring Primary School',\n",
       " 'North View Primary School',\n",
       " 'North Vista Primary School',\n",
       " 'Oasis Primary School',\n",
       " 'Opera Estate Primary School',\n",
       " 'Palm View Primary School',\n",
       " 'Park View Primary School',\n",
       " 'Pasir Ris Primary School',\n",
       " \"Paya Lebar Methodist Girls' School (Primary)\",\n",
       " 'Pei Chun Public School',\n",
       " 'Pei Hwa Presbyterian Primary School',\n",
       " 'Pei Tong Primary School',\n",
       " 'Peiying Primary School',\n",
       " 'Pioneer Primary School',\n",
       " 'Poi Ching School',\n",
       " 'Princess Elizabeth Primary School',\n",
       " 'Punggol Cove Primary School',\n",
       " 'Punggol Green Primary School',\n",
       " 'Punggol Primary School',\n",
       " 'Punggol View Primary School',\n",
       " 'Qifa Primary School',\n",
       " 'Qihua Primary School',\n",
       " 'Queenstown Primary School',\n",
       " 'Radin Mas Primary School',\n",
       " \"Raffles Girls' Primary School\",\n",
       " 'Red Swastika School',\n",
       " 'Riverside Primary School',\n",
       " 'River Valley Primary School',\n",
       " 'Rivervale Primary School',\n",
       " 'Rosyth School',\n",
       " 'Rulang Primary School',\n",
       " 'Sengkang Green Primary School',\n",
       " 'Sembawang Primary School',\n",
       " 'Si Ling Primary School',\n",
       " 'Seng Kang Primary School',\n",
       " 'Shuqun Primary School',\n",
       " 'Singapore Chinese Girls’ School (Primary)',\n",
       " 'South View Primary School',\n",
       " 'Springdale Primary School',\n",
       " \"St. Andrew's Junior School\",\n",
       " \"St. Anthony's Canossian Primary School\",\n",
       " \"St. Anthony's Primary School\",\n",
       " \"St. Gabriel's Primary School\",\n",
       " \"St. Hilda's Primary School\",\n",
       " \"St. Joseph's Institution Junior\",\n",
       " \"St. Margaret's Primary School\",\n",
       " \"St. Stephen's School\",\n",
       " 'Tampines North Primary School',\n",
       " 'Tampines Primary School',\n",
       " 'Tanjong Katong Primary School',\n",
       " 'Tao Nan School',\n",
       " 'Teck Ghee Primary School',\n",
       " 'Teck Whye Primary School',\n",
       " 'Telok Kurau Primary School',\n",
       " 'Temasek Primary School',\n",
       " 'Townsville Primary School',\n",
       " 'Unity Primary School',\n",
       " 'Valour Primary School',\n",
       " 'Waterway Primary School',\n",
       " 'Wellington Primary School',\n",
       " 'West Grove Primary School',\n",
       " 'West Spring Primary School',\n",
       " 'Westwood Primary School',\n",
       " 'West View Primary School',\n",
       " 'White Sands Primary School',\n",
       " 'Woodgrove Primary School',\n",
       " 'Woodlands Primary School',\n",
       " 'Woodlands Ring Primary School',\n",
       " 'Xinghua Primary School',\n",
       " 'Xingnan Primary School',\n",
       " 'Xinmin Primary School',\n",
       " 'Xishan Primary School',\n",
       " 'Yangzheng Primary School',\n",
       " 'Yew Tee Primary School',\n",
       " 'Yio Chu Kang Primary School',\n",
       " 'Yishun Primary School',\n",
       " 'Yu Neng Primary School',\n",
       " 'Yuhua Primary School',\n",
       " 'Yumin Primary School',\n",
       " 'Zhangde Primary School',\n",
       " 'Zhenghua Primary School',\n",
       " 'Zhonghua Primary School']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prim_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5cc9222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schools = prim_schools+sec_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "209c7cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Admiralty Primary School',\n",
       " 'Ahmad Ibrahim Primary School',\n",
       " 'Ai Tong School',\n",
       " 'Alexandra Primary School',\n",
       " 'Anchor Green Primary School',\n",
       " 'Anderson Primary School',\n",
       " 'Anglo-Chinese School (Junior)',\n",
       " 'Anglo-Chinese School (Primary)',\n",
       " 'Angsana Primary School',\n",
       " 'Ang Mo Kio Primary School',\n",
       " 'Beacon Primary School',\n",
       " 'Bedok Green Primary School',\n",
       " 'Bendemeer Primary School',\n",
       " 'Blangah Rise Primary School',\n",
       " 'Boon Lay Garden Primary School',\n",
       " 'Bukit Panjang Primary School',\n",
       " 'Bukit Timah Primary School',\n",
       " 'Bukit View Primary School',\n",
       " 'Canberra Primary School',\n",
       " 'Canossa Catholic Primary School',\n",
       " 'Cantonment Primary School',\n",
       " 'Casuarina Primary School',\n",
       " 'Catholic High School (Primary)',\n",
       " 'Cedar Primary School',\n",
       " 'Changkat Primary School',\n",
       " 'CHIJ (Katong) Primary',\n",
       " 'CHIJ (Kellock)',\n",
       " 'CHIJ Our Lady of Good Counsel',\n",
       " 'CHIJ Our Lady of the Nativity',\n",
       " 'CHIJ Our Lady Queen of Peace',\n",
       " 'CHIJ Primary (Toa Payoh)',\n",
       " \"CHIJ St. Nicholas Girls' School (Primary Section)\",\n",
       " 'Chongfu School',\n",
       " 'Chongzheng Primary School',\n",
       " 'Chua Chu Kang Primary School',\n",
       " 'Clementi Primary School',\n",
       " 'Compassvale Primary School',\n",
       " 'Concord Primary School',\n",
       " 'Coral Primary School',\n",
       " 'Corporation Primary School',\n",
       " 'Da Qiao Primary School',\n",
       " 'Damai Primary School',\n",
       " 'Dazhong Primary School',\n",
       " 'De La Salle School',\n",
       " 'East Coast Primary School',\n",
       " 'East Spring Primary School',\n",
       " 'East View Primary School',\n",
       " 'Edgefield Primary School',\n",
       " 'Elias Park Primary School',\n",
       " 'Endeavour Primary School',\n",
       " 'Evergreen Primary School',\n",
       " 'Fairfield Methodist School (Primary)',\n",
       " 'Farrer Park Primary School',\n",
       " 'Fengshan Primary School',\n",
       " 'Fernvale Primary School',\n",
       " 'First Toa Payoh Primary School',\n",
       " 'Frontier Primary School',\n",
       " 'Fuchun Primary School',\n",
       " 'Fuhua Primary School',\n",
       " 'Gan Eng Seng Primary School',\n",
       " 'Geylang Methodist School (Primary)',\n",
       " 'Gongshang Primary School',\n",
       " 'Greendale Primary School',\n",
       " 'Greenridge Primary School',\n",
       " 'Greenwood Primary School',\n",
       " \"Haig Girls' School\",\n",
       " \"Holy Innocents' Primary School\",\n",
       " 'Henry Park Primary School',\n",
       " 'Hong Wen School',\n",
       " 'Horizon Primary School',\n",
       " 'Hougang Primary School',\n",
       " 'Huamin Primary School',\n",
       " 'Innova Primary School',\n",
       " 'Jiemin Primary School',\n",
       " 'Jing Shan Primary School\\xa0[zh]',\n",
       " 'Junyuan Primary School',\n",
       " 'Jurong Primary School',\n",
       " 'Jurong West Primary School',\n",
       " 'Juying Primary School',\n",
       " 'Keming Primary School',\n",
       " 'Kheng Cheng School',\n",
       " 'Kong Hwa School',\n",
       " 'Kranji Primary School',\n",
       " 'Kuo Chuan Presbyterian Primary School',\n",
       " 'Lakeside Primary School',\n",
       " 'Lianhua Primary School',\n",
       " 'Maha Bodhi School',\n",
       " 'Maris Stella High School (Primary Section)',\n",
       " 'Marsiling Primary School',\n",
       " 'Marymount Convent School',\n",
       " 'Mayflower Primary School',\n",
       " 'Mee Toh School',\n",
       " 'Meridian Primary School',\n",
       " \"Methodist Girls' School (Primary)\",\n",
       " 'Montfort Junior School',\n",
       " 'Nan Chiau Primary School',\n",
       " 'Nan Hua Primary School',\n",
       " 'Nanyang Primary School',\n",
       " 'Ngee Ann Primary School',\n",
       " 'Naval Base Primary School',\n",
       " 'New Town Primary School',\n",
       " 'Northland Primary School',\n",
       " 'Northoaks Primary School',\n",
       " 'North Spring Primary School',\n",
       " 'North View Primary School',\n",
       " 'North Vista Primary School',\n",
       " 'Oasis Primary School',\n",
       " 'Opera Estate Primary School',\n",
       " 'Palm View Primary School',\n",
       " 'Park View Primary School',\n",
       " 'Pasir Ris Primary School',\n",
       " \"Paya Lebar Methodist Girls' School (Primary)\",\n",
       " 'Pei Chun Public School',\n",
       " 'Pei Hwa Presbyterian Primary School',\n",
       " 'Pei Tong Primary School',\n",
       " 'Peiying Primary School',\n",
       " 'Pioneer Primary School',\n",
       " 'Poi Ching School',\n",
       " 'Princess Elizabeth Primary School',\n",
       " 'Punggol Cove Primary School',\n",
       " 'Punggol Green Primary School',\n",
       " 'Punggol Primary School',\n",
       " 'Punggol View Primary School',\n",
       " 'Qifa Primary School',\n",
       " 'Qihua Primary School',\n",
       " 'Queenstown Primary School',\n",
       " 'Radin Mas Primary School',\n",
       " \"Raffles Girls' Primary School\",\n",
       " 'Red Swastika School',\n",
       " 'Riverside Primary School',\n",
       " 'River Valley Primary School',\n",
       " 'Rivervale Primary School',\n",
       " 'Rosyth School',\n",
       " 'Rulang Primary School',\n",
       " 'Sengkang Green Primary School',\n",
       " 'Sembawang Primary School',\n",
       " 'Si Ling Primary School',\n",
       " 'Seng Kang Primary School',\n",
       " 'Shuqun Primary School',\n",
       " 'Singapore Chinese Girls’ School (Primary)',\n",
       " 'South View Primary School',\n",
       " 'Springdale Primary School',\n",
       " \"St. Andrew's Junior School\",\n",
       " \"St. Anthony's Canossian Primary School\",\n",
       " \"St. Anthony's Primary School\",\n",
       " \"St. Gabriel's Primary School\",\n",
       " \"St. Hilda's Primary School\",\n",
       " \"St. Joseph's Institution Junior\",\n",
       " \"St. Margaret's Primary School\",\n",
       " \"St. Stephen's School\",\n",
       " 'Tampines North Primary School',\n",
       " 'Tampines Primary School',\n",
       " 'Tanjong Katong Primary School',\n",
       " 'Tao Nan School',\n",
       " 'Teck Ghee Primary School',\n",
       " 'Teck Whye Primary School',\n",
       " 'Telok Kurau Primary School',\n",
       " 'Temasek Primary School',\n",
       " 'Townsville Primary School',\n",
       " 'Unity Primary School',\n",
       " 'Valour Primary School',\n",
       " 'Waterway Primary School',\n",
       " 'Wellington Primary School',\n",
       " 'West Grove Primary School',\n",
       " 'West Spring Primary School',\n",
       " 'Westwood Primary School',\n",
       " 'West View Primary School',\n",
       " 'White Sands Primary School',\n",
       " 'Woodgrove Primary School',\n",
       " 'Woodlands Primary School',\n",
       " 'Woodlands Ring Primary School',\n",
       " 'Xinghua Primary School',\n",
       " 'Xingnan Primary School',\n",
       " 'Xinmin Primary School',\n",
       " 'Xishan Primary School',\n",
       " 'Yangzheng Primary School',\n",
       " 'Yew Tee Primary School',\n",
       " 'Yio Chu Kang Primary School',\n",
       " 'Yishun Primary School',\n",
       " 'Yu Neng Primary School',\n",
       " 'Yuhua Primary School',\n",
       " 'Yumin Primary School',\n",
       " 'Zhangde Primary School',\n",
       " 'Zhenghua Primary School',\n",
       " 'Zhonghua Primary School',\n",
       " 'Admiralty Secondary School',\n",
       " 'Ahmad Ibrahim Secondary School',\n",
       " 'Anderson Secondary School',\n",
       " 'Anglican High School',\n",
       " 'Anglo-Chinese School (Barker Road)',\n",
       " 'Anglo-Chinese School (Independent)',\n",
       " 'Ang Mo Kio Secondary School',\n",
       " 'Assumption English School',\n",
       " 'Bartley Secondary School',\n",
       " 'Beatty Secondary School',\n",
       " 'Bedok Green Secondary School',\n",
       " 'Bedok South Secondary School',\n",
       " 'Bedok View Secondary School',\n",
       " 'Bendemeer Secondary School',\n",
       " 'Boon Lay Secondary School',\n",
       " 'Bowen Secondary School',\n",
       " 'Broadrick Secondary School',\n",
       " 'Bukit Batok Secondary School',\n",
       " 'Bukit Merah Secondary School',\n",
       " 'Bukit Panjang Government High School',\n",
       " 'Bukit View Secondary School',\n",
       " 'Catholic High School',\n",
       " 'Canberra Secondary School',\n",
       " \"Cedar Girls' Secondary School\",\n",
       " 'Changkat Changi Secondary School',\n",
       " 'CHIJ Katong Convent (Secondary)',\n",
       " 'CHIJ Secondary (Toa Payoh)',\n",
       " \"CHIJ St. Joseph's Convent\",\n",
       " \"CHIJ St. Nicholas Girls' School\",\n",
       " \"CHIJ St. Theresa's Convent\",\n",
       " 'Chua Chu Kang Secondary School',\n",
       " 'Christ Church Secondary School',\n",
       " 'Chung Cheng High School (Main)',\n",
       " 'Chung Cheng High School (Yishun)',\n",
       " 'Clementi Town Secondary School',\n",
       " 'Commonwealth Secondary School',\n",
       " 'Compassvale Secondary School',\n",
       " \"Crescent Girls' School\",\n",
       " 'Damai Secondary School',\n",
       " 'Deyi Secondary School',\n",
       " 'Dunearn Secondary School',\n",
       " 'Dunman High School',\n",
       " 'Dunman Secondary School',\n",
       " 'East Spring Secondary School',\n",
       " 'Edgefield Secondary School',\n",
       " 'Evergreen Secondary School',\n",
       " 'Fairfield Methodist Secondary School',\n",
       " 'Fuchun Secondary School',\n",
       " 'Fuhua Secondary School',\n",
       " 'Gan Eng Seng School',\n",
       " 'Geylang Methodist School (Secondary)',\n",
       " 'Greendale Secondary School',\n",
       " 'Greenridge Secondary School',\n",
       " 'Guangyang Secondary School',\n",
       " 'Hai Sing Catholic School',\n",
       " 'Hillgrove Secondary School',\n",
       " \"Holy Innocents' High School\",\n",
       " 'Hougang Secondary School',\n",
       " 'Hua Yi Secondary School',\n",
       " 'Hwa Chong Institution',\n",
       " 'Junyuan Secondary School',\n",
       " 'Jurong Secondary School',\n",
       " 'Jurong West Secondary School',\n",
       " 'Jurongville Secondary School',\n",
       " 'Juying Secondary School',\n",
       " 'Kent Ridge Secondary School',\n",
       " 'Kranji Secondary School',\n",
       " 'Kuo Chuan Presbyterian Secondary School',\n",
       " 'Loyang View Secondary School',\n",
       " 'Manjusri Secondary School',\n",
       " 'Maris Stella High School',\n",
       " 'Marsiling Secondary School',\n",
       " 'Mayflower Secondary School',\n",
       " 'Meridian Secondary School',\n",
       " \"Methodist Girls' School (Secondary)\",\n",
       " 'Montfort Secondary School',\n",
       " 'Nan Chiau High School',\n",
       " 'Nan Hua High School',\n",
       " \"Nanyang Girls' High School\",\n",
       " 'National Junior College',\n",
       " 'Naval Base Secondary School',\n",
       " 'New Town Secondary School',\n",
       " 'Ngee Ann Secondary School',\n",
       " 'North Vista Secondary School',\n",
       " 'Northbrooks Secondary School',\n",
       " 'Northland Secondary School',\n",
       " 'NUS High School of Mathematics and Science',\n",
       " 'Orchid Park Secondary School',\n",
       " 'Outram Secondary School',\n",
       " 'Pasir Ris Crest Secondary School',\n",
       " 'Pasir Ris Secondary School',\n",
       " \"Paya Lebar Methodist Girls' School (Secondary)\",\n",
       " 'Pei Hwa Secondary School',\n",
       " 'Peicai Secondary School',\n",
       " 'Peirce Secondary School',\n",
       " 'Presbyterian High School',\n",
       " 'Punggol Secondary School',\n",
       " 'Queenstown Secondary School',\n",
       " 'Queensway Secondary School',\n",
       " \"Raffles Girls' School (Secondary)\",\n",
       " 'Raffles Institution',\n",
       " 'Regent Secondary School',\n",
       " 'Riverside Secondary School',\n",
       " 'River Valley High School',\n",
       " \"St. Andrew's Secondary School\",\n",
       " \"St. Patrick's School\",\n",
       " 'School of Science and Technology, Singapore',\n",
       " 'School of the Arts',\n",
       " 'Sembawang Secondary School',\n",
       " 'Sengkang Secondary School',\n",
       " 'Serangoon Garden Secondary School',\n",
       " 'Serangoon Secondary School',\n",
       " \"Singapore Chinese Girls' School\",\n",
       " 'Singapore Sports School',\n",
       " 'Springfield Secondary School',\n",
       " \"St. Anthony's Canossian Secondary School\",\n",
       " \"St. Gabriel's Secondary School\",\n",
       " \"St. Hilda's Secondary School\",\n",
       " \"St. Margaret's Secondary School\",\n",
       " \"St. Joseph's Institution\",\n",
       " 'Swiss Cottage Secondary School',\n",
       " 'Tanglin Secondary School',\n",
       " 'Tampines Secondary School',\n",
       " \"Tanjong Katong Girls' School\",\n",
       " 'Tanjong Katong Secondary School',\n",
       " 'Temasek Junior College',\n",
       " 'Temasek Secondary School',\n",
       " 'Unity Secondary School',\n",
       " 'Victoria School',\n",
       " 'West Spring Secondary School',\n",
       " 'Westwood Secondary School',\n",
       " 'Whitley Secondary School',\n",
       " 'Woodgrove Secondary School',\n",
       " 'Woodlands Ring Secondary School',\n",
       " 'Woodlands Secondary School',\n",
       " 'Xinmin Secondary School',\n",
       " 'Yio Chu Kang Secondary School',\n",
       " 'Yishun Secondary School',\n",
       " 'Yishun Town Secondary School',\n",
       " 'Yuan Ching Secondary School',\n",
       " 'Yuhua Secondary School',\n",
       " 'Yusof Ishak Secondary School',\n",
       " 'Yuying Secondary School',\n",
       " 'Zhenghua Secondary School',\n",
       " 'Zhonghua Secondary School']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de916a96",
   "metadata": {},
   "source": [
    "# Test scannning of directory files and opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3206c91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of '<DirEntry 'Session 13_5-6_2-end.pdf'>'\n",
      "Content of '<DirEntry 'Session 13_5-6_1-1.pdf'>'\n"
     ]
    }
   ],
   "source": [
    "# Test scan of directory files and opening\n",
    "\n",
    "directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6_1-1/\"\n",
    " \n",
    "# Iterate over files in directory\n",
    "for filename in os.scandir(directory):\n",
    "    # Open file\n",
    "    with open(os.path.join(directory, filename)) as f:\n",
    "        print(f\"Content of '{filename}'\")    \n",
    "    \n",
    "    with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "        page = pdf.pages[0]\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()\n",
    "\n",
    "\n",
    "    splitted=text.splitlines()\n",
    "\n",
    "    splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f793bf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Audited List',\n",
       " 'Event: S13-03 4 X 400m Relay - B DIVISION GIRLS Heats',\n",
       " 'Schools National Record Singapore Sports School SSP (ET)04:01.98s 2011',\n",
       " 'Championships Record Singapore Sports School SSP (ET)04:01.98s 2011',\n",
       " 'POS Competitor Q Tag Team Heat Ln Result Pts W/G Remarks NR',\n",
       " '1 SINGAPORE SPORTS SCHOOL Q 720 SSP h3 3 04:23.41',\n",
       " \"2 NANYANG GIRLS' HIGH Q 1022 NYGH h3 6 04:24.02\",\n",
       " 'SCHOOL',\n",
       " \"3 CRESCENT GIRLS' SCHOOL Q 791 CGS h3 2 04:24.09\",\n",
       " \"4 CEDAR GIRLS' SECONDARY Q 871 CG h2 4 04:25.16\",\n",
       " 'SCHOOL',\n",
       " \"5 CHIJ ST. NICHOLAS GIRLS' Q 656 SNG h2 5 04:30.99\",\n",
       " 'SCHOOL (SECONDARY)',\n",
       " '6 NATIONAL JUNIOR COLLEGE Q 810 NJC h2 8 04:32.69',\n",
       " '7 DUNMAN HIGH SCHOOL Q 930 DHS h2 2 04:37.82',\n",
       " '8 CHIJ SECONDARY (TOA PAYOH) Q 747 HIJ h3 5 04:39.52',\n",
       " \"9 RAFFLES GIRLS' SCHOOL Q 845 RGS h2 1 04:40.60\",\n",
       " '(SECONDARY)',\n",
       " '10 AHMAD IBRAHIM SECONDARY 648 AIS h1 6 04:43.48',\n",
       " 'SCHOOL',\n",
       " '11 PAYA LEBAR METHODIST 953 PLMGS h3 1 04:48.28',\n",
       " \"GIRLS' SCHOOL (SECONDARY)\",\n",
       " '12 NORTH VISTA SECONDARY 707 NV h1 2 04:49.01',\n",
       " 'SCHOOL',\n",
       " '13 SCHOOL OF SCIENCE AND 1062 SST h1 5 04:49.82',\n",
       " 'TECHNOLOGY, SINGAPORE',\n",
       " '14 TANJONG KATONG SECONDARY 981 TK h1 3 04:49.85',\n",
       " 'SCHOOL',\n",
       " \"15 CHIJ ST. THERESA'S CONVENT 764 STC h1 4 04:52.53\",\n",
       " \"16 ST. ANTHONY'S CANOSSIAN 966 SAC h2 6 04:55.13\",\n",
       " 'SECONDARY SCHOOL',\n",
       " '17 TEMASEK SECONDARY SCHOOL 989 TMS h3 7 05:03.64',\n",
       " '18 NAN CHIAU HIGH SCHOOL 697 NCH h1 7 05:11.33',\n",
       " '19 UNITY SECONDARY SCHOOL 1069 US h2 3 05:12.55',\n",
       " '20 ADMIRALTY SECONDARY 641 ADSS h2 7 05:13.20',\n",
       " 'SCHOOL',\n",
       " '21 CHIJ KATONG CONVENT 910 KC h1 1 05:23.53',\n",
       " '22 WOODLANDS SECONDARY 737 WDL h1 8 05:43.18',\n",
       " 'SCHOOL /']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5d10b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_directory(directory):\n",
    "    items = os.listdir(directory)\n",
    "    sorted_items = sorted(items)\n",
    "    return sorted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a72de1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Session 13_5-6_1-1.pdf', 'Session 13_5-6_2-end.pdf']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test open all files in directory\n",
    "\n",
    "def sort_directory(directory):\n",
    "    items = os.listdir(directory)\n",
    "    sorted_items = sorted(items)\n",
    "    return sorted_items\n",
    "\n",
    "\n",
    "directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022PDF/\"\n",
    " \n",
    "# Iterate over files in directory\n",
    "\n",
    "sorted_items=sort_directory(directory)\n",
    "\n",
    "print(sorted_items)\n",
    "\n",
    "sorted_items.pop(0)\n",
    "\n",
    "master_df=pd.DataFrame()  # initialize empty master df\n",
    "\n",
    "for file in sorted_items:\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    temp = pd.read_csv(file)\n",
    "    \n",
    "    master_df=pd.concat([master_df, temp], axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4af6498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01-01_TO_11_deconstructed.pdf\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'S01-01_TO_11_deconstructed.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m sorted_items:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpdfplumber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m     21\u001b[0m         page \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mpages[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# can iterate over different pages\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         table\u001b[38;5;241m=\u001b[39mpage\u001b[38;5;241m.\u001b[39mextract_table()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pdfplumber/pdf.py:85\u001b[0m, in \u001b[0;36mPDF.open\u001b[0;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, repair, gs_path)\u001b[0m\n\u001b[1;32m     83\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m---> 85\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'S01-01_TO_11_deconstructed.pdf'"
     ]
    }
   ],
   "source": [
    "# This is the starting point. Need 'extraction' and 'new_format_parser' functons.\n",
    "# Test scan of directory with multiple files and opening \n",
    "\n",
    "\n",
    "#os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6_1-1/')\n",
    "\n",
    "directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/Deconstructed/\"\n",
    " \n",
    "# Iterate over files in directory\n",
    "\n",
    "sorted_items=sort_directory(directory)\n",
    "\n",
    "master_df=pd.DataFrame()  # initialize empty master df\n",
    "\n",
    "for file in sorted_items:\n",
    "    \n",
    "    print(file)\n",
    "\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "        page = pdf.pages[0]  # can iterate over different pages\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()\n",
    "\n",
    "\n",
    "    splitted=text.splitlines() # if more than one page should append the two 'splitted' files before extraction\n",
    "            \n",
    "    master_df=extraction(splitted, master_df)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b82b5342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 BUKIT VIEW SECONDARY 999 BTV h3 4 05:51.77', 'SCHOOL', '/']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7e6ba88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Q</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Team</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Ln</th>\n",
       "      <th>Result</th>\n",
       "      <th>Pts</th>\n",
       "      <th>W/G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SINGAPORE SPORTS SCHOOL</td>\n",
       "      <td>Q</td>\n",
       "      <td>720</td>\n",
       "      <td>SSP</td>\n",
       "      <td>h3</td>\n",
       "      <td>3</td>\n",
       "      <td>04:23.41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NANYANG GIRLS' HIGH SCHOOL</td>\n",
       "      <td>Q</td>\n",
       "      <td>1022</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>h3</td>\n",
       "      <td>6</td>\n",
       "      <td>04:24.02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CRESCENT GIRLS' SCHOOL</td>\n",
       "      <td>Q</td>\n",
       "      <td>791</td>\n",
       "      <td>CGS</td>\n",
       "      <td>h3</td>\n",
       "      <td>2</td>\n",
       "      <td>04:24.09</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CEDAR GIRLS' SECONDARY SCHOOL</td>\n",
       "      <td>Q</td>\n",
       "      <td>871</td>\n",
       "      <td>CG</td>\n",
       "      <td>h2</td>\n",
       "      <td>4</td>\n",
       "      <td>04:25.16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CHIJ ST. NICHOLAS GIRLS' SCHOOL (SECONDARY)</td>\n",
       "      <td>Q</td>\n",
       "      <td>656</td>\n",
       "      <td>SNG</td>\n",
       "      <td>h2</td>\n",
       "      <td>5</td>\n",
       "      <td>04:30.99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NATIONAL JUNIOR COLLEGE</td>\n",
       "      <td>Q</td>\n",
       "      <td>810</td>\n",
       "      <td>NJC</td>\n",
       "      <td>h2</td>\n",
       "      <td>8</td>\n",
       "      <td>04:32.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>DUNMAN HIGH SCHOOL</td>\n",
       "      <td>Q</td>\n",
       "      <td>930</td>\n",
       "      <td>DHS</td>\n",
       "      <td>h2</td>\n",
       "      <td>2</td>\n",
       "      <td>04:37.82</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>CHIJ SECONDARY (TOA PAYOH)</td>\n",
       "      <td>Q</td>\n",
       "      <td>747</td>\n",
       "      <td>HIJ</td>\n",
       "      <td>h3</td>\n",
       "      <td>5</td>\n",
       "      <td>04:39.52</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>RAFFLES GIRLS' SCHOOL (SECONDARY)</td>\n",
       "      <td>Q</td>\n",
       "      <td>845</td>\n",
       "      <td>RGS</td>\n",
       "      <td>h2</td>\n",
       "      <td>1</td>\n",
       "      <td>04:40.60</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>AHMAD IBRAHIM SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>648</td>\n",
       "      <td>AIS</td>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>04:43.48</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>PAYA LEBAR METHODIST GIRLS' SCHOOL (SECONDARY)</td>\n",
       "      <td></td>\n",
       "      <td>953</td>\n",
       "      <td>PLMGS</td>\n",
       "      <td>h3</td>\n",
       "      <td>1</td>\n",
       "      <td>04:48.28</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>NORTH VISTA SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>707</td>\n",
       "      <td>NV</td>\n",
       "      <td>h1</td>\n",
       "      <td>2</td>\n",
       "      <td>04:49.01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>SCHOOL OF SCIENCE AND TECHNOLOGY, SINGAPORE</td>\n",
       "      <td></td>\n",
       "      <td>1062</td>\n",
       "      <td>SST</td>\n",
       "      <td>h1</td>\n",
       "      <td>5</td>\n",
       "      <td>04:49.82</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>TANJONG KATONG SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>981</td>\n",
       "      <td>TK</td>\n",
       "      <td>h1</td>\n",
       "      <td>3</td>\n",
       "      <td>04:49.85</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>CHIJ ST. THERESA'S CONVENT</td>\n",
       "      <td></td>\n",
       "      <td>764</td>\n",
       "      <td>STC</td>\n",
       "      <td>h1</td>\n",
       "      <td>4</td>\n",
       "      <td>04:52.53</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>ST. ANTHONY'S CANOSSIAN SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>966</td>\n",
       "      <td>SAC</td>\n",
       "      <td>h2</td>\n",
       "      <td>6</td>\n",
       "      <td>04:55.13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>TEMASEK SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>989</td>\n",
       "      <td>TMS</td>\n",
       "      <td>h3</td>\n",
       "      <td>7</td>\n",
       "      <td>05:03.64</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>NAN CHIAU HIGH SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>697</td>\n",
       "      <td>NCH</td>\n",
       "      <td>h1</td>\n",
       "      <td>7</td>\n",
       "      <td>05:11.33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>UNITY SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>1069</td>\n",
       "      <td>US</td>\n",
       "      <td>h2</td>\n",
       "      <td>3</td>\n",
       "      <td>05:12.55</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>ADMIRALTY SECONDARY SCHOOL</td>\n",
       "      <td></td>\n",
       "      <td>641</td>\n",
       "      <td>ADSS</td>\n",
       "      <td>h2</td>\n",
       "      <td>7</td>\n",
       "      <td>05:13.20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>CHIJ KATONG CONVENT</td>\n",
       "      <td></td>\n",
       "      <td>910</td>\n",
       "      <td>KC</td>\n",
       "      <td>h1</td>\n",
       "      <td>1</td>\n",
       "      <td>05:23.53</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>WOODLANDS SECONDARY SCHOOL /</td>\n",
       "      <td></td>\n",
       "      <td>737</td>\n",
       "      <td>WDL</td>\n",
       "      <td>h1</td>\n",
       "      <td>8</td>\n",
       "      <td>05:43.18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>BUKIT VIEW SECONDARY SCHOOL/</td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>BTV</td>\n",
       "      <td>h3</td>\n",
       "      <td>4</td>\n",
       "      <td>05:51.77</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS                                      Competitor   Q    Tag    Team  \\\n",
       "0    1                        SINGAPORE SPORTS SCHOOL    Q    720     SSP   \n",
       "1    2                      NANYANG GIRLS' HIGH SCHOOL   Q   1022    NYGH   \n",
       "2    3                         CRESCENT GIRLS' SCHOOL    Q    791     CGS   \n",
       "3    4                   CEDAR GIRLS' SECONDARY SCHOOL   Q    871      CG   \n",
       "4    5     CHIJ ST. NICHOLAS GIRLS' SCHOOL (SECONDARY)   Q    656     SNG   \n",
       "5    6                        NATIONAL JUNIOR COLLEGE    Q    810     NJC   \n",
       "6    7                             DUNMAN HIGH SCHOOL    Q    930     DHS   \n",
       "7    8                     CHIJ SECONDARY (TOA PAYOH)    Q    747     HIJ   \n",
       "8    9               RAFFLES GIRLS' SCHOOL (SECONDARY)   Q    845     RGS   \n",
       "9   10                  AHMAD IBRAHIM SECONDARY SCHOOL        648     AIS   \n",
       "10  11  PAYA LEBAR METHODIST GIRLS' SCHOOL (SECONDARY)        953   PLMGS   \n",
       "11  12                    NORTH VISTA SECONDARY SCHOOL        707      NV   \n",
       "12  13     SCHOOL OF SCIENCE AND TECHNOLOGY, SINGAPORE       1062     SST   \n",
       "13  14                 TANJONG KATONG SECONDARY SCHOOL        981      TK   \n",
       "14  15                     CHIJ ST. THERESA'S CONVENT         764     STC   \n",
       "15  16        ST. ANTHONY'S CANOSSIAN SECONDARY SCHOOL        966     SAC   \n",
       "16  17                       TEMASEK SECONDARY SCHOOL         989     TMS   \n",
       "17  18                          NAN CHIAU HIGH SCHOOL         697     NCH   \n",
       "18  19                         UNITY SECONDARY SCHOOL        1069      US   \n",
       "19  20                      ADMIRALTY SECONDARY SCHOOL        641    ADSS   \n",
       "20  21                            CHIJ KATONG CONVENT         910      KC   \n",
       "21  22                    WOODLANDS SECONDARY SCHOOL /        737     WDL   \n",
       "0   23                    BUKIT VIEW SECONDARY SCHOOL/        999     BTV   \n",
       "\n",
       "   Heat  Ln     Result Pts W/G  \n",
       "0    h3   3   04:23.41          \n",
       "1    h3   6   04:24.02          \n",
       "2    h3   2   04:24.09          \n",
       "3    h2   4   04:25.16          \n",
       "4    h2   5   04:30.99          \n",
       "5    h2   8   04:32.69          \n",
       "6    h2   2   04:37.82          \n",
       "7    h3   5   04:39.52          \n",
       "8    h2   1   04:40.60          \n",
       "9    h1   6   04:43.48          \n",
       "10   h3   1   04:48.28          \n",
       "11   h1   2   04:49.01          \n",
       "12   h1   5   04:49.82          \n",
       "13   h1   3   04:49.85          \n",
       "14   h1   4   04:52.53          \n",
       "15   h2   6   04:55.13          \n",
       "16   h3   7   05:03.64          \n",
       "17   h1   7   05:11.33          \n",
       "18   h2   3   05:12.55          \n",
       "19   h2   7   05:13.20          \n",
       "20   h1   1   05:23.53          \n",
       "21   h1   8   05:43.18          \n",
       "0    h3   4   05:51.77          "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ac9b0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do:\n",
    "# 1. code old_format_parser function for old format pdfs\n",
    "# 2. Test iteration over several pages using pdf.pages[0]\n",
    "# 3. Modify code to iterate over second stranded page and add data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c5cce",
   "metadata": {},
   "source": [
    "# Extract 2024 NSG PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39066d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session 02-01\n",
      "session 02-02\n",
      "session 02-03\n",
      "session 02-04\n",
      "session 02-05\n",
      "session 02-06\n",
      "session 02-07\n",
      "session 02-07\n",
      "session 02-07\n",
      "session 02-08\n",
      "session 02-08\n",
      "session 02-09\n",
      "session 02-09\n",
      "session 02-10\n",
      "session 02-10\n",
      "session 02-11\n",
      "session 02-11\n",
      "session 02-11\n",
      "session 02-12\n",
      "session 02-12\n"
     ]
    }
   ],
   "source": [
    "# ONLY For 2024 NSG pdfs--latest version\n",
    "#\n",
    "# New schema\n",
    "#df_filtered = df_filtered.reindex(columns= ['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION', 'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', \n",
    "#                                      'POINTS', 'AGE', 'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'DATE', 'COMPETITION', 'REGION', 'DOB','GROUP', 'CATEGORY_EVENT', \n",
    "#                                      'ATHLETE_ID', 'SOURCE', 'REMARKS', 'TIMESTAMP', 'VENUE', 'DATE', 'SUB_EVENT', 'SESSION', 'EVENT_CLASS', 'RX_TIME'])\n",
    "\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024PDF/sectrack_result_02p.pdf\"\n",
    "\n",
    " \n",
    "# Iterate over files in directory\n",
    "\n",
    "#sorted_items=sort_directory(directory)\n",
    "\n",
    "new_pattern='\\d\\s.{5,40}?\\s(Q|q|\\d)'\n",
    "    \n",
    "old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "#event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "event_pattern='(\\:\\s.{5,32})\\sT'\n",
    "\n",
    "final_pattern = '.{4,30}\\('\n",
    "\n",
    "\n",
    "school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "year_pattern='\\d\\d\\d\\d'\n",
    "\n",
    "session_pattern='\\d\\d\\-\\d\\d'\n",
    "\n",
    "div_pattern='([A-Z]\\-Boys)|([A-Z]\\-Girls)'\n",
    "\n",
    "wind_pattern='(H[0-9])\\s\\:\\s(\\+\\d\\.\\d|\\-\\d\\.\\d)'\n",
    "\n",
    "event_mapping={'100m': 'Sprint', '100m': 'Sprint'}    \n",
    "\n",
    "\n",
    "df_table=pd.DataFrame()  # initialize empty master df\n",
    "\n",
    "df=None\n",
    "\n",
    "\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "        \n",
    "        \n",
    "    for i in range(len(pdf.pages)):    \n",
    "        \n",
    "        page = pdf.pages[i]  # can iterate over different pages\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()        \n",
    "        \n",
    "        df=pd.DataFrame(text.splitlines())\n",
    "        \n",
    "                        \n",
    "        for index, row in df.iterrows(): # find row containing event details and column names\n",
    "                \n",
    "        \n",
    "            if 'Event' in row[0]:\n",
    "            \n",
    "                details=row[0]\n",
    "                                                \n",
    "                if 'BOYS' in details or 'Boys' in details:\n",
    "                    gender='Male'\n",
    "                \n",
    "                if 'GIRLS' in details or 'Girls' in details:\n",
    "                    gender='Female'    \n",
    "                \n",
    "                # Slice event name. Must be done in 2 stages.   \n",
    "                \n",
    "                \n",
    "                epos = re.search(event_pattern, details)  \n",
    "                                \n",
    "                        \n",
    "                split_end=epos.end()-1      # adjust the splicing position to capture the event + division\n",
    "                split_start=epos.start()+1\n",
    "    \n",
    "                event=details[split_start:split_end]\n",
    "                \n",
    "                pos=re.search(final_pattern, event)  # new\n",
    "            \n",
    "                final_end=pos.end()-1      # new\n",
    "                final_start=pos.start()+1  # new\n",
    "                \n",
    "                final_match=event[final_start:final_end] # finally extract event name\n",
    "                \n",
    "                session_list=re.findall(session_pattern, details)\n",
    "                \n",
    "                session=session_list[0]\n",
    "                \n",
    "                print('session', session)\n",
    "                \n",
    "                \n",
    "                \n",
    "            # Assign high level event type\n",
    "                \n",
    "                if 'Throw' in final_match:\n",
    "                    category_event='Throw'\n",
    "                elif 'Jump' in final_match:\n",
    "                    category_event='Jump'\n",
    "                elif 'Vault' in final_match:\n",
    "                    category_event='Jump'\n",
    "                elif '100' in final_match:\n",
    "                    category_event='Sprint'\n",
    "                elif '1500' in final_match:\n",
    "                    category_event='Mid'\n",
    "                elif 'Javelin' in final_match:\n",
    "                    category_event='Throw'\n",
    "                elif 'Shot' in final_match:\n",
    "                    category_event='Throw'\n",
    "                elif '400' in final_match:\n",
    "                    category_event='Sprint'\n",
    "                elif '800' in final_match:\n",
    "                    category_event='Mid'\n",
    "                elif '400' in final_match:\n",
    "                    category_event='Sprint'\n",
    "                elif 'Hurdles' in final_match:\n",
    "                    category_event='Hurdles'\n",
    "                elif '200' in final_match:\n",
    "                    category_event='Sprint'\n",
    "                elif 'Walk' in final_match:\n",
    "                    category_event='Walk'\n",
    "                elif '3000' in final_match:\n",
    "                    category_event='Long'\n",
    "                elif '5000' in final_match:\n",
    "                    category_event='Long'\n",
    "                elif '2000' in final_match:\n",
    "                    category_event='Mid'\n",
    "                elif 'Discus' in final_match:\n",
    "                    category_event='Throw'\n",
    "                \n",
    "                if 'Relay' in final_match: # Change from Sprint to Relay for relays only\n",
    "                    category_event='Relay'\n",
    "\n",
    "               \n",
    "                # Slice division\n",
    "        \n",
    "                divpos = re.search(div_pattern, details)\n",
    "                            \n",
    "                s_pos=divpos.start()\n",
    "                e_pos=divpos.start()+1\n",
    "    \n",
    "                div=details[s_pos:e_pos] # extract division        \n",
    "                                      \n",
    "            \n",
    "            if 'Competitor' in row[0]: # extract column names\n",
    "            \n",
    "                row_index=index  # where the header row is\n",
    "                columns=df.iloc[row_index,0]\n",
    "                names=columns.split(' ')\n",
    "                \n",
    "            if 'Final' in row[0]:\n",
    "                \n",
    "                stage=\"Final\"\n",
    "                \n",
    "            if 'Heat' in row[0]:\n",
    "                \n",
    "                stage='Heats'\n",
    "                \n",
    "            if 'SF' in row[0]:\n",
    "                \n",
    "                stage = 'SF'    \n",
    "                \n",
    "                               \n",
    "            if 'W/Gauge' in row[0]:\n",
    "                \n",
    "                details=row[0]            \n",
    "                \n",
    "                try:\n",
    "            \n",
    "                    wind=re.findall(wind_pattern, details)\n",
    "                                    \n",
    "                    wind_dict = {}\n",
    "                    \n",
    "                    for key, val in wind: # create dictionary of extracted wind data\n",
    "                        wind_dict.setdefault(key, val)\n",
    "                \n",
    "                except:\n",
    "                    \n",
    "                    pass\n",
    "            \n",
    "                    \n",
    "        temp=pd.DataFrame(table)\n",
    "        \n",
    "                            \n",
    "                \n",
    "        temp.iloc[2:,:]  # drop first 2 rows\n",
    "\n",
    "        temp['EVENT'] = final_match\n",
    "        temp['GENDER'] = gender\n",
    "        temp['DIVISION'] = div\n",
    "        temp['STAGE'] = stage\n",
    "        temp['COMPETITION'] = 'NSG'\n",
    "        temp['REGION'] = 'Local'\n",
    "        temp['CATEGORY_EVENT'] = category_event\n",
    "        temp['test'] = 'H'+temp[5].map(str) # create a new temp field to map across wind\n",
    "        temp['SOURCE'] = 'https://nsg.moe.edu.sg/results'       \n",
    "        temp['YEAR'] = '2024'\n",
    "        temp['QUALIFICATION']=''\n",
    "        temp['POINTS']=''\n",
    "        temp['UNIQUE_ID']=''\n",
    "        temp['COUNTRY']=''\n",
    "        temp['DICT_RESULTS']=''\n",
    "        temp['DOB']=''\n",
    "        temp['GROUP']=''\n",
    "        temp['ATHLETE_ID']=''\n",
    "        temp['TIMESTAMP']=''\n",
    "        temp['VENUE']=''\n",
    "        temp['DATE']=session\n",
    "        temp['SUB_EVENT']=''   # event=decathlon, sub_event=shot put\n",
    "        temp['SESSION']=''\n",
    "        temp['EVENT_CLASS']=''   # weight height category for javelin, high jump etc.\n",
    "        temp['RX_TIME']=''\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# need to add 'VENUE', 'DATE', 'SUB_EVENT', 'SESSION', 'EVENT_CLASS', 'RX_TIME' for new updated schema        \n",
    "        \n",
    "        \n",
    "        temp['WIND']=temp['test'].map(wind_dict) # map temp field across to wind data     \n",
    "        \n",
    "        \n",
    "        temp = temp[temp[0].str.contains(\"~~~ End of Listing ~~~\") == False]  # drop useless rows\n",
    "        temp = temp[temp[0].str.contains(\"W/Gauge :\") == False]\n",
    "        temp = temp[temp[0].str.contains(\"Pos\") == False]\n",
    "     #   temp = temp[temp[7].str.contains(\"DNS|NM|DQ|DNF\") == False] # drop rows without results\n",
    "        \n",
    "            \n",
    "        df_table=pd.concat([df_table, temp], axis=0)\n",
    "         \n",
    "        \n",
    "\n",
    "\n",
    "df_table.rename(\n",
    "    columns={0: \"RANK\", 1: \"TAG_ID\", 2: \"NAME\", 3: \"TEAM\", 4: \"RESULT\", 5: \"HEAT\", 6: \"LANE\", 7: \"REMARKS\"},\n",
    "    inplace=True,\n",
    ")\n",
    "        \n",
    "df_table.drop('test', axis=1, inplace=True)    # drop temp columns used to map wind data   \n",
    "\n",
    "df_table = df_table.reindex(columns= ['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION', 'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', \n",
    "                                      'POINTS', 'AGE', 'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'DATE', 'COMPETITION', 'REGION', 'DOB','GROUP', 'CATEGORY_EVENT', \n",
    "                                      'ATHLETE_ID', 'SOURCE', 'REMARKS', 'TIMESTAMP', 'VENUE', 'DATE', 'SUB_EVENT', 'SESSION', 'EVENT_CLASS', 'RX_TIME'])\n",
    "\n",
    "# Map NM/DNS/DQ/DNF to results column                            \n",
    "                            \n",
    "mask = df_table['REMARKS'].str.contains(r'NM', na=True)\n",
    "df_table.loc[mask, 'RESULT'] = 'NM'\n",
    "\n",
    "mask = df_table['REMARKS'].str.contains(r'DNS', na=True)\n",
    "df_table.loc[mask, 'RESULT'] = 'DNS'\n",
    "                            \n",
    "mask = df_table['REMARKS'].str.contains(r'DQ', na=True)\n",
    "df_table.loc[mask, 'RESULT'] = 'DQ'\n",
    "\n",
    "mask = df_table['REMARKS'].str.contains(r'DNF', na=True)\n",
    "df_table.loc[mask, 'RESULT'] = 'DNF'\n",
    "                            \n",
    "                            \n",
    "\n",
    "df_table.to_csv('sectrack_result_01p.csv', sep=',', index=False, encoding='utf-8')\n",
    "        \n",
    "\n",
    "            \n",
    "                       \n",
    "                       \n",
    "\n",
    "        \n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a90fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>QUALIFICATION</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>WIND</th>\n",
       "      <th>...</th>\n",
       "      <th>DOB</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>CATEGORY_EVENT</th>\n",
       "      <th>ATHLETE_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>REACT_TIME</th>\n",
       "      <th>SESSION</th>\n",
       "      <th>FREE_FIELD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>Tan Shou Yi Rei (Chen Shouyi)</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.66</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Raffles Institution</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>879</td>\n",
       "      <td>Tang Kai Sheng, Cayman</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.15</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Victoria School</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>Lau Jia Hern</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.86</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Raffles Institution</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>881</td>\n",
       "      <td>Telukula Sourendra</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.59</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Victoria School</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>757</td>\n",
       "      <td>Low Ming Dao, Jase</td>\n",
       "      <td>SSP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.32</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Singapore Sports School</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>398</td>\n",
       "      <td>Reuben Chiang</td>\n",
       "      <td>TMJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:19.65</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Tampines Meridian Junior</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>232</td>\n",
       "      <td>Peh Kang Shen Javis</td>\n",
       "      <td>EJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:32.01</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Eunoia Junior College</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>296</td>\n",
       "      <td>Velranjan S/O Krishnasamy</td>\n",
       "      <td>MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:42.40</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Millennia Institute</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>226</td>\n",
       "      <td>Lim Yi Da Alvis</td>\n",
       "      <td>EJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:56.75</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>Eunoia Junior College</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>316</td>\n",
       "      <td>Tan E-Jie</td>\n",
       "      <td>NUSHS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06:07.05</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td></td>\n",
       "      <td>https://nsg.moe.edu.sg/results</td>\n",
       "      <td>NUS High School</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>02-12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK TAG_ID                           NAME   TEAM  SEED    RESULT  \\\n",
       "2     1    662  Tan Shou Yi Rei (Chen Shouyi)     RI   NaN     13.66   \n",
       "3     2    879         Tang Kai Sheng, Cayman     VS   NaN     13.15   \n",
       "4     3    642                   Lau Jia Hern     RI   NaN     12.86   \n",
       "5     4    881             Telukula Sourendra     VS   NaN     12.59   \n",
       "6     5    757             Low Ming Dao, Jase    SSP   NaN     12.32   \n",
       "..  ...    ...                            ...    ...   ...       ...   \n",
       "39   38    398                  Reuben Chiang   TMJC   NaN  05:19.65   \n",
       "40   39    232            Peh Kang Shen Javis    EJC   NaN  05:32.01   \n",
       "41   40    296      Velranjan S/O Krishnasamy     MI   NaN  05:42.40   \n",
       "42   41    226                Lim Yi Da Alvis    EJC   NaN  05:56.75   \n",
       "1    42    316                      Tan E-Jie  NUSHS   NaN  06:07.05   \n",
       "\n",
       "   QUALIFICATION HEAT LANE  WIND  ... DOB GROUP CATEGORY_EVENT ATHLETE_ID  \\\n",
       "2                   2    9   NaN  ...                     Jump              \n",
       "3                   1    4   NaN  ...                     Jump              \n",
       "4                   1   11   NaN  ...                     Jump              \n",
       "5                   2    4   NaN  ...                     Jump              \n",
       "6                   1    8   NaN  ...                     Jump              \n",
       "..           ...  ...  ...   ...  ...  ..   ...            ...        ...   \n",
       "39                  2    7   NaN  ...                      Mid              \n",
       "40                  1   13   NaN  ...                      Mid              \n",
       "41                  2    6   NaN  ...                      Mid              \n",
       "42                  3    3   NaN  ...                      Mid              \n",
       "1                   3    1   NaN  ...                      Mid              \n",
       "\n",
       "                            SOURCE                   REMARKS TIMESTAMP  \\\n",
       "2   https://nsg.moe.edu.sg/results       Raffles Institution             \n",
       "3   https://nsg.moe.edu.sg/results           Victoria School             \n",
       "4   https://nsg.moe.edu.sg/results       Raffles Institution             \n",
       "5   https://nsg.moe.edu.sg/results           Victoria School             \n",
       "6   https://nsg.moe.edu.sg/results   Singapore Sports School             \n",
       "..                             ...                       ...       ...   \n",
       "39  https://nsg.moe.edu.sg/results  Tampines Meridian Junior             \n",
       "40  https://nsg.moe.edu.sg/results     Eunoia Junior College             \n",
       "41  https://nsg.moe.edu.sg/results       Millennia Institute             \n",
       "42  https://nsg.moe.edu.sg/results     Eunoia Junior College             \n",
       "1   https://nsg.moe.edu.sg/results           NUS High School             \n",
       "\n",
       "   REACT_TIME SESSION FREE_FIELD3  \n",
       "2               02-01              \n",
       "3               02-01              \n",
       "4               02-01              \n",
       "5               02-01              \n",
       "6               02-01              \n",
       "..        ...     ...         ...  \n",
       "39              02-12              \n",
       "40              02-12              \n",
       "41              02-12              \n",
       "42              02-12              \n",
       "1               02-12              \n",
       "\n",
       "[592 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef6099",
   "metadata": {},
   "source": [
    "# Production Code for 2022/23 PDFs - Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88806ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(table, master_df):  # latest version to process 2023/22. takes stitchesd list from multiple paged pdfs\n",
    "\n",
    "    global index, row_index\n",
    "        \n",
    "        \n",
    "    # Regex patterns to extract competitor names, event name etc.\n",
    "    \n",
    "    #new_pattern='\\d\\s.{5,20}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='\\d\\s[A-Z\\s\\,]{5,30}\\s\\d' # look for text between two numbers or Q/q\n",
    "    \n",
    "    #new_pattern='^[A-Z\\s]*$'\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Q|q|\\d)'\n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "    \n",
    "    session_pattern='S\\d\\d\\-\\d\\d|S\\d\\d[A-Z]\\-\\d\\d|S\\dl-\\d\\d|SO\\d\\-\\d\\d|SOl-\\d\\d'\n",
    "    \n",
    "    division_pattern='DIVISION'\n",
    "\n",
    "    \n",
    "    event = None\n",
    "    \n",
    "    names = None\n",
    "    \n",
    "    gender = None\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # Put extracted info from pdf into a df and extract event information\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "    \n",
    "    columns=[]\n",
    "    \n",
    "        \n",
    "    for index, row in df.iterrows(): # find row containing event details and column names\n",
    "                \n",
    "        \n",
    "        if 'Event' in row[0]:\n",
    "            \n",
    "            row_string=row[0]\n",
    "            \n",
    "            print('row string', row_string)\n",
    "                                    \n",
    "            epos = re.search(event_pattern, row_string)\n",
    "                        \n",
    "            split_end=epos.end()-1      # adjust the splicing position to only capture the event name\n",
    "            split_start=epos.start()+1\n",
    "\n",
    "            event=row_string[split_start:split_end]\n",
    "            \n",
    "            print('event', event)\n",
    "                                    \n",
    "            \n",
    "            if 'BOYS' in row_string or 'Boys' in row_string:\n",
    "                gender='Male'\n",
    "                \n",
    "            if 'GIRLS' in row_string or 'Girls' in row_string:\n",
    "                gender='Female'    \n",
    "                \n",
    "            \n",
    "            if 'Finals' in row_string:\n",
    "                round='Finals'\n",
    "            \n",
    "            region='Local'    \n",
    "            \n",
    "            session_list=re.findall(session_pattern, row_string)\n",
    "            \n",
    "            print('session list', session_list)\n",
    "                \n",
    "            session=session_list[0]\n",
    "                \n",
    "            print('session', session)\n",
    "            \n",
    "            event_final = re.sub(session, '', event)     # remove session from string         \n",
    "            \n",
    "            division_pos=re.search(division_pattern, row_string)\n",
    "            \n",
    "            s_end=division_pos.start()      # adjust the splicing position to only capture the division\n",
    "            s_start=division_pos.start()-2\n",
    "\n",
    "            division=row_string[s_start:s_end]\n",
    "            \n",
    "            print('division', division)\n",
    "\n",
    "            print('gender', gender)\n",
    "     \n",
    "        \n",
    "            \n",
    "        if 'Competitor' in row[0]: # extract column names\n",
    "            \n",
    "            row_index=index\n",
    "            columns=df.iloc[row_index,0]\n",
    "            names=columns.split(' ')\n",
    "            \n",
    " #           names[-1]='SESSION'  # change NR column to SESSION column\n",
    "                        \n",
    "    \n",
    "#    if (event and names) is None:  # if it is a stranded page (no header) that is cutoff from the main pdf\n",
    "                                # Change this code to add iteration over pages. Just append splitted 2nd page.\n",
    "                                \n",
    "#            temp_df = master_df.iloc[:0]  # initiate empty df and copy column names\n",
    "                                    \n",
    "#            row_index=0   # if no header \n",
    "            \n",
    "#            names = None  # retrieve master df and append instead\n",
    "            \n",
    "#            print('here')\n",
    "            \n",
    "#            print(table)\n",
    "                                            \n",
    "#            temp_df=new_format_parser(row_index, names, table, master_df) # need to concat master_df and temp df\n",
    "            \n",
    "#            print('reached this 3rd point for a stranded pdf')\n",
    "            \n",
    "#            master_df= pd.concat([master_df, temp_df])  # this concat is not working as temp_df is empty\n",
    "                    \n",
    "#            return master_df # exit function\n",
    "\n",
    "            \n",
    "    \n",
    "    # Check pdf format and begin extraction of results\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'W/G' not in columns:  # if older pdf format without a 'W/G column'\n",
    "            \n",
    "        df2 = pd.DataFrame(columns=names)        \n",
    "    \n",
    "        new_df = df2.iloc[:, :-2]    # remove Remarks and N/R columns\n",
    "         \n",
    "        for i in range(row_index+1,(len(df)-1)):                    \n",
    "            \n",
    "            if not re.search('^\\d', table[i]): # skip row if disqualified or withdrawn (does not begin with a digit)\n",
    "            \n",
    "                continue\n",
    "       \n",
    "            string=table[i]\n",
    "                                \n",
    "            lpos = re.search('\\s', string)\n",
    "                #rpos = re.search('\\sQ\\s', s)\n",
    "                #rpos = re.search('\\s[A-Z]{2,4}', s)\n",
    "            \n",
    "            matches=re.findall(school_pattern, string)  # find how many uppercase shortforms for school\n",
    "                                \n",
    "            if len(matches)==2:\n",
    "                \n",
    "                rpos=re.search(matches[1], string) # choose second match if there are two \n",
    "                    \n",
    "            else:\n",
    "                    \n",
    "                rpos = re.search(old_pattern, string)\n",
    "                \n",
    "            \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            \n",
    "            l = string[:lpos.start()] # left string post splicing\n",
    "            r = string[rpos.start():] # right string post slicing\n",
    "         \n",
    "            name=string[lpos.start():rpos.start()] # extract competitor name\n",
    "                                \n",
    "            list=r.split(' ')   # split the parts after the name    \n",
    "            \n",
    "            combined=l+ ',' + name + ', '.join(list)\n",
    "\n",
    "            row=combined.split(\",\")\n",
    "                        \n",
    "                        \n",
    "            if ('W/G' not in names) and len(row)!=6:  # if W/G not in list of columns\n",
    "            \n",
    "                n=len(row)-6\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "            \n",
    "            elif ('W/G' in names) and len(row)>8:\n",
    "            \n",
    "                n=len(row)-8\n",
    "                row = row[: len(row) - n]  # delete last n elements from list to makt it 6 columns  \n",
    "                                        \n",
    "            new_df.loc[len(new_df)] = row\n",
    "            \n",
    "            \n",
    "        return new_df\n",
    "            \n",
    "    elif 'W/G' in columns: # new format     \n",
    "            \n",
    "        master_df=new_format_parser(row_index, names, table, master_df) # call parser function\n",
    "        \n",
    "        master_df['Session']=session   # add session  NEW\n",
    "        master_df['Division']=division # add division NEW\n",
    "        master_df['Event']=event_final # add event NEW\n",
    "        master_df['Gender']=gender # add event NEW\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##        master_df= pd.concat([temp_df, master_df])\n",
    "        \n",
    "#        print(master_df)\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c7a1fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newest version to ingest 2022 PDFs\n",
    "# Almost complete except for some formatting effects\n",
    "# Called by 'extraction' function\n",
    "\n",
    "def new_format_parser(row_index, names, table, master_df):\n",
    "    \n",
    "                \n",
    "    # Define regex patterns\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Qfy|Q\\s|q\\s|\\d)'\n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "    \n",
    "    Q_pattern = '\\sQ'\n",
    "    \n",
    "\n",
    "    \n",
    "    stranded = \"no\"  # flag for stranded pdf pages\n",
    "    \n",
    "    NM_pattern = '\\bNM'  # No Mark\n",
    "    \n",
    " #   ex_pattern = 'NONE'  # Essentially no exlusions\n",
    "\n",
    "    \n",
    "    tag_pattern = '\\d\\d|\\d\\d\\d'\n",
    "    \n",
    "    gap_pattern = ':\\s\\d'\n",
    "        \n",
    "    # Put table that has been processed into a dataframe\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "                \n",
    "    columns=[]\n",
    "    \n",
    "    list=[]\n",
    "                \n",
    "    \n",
    "    # Initialize new df and remove unnecessary columns\n",
    "    \n",
    "    if row_index!=0 and names is not None: # check that its coming from not a stranded pdf with no header i.e. new pdf\n",
    "                    \n",
    "        df2 = pd.DataFrame(columns=names) \n",
    "        \n",
    "    \n",
    "        #new_df = df2.iloc[:, :-2]    # remove 'Remarks' and 'NR' columns\n",
    "        \n",
    "        new_df = df2    # retain 'REMARKS' and 'NR' columns\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('reached this first point for a stranded pdf')\n",
    "        \n",
    "        stranded=\"yes\"\n",
    "        \n",
    "        new_df = master_df.iloc[:0] # new_df columns to come from the master df\n",
    "        \n",
    "        row_index=-1  # move back row_index for a stranded pdf\n",
    "        \n",
    "    \n",
    "#    for i in range(row_index+1,(len(df)-1)):  # iterate over df - only stranded pdf should start from zero. Previous code - revert to original  \n",
    "\n",
    "\n",
    "#  check for stranded pdfs with stranded names\n",
    "\n",
    "    for i in range(row_index+1,(len(df))):  # iterate over df - only stranded pdf should start from index zero    \n",
    "    \n",
    "        print('table[i]', table[i])\n",
    "        \n",
    "        print('LOOK', re.search('^\\d', table[i]), re.search(NM_pattern, table[i]))\n",
    "\n",
    "                                            \n",
    "        \n",
    "        if not re.search('^\\d', table[i]) and not re.search(NM_pattern, table[i]): # look for stranded parts of names (does not begin with a digit). But need to test for standed names in stranded pdf\n",
    "        \n",
    "            print('checkpoint')\n",
    "        \n",
    "            try:  # remove try block to revert back to previous working state\n",
    "                \n",
    "                print('checkpoint 2')\n",
    "                \n",
    "                print('row[1]', row[1], 'table[i]', table[i])\n",
    "                                                \n",
    "                row[1]=row[1]+table[i] # retrieve previous row and add back stranded string to name. Stranded pdf will throw and error here. [1] refers to index position 1 corresponding to name\n",
    "                                                                                \n",
    "                new_df.drop(new_df.tail(1).index,inplace=True) # drop last row with incomplete name\n",
    "                                \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                padded = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "            \n",
    "                                                                        \n",
    "                new_df.loc[len(new_df)] = padded  # add back amended row\n",
    "                \n",
    "                print('padded', padded)\n",
    "                \n",
    "                list.append(padded)\n",
    "                                            \n",
    "                                                                    \n",
    "                continue  # then skip to next row\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                print('reached this second point for a stranded pdf')\n",
    "                \n",
    "                pass                 # move on if it is actually a stranded pdf\n",
    "        \n",
    "        \n",
    "                              \n",
    "        if not re.search('^\\d', table[i]) and re.search(NM_pattern, table[i]): # look for names that don't contain a numeric ranking with 'NM'\n",
    "        \n",
    "  #      if re.search(NM_pattern, table[i]): # look for 'NM'\n",
    "        \n",
    "        \n",
    "            print('NM XXX', table[i])\n",
    "                            \n",
    "            string=table[i] \n",
    "            \n",
    "            tag_pos=re.search(tag_pattern, string)\n",
    "            \n",
    "            name = string[:tag_pos.start()]\n",
    "            \n",
    "            everything_else = string[tag_pos.start():]\n",
    "            \n",
    "            list=everything_else.split(' ')\n",
    "                        \n",
    "            list.insert(0, name)\n",
    "            \n",
    "            list.insert(0, ' ') # insert space for rank\n",
    "            \n",
    "            list.insert(2, ' ') # insert space for Q/q         \n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.extend([' '])\n",
    "                                                    \n",
    "            new_df.loc[len(new_df)] = list\n",
    "            \n",
    "        if re.search('^\\d', table[i]) and re.search(NM_pattern, table[i]):  # DNS pattern that begins with a digit\n",
    "            \n",
    "            string=table[i] \n",
    "            \n",
    "            print('string', string)\n",
    "            \n",
    "            matches=re.findall(tag_pattern, string)  # find second set of digits corresponding to  tag ID\n",
    "                                \n",
    "            if len(matches)==2:\n",
    "                \n",
    "                rpos=re.search(matches[1], string) # choose second match if there are two \n",
    "            \n",
    "            \n",
    "            element = string[:rpos.start()]  # contains rank and name together\n",
    "            \n",
    "            rank = element[0:3]  # extract rank only\n",
    "                        \n",
    "            name =element[3:]  # extract name only\n",
    "                 \n",
    "            everything_else = string[rpos.start():]\n",
    "            \n",
    "            list=everything_else.split(' ')\n",
    "            \n",
    "            print('what', list)\n",
    "            \n",
    "            list.insert(0, name)\n",
    "                                    \n",
    "            list.insert(0, rank)\n",
    "            \n",
    "            list.insert(2, ' ') # insert space for Q/q         \n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "                        \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.extend([' '])\n",
    "            \n",
    "        #    print('DNS pattern', list)\n",
    "            \n",
    "            \n",
    "            new_df.loc[len(new_df)] = list\n",
    "\n",
    "            \n",
    "        if table[i].isdigit():  # exit function if it's not a proper line (e.g. number fragments with no content)  \n",
    "            \n",
    "            return new_df\n",
    "        \n",
    "        \n",
    "        if i==len(df):     # exit if end of df is reached\n",
    "            \n",
    "            return new_df\n",
    "       \n",
    "        \n",
    "        \n",
    "        # Else split lines per normal format\n",
    "    \n",
    "        if not re.search(NM_pattern, table[i]):  # skip those lines matching ex_pattern  \n",
    "        \n",
    "            string=table[i] \n",
    "                    \n",
    "            try:\n",
    "            \n",
    "                string=string.replace(\": \", \":\")       #delete gap in timing result\n",
    "                        \n",
    "            except:\n",
    "            \n",
    "                pass\n",
    "                    \n",
    "        \n",
    "            lpos = re.search('\\s', string)\n",
    "            rpos = re.search(new_pattern, string)\n",
    "            \n",
    "            \n",
    "                                                        \n",
    "        \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            if 'Qfy' not in string:\n",
    "        \n",
    "                split_pos_end=rpos.end()-1      # adjust the splicing position to only capture the name\n",
    "                split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "                left_string = string[:lpos.start()] # left string post splicing\n",
    "                right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "                name_plus = string[split_pos_start:split_pos_end]  # extract competitor name\n",
    "                                \n",
    "                \n",
    "           #     print('name no qfy', name)\n",
    "                \n",
    "            elif 'Qfy' in string:\n",
    "                \n",
    "                split_pos_end=rpos.end()-3      # adjust the splicing position to only capture the name\n",
    "                split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "                left_string = string[:lpos.start()] # left string post splicing\n",
    "                right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "                name=string[split_pos_start:split_pos_end]  # extract competitor name\n",
    "                \n",
    "            #    print('name got qfy', name)\n",
    "\n",
    "                \n",
    "                    \n",
    "                               \n",
    "            list=right_string.split(' ')        # put everything coming after the name into a list  \n",
    "                                                        \n",
    "                \n",
    " #       if len(list)==6:    # check length of list. If less than 7, append blank fields for Pos and W/G \n",
    "                    \n",
    "#            list.extend([' ', ' ', ' ', ' '])\n",
    "                    \n",
    "#        elif len(list)==5:\n",
    "                    \n",
    "#            list.extend([' ', ' ', ' ', ' '])\n",
    "                                                            \n",
    "                \n",
    "            combined=left_string+ ';' + name +'; '+ '; '.join(list)  # use ';' in case names have a ','\n",
    "\n",
    "            row=combined.split(';')   \n",
    "                                                                                                 \n",
    "\n",
    "        # check if Q or q between tag and name. If not, fill in with empty space.\n",
    "        # don't overwrite master df if there is a stranded pdf\n",
    "                \n",
    "            if row[2].strip()=='Q' or row[2].strip()=='q' or row[2].strip()=='Qfy' or row[2] is None:\n",
    "            \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                final_list = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "            \n",
    "          #      print('HERE1', final_list)\n",
    "                                \n",
    "                new_df.loc[len(new_df)] = final_list\n",
    "\n",
    "\n",
    "            else:\n",
    "                \n",
    "                print('row', row)\n",
    "                \n",
    "                row.insert(2, ' ')\n",
    "                \n",
    "                \n",
    "                \n",
    "                if 'DQ' in string:\n",
    "                    \n",
    "                    length=len(row)\n",
    "                    \n",
    "                    row.insert(length-2,' ')\n",
    "                    row.insert(length-2,' ')\n",
    "                    \n",
    "          #          print('padded row', row)\n",
    "            \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                final_list = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "            \n",
    "           #     print('HERE2', final_list)\n",
    "            \n",
    "                list.append(final_list)\n",
    "            \n",
    "                            \n",
    "                new_df.loc[len(new_df)] = final_list\n",
    "                                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# QAed to this point for a stranded pdf. Need to figure out how to attach stranded row to master df\n",
    "            \n",
    "            \n",
    "#            master_df=new_df      # previous   \n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "eba7bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newest version to ingest 2023 PDFs\n",
    "# Almost complete except for some formatting effects\n",
    "# Called by 'extraction' function\n",
    "\n",
    "def new_format_parser(row_index, names, table, master_df):\n",
    "    \n",
    "                \n",
    "    # Define regex patterns\n",
    "    \n",
    "    new_pattern='\\d\\s.{5,40}?\\s(Qfy|Q\\s|q\\s|\\d)'  # extract name \n",
    "    \n",
    "    old_pattern='\\s[A-Z]{2,4}|\\s[0-9]{1,3}?|\\sQ\\s[0-9]{1,3}?' \n",
    "    \n",
    "    event_pattern='\\:\\s.{5,30}\\s(\\-|\\()'\n",
    "\n",
    "    school_pattern='\\s[A-Z]{2,4}'  # find how many uppercase shortforms for school\n",
    "    \n",
    "    year_pattern='\\d\\d\\d\\d'\n",
    "    \n",
    "    Q_pattern = '\\sQ'\n",
    "    \n",
    "\n",
    "    \n",
    "    stranded = \"no\"  # flag for stranded pdf pages\n",
    "    \n",
    "    NM_pattern = '\\sNM'  # No Mark\n",
    "    \n",
    " #   ex_pattern = 'NONE'  # Essentially no exlusions\n",
    "\n",
    "    \n",
    "    tag_pattern = '\\d\\d\\d|\\d\\d'\n",
    "    \n",
    "    gap_pattern = ':\\s\\d'\n",
    "        \n",
    "    # Put table that has been processed into a dataframe\n",
    "    \n",
    "    df=pd.DataFrame(table)\n",
    "                \n",
    "    columns=[]\n",
    "    \n",
    "    list=[]\n",
    "                \n",
    "    \n",
    "    # Initialize new df and remove unnecessary columns\n",
    "    \n",
    "    if row_index!=0 and names is not None: # check that its coming from not a stranded pdf with no header i.e. new pdf\n",
    "                    \n",
    "        df2 = pd.DataFrame(columns=names) \n",
    "        \n",
    "    \n",
    "        #new_df = df2.iloc[:, :-2]    # remove 'Remarks' and 'NR' columns\n",
    "        \n",
    "        new_df = df2    # retain 'REMARKS' and 'NR' columns\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('reached this first point for a stranded pdf')\n",
    "        \n",
    "        stranded=\"yes\"\n",
    "        \n",
    "        new_df = master_df.iloc[:0] # new_df columns to come from the master df\n",
    "        \n",
    "        row_index=-1  # move back row_index for a stranded pdf\n",
    "        \n",
    "    \n",
    "#    for i in range(row_index+1,(len(df)-1)):  # iterate over df - only stranded pdf should start from zero. Previous code - revert to original  \n",
    "\n",
    "\n",
    "#  check for stranded pdfs with stranded names\n",
    "\n",
    "    for i in range(row_index+1,(len(df))):  # iterate over df - only stranded pdf should start from index zero    \n",
    "    \n",
    "        print('table[i]', table[i])\n",
    "        \n",
    "        print('MATCH', re.search('^\\d', table[i]), re.search(NM_pattern, table[i]))\n",
    "\n",
    "                                            \n",
    "        \n",
    "        if not re.search('^\\d', table[i]) and not re.search(NM_pattern, table[i]): # look for stranded parts of names (does not begin with a digit). But need to test for standed names in stranded pdf\n",
    "        \n",
    "            print('stranded name checkpoint')\n",
    "        \n",
    "            try:  # remove try block to revert back to previous working state\n",
    "                \n",
    "                print('reattaching stranded name checkpoint')\n",
    "                \n",
    "                print('row[1]', row[1], 'table[i]', table[i])\n",
    "                                                \n",
    "                row[1]=row[1]+table[i] # retrieve previous row and add back stranded string to name. Stranded pdf will throw and error here. [1] refers to index position 1 corresponding to name\n",
    "                                                                                \n",
    "                new_df.drop(new_df.tail(1).index,inplace=True) # drop last row with incomplete name\n",
    "                                \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                padded = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "            \n",
    "                                                                        \n",
    "                new_df.loc[len(new_df)] = padded  # add back amended row\n",
    "                \n",
    "                print('padded full append list', padded)\n",
    "                \n",
    "                list.append(padded)\n",
    "                                            \n",
    "                                                                    \n",
    "                continue  # then skip to next row\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                print('reached this second point for a stranded pdf')\n",
    "                \n",
    "                pass                 # move on if it is actually a stranded pdf\n",
    "        \n",
    "        ## 'NM' pattern with no numeric ranking ##\n",
    "                              \n",
    "        if not re.search('^\\d', table[i]) and re.search(NM_pattern, table[i]): \n",
    "        \n",
    "  #      if re.search(NM_pattern, table[i]): # look for 'NM'\n",
    "        \n",
    "        \n",
    "            print('NM XXX', table[i])\n",
    "                            \n",
    "            string=table[i] \n",
    "            \n",
    "            tag_pos=re.search(tag_pattern, string)\n",
    "            \n",
    "            name = string[:tag_pos.start()]\n",
    "            \n",
    "            everything_else = string[tag_pos.start():]\n",
    "            \n",
    "            list=everything_else.split(' ')\n",
    "                        \n",
    "            list.insert(0, name)\n",
    "            \n",
    "            list.insert(0, ' ') # insert space for rank\n",
    "            \n",
    "            list.insert(2, ' ') # insert space for Q/q         \n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.extend([' '])\n",
    "            \n",
    "            print('list', list)\n",
    "                                                    \n",
    "            new_df.loc[len(new_df)] = list\n",
    "            \n",
    "            \n",
    "        ## NM pattern that begins with a numeric ranking ##\n",
    "        \n",
    "        if re.search('^\\d', table[i]) and re.search(NM_pattern, table[i]):  \n",
    "            \n",
    "            string=table[i] \n",
    "            \n",
    "            print('NM with ranking string here', string)\n",
    "            \n",
    "            matches=re.findall(tag_pattern, string)  # find second set of digits corresponding to  tag ID\n",
    "            \n",
    "            print('matches', matches)\n",
    "                                            \n",
    "            if len(matches)>=2:\n",
    "                \n",
    "                rpos=re.search(matches[1], string) # choose second match if there are two \n",
    "                                \n",
    "                \n",
    "                print('rpos', rpos)\n",
    "            \n",
    "            \n",
    "            element = string[:rpos.start()]  # contains rank and name together\n",
    "            \n",
    "            print('element', element)\n",
    "            \n",
    "            rank = element[0:3]  # extract rank only\n",
    "                        \n",
    "            name =element[3:]  # extract name only\n",
    "                 \n",
    "            everything_else = string[rpos.start():]\n",
    "            \n",
    "            list=everything_else.split(' ')\n",
    "                        \n",
    "            list.insert(0, name)\n",
    "                                    \n",
    "            list.insert(0, rank)\n",
    "            \n",
    "            list.insert(2, ' ') # insert space for Q/q         \n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "                        \n",
    "            list.insert(7, ' ')\n",
    "            \n",
    "            list.insert(7, ' ')\n",
    "\n",
    "            \n",
    "            list.extend([' '])\n",
    "            \n",
    "            print('final list', list)\n",
    "            \n",
    "        #    print('DNS pattern', list)\n",
    "            \n",
    "            \n",
    "            new_df.loc[len(new_df)] = list\n",
    "\n",
    "            \n",
    "        if table[i].isdigit():  # exit function if it's not a proper line (e.g. number fragments with no content)  \n",
    "            \n",
    "            return new_df\n",
    "        \n",
    "        \n",
    "        if i==len(df):     # exit if end of df is reached\n",
    "            \n",
    "            return new_df\n",
    "       \n",
    "        \n",
    "        \n",
    "        ### Normal Splicing of Lines ##\n",
    "    \n",
    "        if not re.search(NM_pattern, table[i]):  # skip those lines matching NM_pattern  \n",
    "        \n",
    "            string=table[i] \n",
    "                        \n",
    "                    \n",
    "            try:\n",
    "            \n",
    "                string=string.replace(\": \", \":\")       #delete gap in timing result\n",
    "                        \n",
    "            except:\n",
    "            \n",
    "                pass\n",
    "                    \n",
    "        \n",
    "            lpos = re.search('\\s', string)\n",
    "            rpos = re.search(new_pattern, string)\n",
    "            qpos = re.search(Q_pattern, string)\n",
    "\n",
    "            \n",
    "            print('lpos', lpos, 'rpos', rpos, 'qpos', qpos)\n",
    "        \n",
    "            \n",
    "            \n",
    "                                                        \n",
    "        \n",
    "        # Splice string to extract name of competitor\n",
    "\n",
    "            if 'Qfy' not in string:\n",
    "        \n",
    "                split_pos_end=rpos.end()-1      # adjust the splicing position to only capture the name\n",
    "                split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "                left_string = string[:lpos.start()] # left string post splicing\n",
    "                right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "                name=string[split_pos_start:split_pos_end]  # extract competitor name\n",
    "                \n",
    "                # Strip out 'Q' from extracted string\n",
    "                \n",
    "          #      try:\n",
    "                \n",
    "          #          qpos = re.search(Q_pattern, name)\n",
    "                    \n",
    "           #         print('qpos', qpos)\n",
    "                    \n",
    "          #          endpos = qpos.start()-1\n",
    "                    \n",
    "          #          name = name[:endpos]\n",
    "                    \n",
    "                    \n",
    "                \n",
    "          #      except:\n",
    "                    \n",
    "          #          pass\n",
    "                \n",
    "                \n",
    "           #     print('name no qfy', name)\n",
    "                \n",
    "            elif 'Qfy' in string:\n",
    "                \n",
    "                split_pos_end=rpos.end()-3      # adjust the splicing position to only capture the name\n",
    "                split_pos_start=lpos.start()+1\n",
    "\n",
    "            \n",
    "                left_string = string[:lpos.start()] # left string post splicing\n",
    "                right_string = string[split_pos_end:] # right string post slicing\n",
    "                         \n",
    "                name=string[split_pos_start:split_pos_end]  # extract competitor name\n",
    "                \n",
    "            #    print('name got qfy', name)\n",
    "\n",
    "                \n",
    "                    \n",
    "                               \n",
    "            list=right_string.split(' ')        # put everything coming after the name into a list  \n",
    "            \n",
    "            print('LIST', list)\n",
    "            \n",
    "            list.insert(6, ' ') # move one over \n",
    "                                                        \n",
    "                \n",
    " #       if len(list)==6:    # check length of list. If less than 7, append blank fields for Pos and W/G \n",
    "                    \n",
    "#            list.extend([' ', ' ', ' ', ' '])\n",
    "                    \n",
    "#        elif len(list)==5:\n",
    "                    \n",
    "#            list.extend([' ', ' ', ' ', ' '])\n",
    "                                                            \n",
    "                \n",
    "            combined=left_string+ ';' + name +'; '+ '; '.join(list)  # use ';' in case names have a ','\n",
    "\n",
    "            row=combined.split(';')   \n",
    "                                                                                                 \n",
    "\n",
    "        # check if Q or q between tag and name. If not, fill in with empty space.\n",
    "        # don't overwrite master df if there is a stranded pdf\n",
    "        \n",
    "            print('split', row[1].split().pop()) \n",
    "            \n",
    "    #        if row[1].strip()=='Q' or row[1].strip()=='q' or row[1].strip()=='Qfy' or row[1] is None:\n",
    "            if row[1].split().pop()=='Q':\n",
    "            \n",
    "                row[1]=row[1].replace(' Q', ' ')\n",
    "                \n",
    "                #row.insert(2, 'Q') # insert 'Q' back into list\n",
    "           \n",
    "                row[2] = row[2].replace(' ', 'Q')\n",
    "            \n",
    "                print('rowX', row)\n",
    "        \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                final_list = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "                                                            \n",
    "                new_df.loc[len(new_df)] = final_list\n",
    "\n",
    "\n",
    "            else:\n",
    "                \n",
    "                print('rowX2', row)\n",
    "                \n",
    "                row.insert(2, ' ')\n",
    "                row.insert(8, ' ')\n",
    "                \n",
    "                \n",
    "                \n",
    "                if 'DQ' in string:\n",
    "                    \n",
    "                    length=len(row)\n",
    "                    \n",
    "                    row.insert(length-2,' ')\n",
    "                    row.insert(length-2,' ')\n",
    "                    \n",
    "                if 'DNS' in string:\n",
    "                    \n",
    "                    row.insert(7,' ')\n",
    "                    row.insert(7,' ')\n",
    "                    del row[10]\n",
    "\n",
    "                \n",
    "                    \n",
    "            \n",
    "                pad_value = ' '\n",
    "                pad_size = 12 - len(row)\n",
    "\n",
    "                final_list = [*row, *[pad_value] * pad_size]  # add extra columns to make it 12\n",
    "            \n",
    "                print('HERE2', final_list)\n",
    "            \n",
    "                list.append(final_list)\n",
    "            \n",
    "                            \n",
    "                new_df.loc[len(new_df)] = final_list\n",
    "                                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# QAed to this point for a stranded pdf. Need to figure out how to attach stranded row to master df\n",
    "            \n",
    "            \n",
    "#            master_df=new_df      # previous   \n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f79f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_directory(directory):\n",
    "    items = os.listdir(directory)\n",
    "    sorted_items = sorted(items)\n",
    "    return sorted_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8808dfc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG202/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test iteration over more than one page and multiple files in directory\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG202/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/Session_20.pdf\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022PDF/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG202/'"
     ]
    }
   ],
   "source": [
    "# 2022 #\n",
    "# Test iteration over more than one page and multiple files in directory\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG202/')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1/S01-01_TO_11_deconstructed_22-25.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/Session_20.pdf\"\n",
    "\n",
    "directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022PDF/\"\n",
    "\n",
    "    \n",
    "    \n",
    "# Iterate over files in directory\n",
    "\n",
    "sorted_items=sort_directory(directory)\n",
    "\n",
    "temp_df=pd.DataFrame()  # initialize empty temp df\n",
    "\n",
    "master_df=pd.DataFrame()\n",
    "\n",
    "splitted=None\n",
    "\n",
    "print(sorted_items)\n",
    "\n",
    "for file in sorted_items:\n",
    "\n",
    "\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "        for i in range(len(pdf.pages)):\n",
    "        \n",
    "            temp=splitted\n",
    "        \n",
    "            page = pdf.pages[i]  # can iterate over different pages\n",
    "            table=page.extract_table()\n",
    "            text=page.extract_text()\n",
    "                \n",
    "            if i==0:\n",
    "        \n",
    "                splitted=text.splitlines()\n",
    "            \n",
    "                temp_df=extraction(splitted, temp_df)\n",
    "            \n",
    "            else: # stitch list from second page\n",
    "            \n",
    "                temp=text.splitlines()\n",
    "            \n",
    "                splitted.extend(temp)\n",
    "            \n",
    "                temp_df=extraction(splitted, temp_df)\n",
    "                        \n",
    "            master_df=pd.concat([master_df, temp_df], axis=0)\n",
    "\n",
    "\n",
    "            \n",
    "    #master_df=extraction(splitted, master_df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdc17a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Q</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Team</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Ln</th>\n",
       "      <th>Result</th>\n",
       "      <th>Pts</th>\n",
       "      <th>W/G</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>NR</th>\n",
       "      <th>Session</th>\n",
       "      <th>Division</th>\n",
       "      <th>Event</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WONG CHOONG YIN</td>\n",
       "      <td></td>\n",
       "      <td>719</td>\n",
       "      <td>VS</td>\n",
       "      <td>Finals</td>\n",
       "      <td>5</td>\n",
       "      <td>38.77</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Discus</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ONG YI JUN RAYMUS</td>\n",
       "      <td></td>\n",
       "      <td>337</td>\n",
       "      <td>HCI</td>\n",
       "      <td>Finals</td>\n",
       "      <td>4</td>\n",
       "      <td>37.56</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Discus</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LEAM TEO JIN TZE</td>\n",
       "      <td></td>\n",
       "      <td>499</td>\n",
       "      <td>RI</td>\n",
       "      <td>Finals</td>\n",
       "      <td>14</td>\n",
       "      <td>36.92</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Discus</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LEROY ANDRE CHNG CHONG KAI</td>\n",
       "      <td></td>\n",
       "      <td>695</td>\n",
       "      <td>VS</td>\n",
       "      <td>Finals</td>\n",
       "      <td>12</td>\n",
       "      <td>35.21</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Discus</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>KEANE WONG JEN QUIN</td>\n",
       "      <td></td>\n",
       "      <td>585</td>\n",
       "      <td>SJI</td>\n",
       "      <td>Finals</td>\n",
       "      <td>11</td>\n",
       "      <td>34.78</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Discus</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>QUINN PUAR MIN (PAN MIN)</td>\n",
       "      <td></td>\n",
       "      <td>281</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>Finals</td>\n",
       "      <td>1</td>\n",
       "      <td>00:15.88</td>\n",
       "      <td>5</td>\n",
       "      <td>+0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S09-09</td>\n",
       "      <td>C</td>\n",
       "      <td>80m Hurdles</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SEM EUNA (SUN YUNYA)</td>\n",
       "      <td></td>\n",
       "      <td>145</td>\n",
       "      <td>SNG</td>\n",
       "      <td>Finals</td>\n",
       "      <td>7</td>\n",
       "      <td>00:16.28</td>\n",
       "      <td>4</td>\n",
       "      <td>+0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S09-09</td>\n",
       "      <td>C</td>\n",
       "      <td>80m Hurdles</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>TAN NGANG TENG XEN (CHEN YANYING)</td>\n",
       "      <td></td>\n",
       "      <td>78</td>\n",
       "      <td>CG</td>\n",
       "      <td>Finals</td>\n",
       "      <td>8</td>\n",
       "      <td>00:16.96</td>\n",
       "      <td>3</td>\n",
       "      <td>+0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S09-09</td>\n",
       "      <td>C</td>\n",
       "      <td>80m Hurdles</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>EDEN SAIGE TAN</td>\n",
       "      <td></td>\n",
       "      <td>266</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>Finals</td>\n",
       "      <td>2</td>\n",
       "      <td>00:17.16</td>\n",
       "      <td>2</td>\n",
       "      <td>+0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>S09-09</td>\n",
       "      <td>C</td>\n",
       "      <td>80m Hurdles</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>AMELIA PAO TSE TENG</td>\n",
       "      <td></td>\n",
       "      <td>199</td>\n",
       "      <td>DHS</td>\n",
       "      <td>Finals</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>+0.0</td>\n",
       "      <td>DQ</td>\n",
       "      <td></td>\n",
       "      <td>S09-09</td>\n",
       "      <td>C</td>\n",
       "      <td>80m Hurdles</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7300 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS                         Competitor  Q   Tag   Team     Heat   Ln  \\\n",
       "0    1                   WONG CHOONG YIN       719     VS   Finals    5   \n",
       "1    2                 ONG YI JUN RAYMUS       337    HCI   Finals    4   \n",
       "2    3                  LEAM TEO JIN TZE       499     RI   Finals   14   \n",
       "3    4        LEROY ANDRE CHNG CHONG KAI       695     VS   Finals   12   \n",
       "4    5               KEANE WONG JEN QUIN       585    SJI   Finals   11   \n",
       "..  ..                                ... ..   ...    ...      ...  ...   \n",
       "3    4          QUINN PUAR MIN (PAN MIN)       281   NYGH   Finals    1   \n",
       "4    5              SEM EUNA (SUN YUNYA)       145    SNG   Finals    7   \n",
       "5    6  TAN NGANG TENG XEN (CHEN YANYING)       78     CG   Finals    8   \n",
       "6    7                    EDEN SAIGE TAN       266   NYGH   Finals    2   \n",
       "7    8               AMELIA PAO TSE TENG       199    DHS   Finals    5   \n",
       "\n",
       "       Result Pts    W/G Remarks NR Session Division           Event  Gender  \n",
       "0       38.77   9                    S01-01       B          Discus     Male  \n",
       "1       37.56   7                    S01-01       B          Discus     Male  \n",
       "2       36.92   6                    S01-01       B          Discus     Male  \n",
       "3       35.21   5                    S01-01       B          Discus     Male  \n",
       "4       34.78   4                    S01-01       B          Discus     Male  \n",
       "..        ...  ..    ...     ... ..     ...      ...             ...     ...  \n",
       "3    00:15.88   5   +0.0             S09-09       C     80m Hurdles   Female  \n",
       "4    00:16.28   4   +0.0             S09-09       C     80m Hurdles   Female  \n",
       "5    00:16.96   3   +0.0             S09-09       C     80m Hurdles   Female  \n",
       "6    00:17.16   2   +0.0             S09-09       C     80m Hurdles   Female  \n",
       "7                   +0.0      DQ     S09-09       C     80m Hurdles   Female  \n",
       "\n",
       "[7300 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d93a2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('NSG_2022_final.csv', sep=',', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c33f28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Audited List Published Date: 04-05-2022 09:04:34\\nEvent: S20-04 800m - A DIVISION BOYS Finals\\nSchools National Record S Pandian BTVI 01:52.37s 1985\\nSchools National Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017\\nChampionships Record S Pandian BTVI 01:54.5s 1985\\nChampionships Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], ['Audited List Published Date: 04-05-2022 09:04:34\\nEvent: S20-04 800m - A DIVISION BOYS Finals\\nSchools National Record S Pandian BTVI 01:52.37s 1985\\nSchools National Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017\\nChampionships Record S Pandian BTVI 01:54.5s 1985\\nChampionships Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], [None, '', '', 'Audited List Published Date: 04-05-2022 09:04:34\\nEvent: S20-04 800m - A DIVISION BOYS Finals\\nSchools National Record S Pandian BTVI 01:52.37s 1985\\nSchools National Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017\\nChampionships Record S Pandian BTVI 01:54.5s 1985\\nChampionships Record Thiruben S/O Thana Rajan NJC (ET)01:55.40s 2017', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], [None, None, None, None, '', None, 'Audited List', None, None, None, None, None, 'Published Date: 04-05-2022 09:04:34', None, None, None, None, None, None, None, None, None], [None, None, None, None, 'Event: S20-04', None, '800m - A DIVISION BOYS Finals', None, None, None, None, None, '', None, '', None, None, '', None, None, None, None], [None, None, None, None, 'Schools National Record', None, 'S Pandian', None, None, None, None, None, 'BTVI', None, '01:52.37s', None, None, '1985', None, None, None, None], [None, None, None, None, 'Schools National Record', None, 'Thiruben S/O Thana Rajan', None, None, None, None, None, 'NJC', None, '(ET)01:55.40s', None, None, '2017', None, None, None, None], [None, None, None, None, 'Championships Record', None, 'S Pandian', None, None, None, None, None, 'BTVI', None, '01:54.5s', None, None, '1985', None, None, None, None], [None, None, None, None, 'Championships Record', None, 'Thiruben S/O Thana Rajan', None, None, None, None, None, 'NJC', None, '(ET)01:55.40s', None, None, '2017', None, None, None, None], ['', '', '', '', '', None, '', None, None, None, None, None, '', None, '', None, None, '', None, '', '', ''], [None, None, None, None, '', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], [None, None, None, '', '', None, None, None, None, None, None, None, None, None, None, None, None, None, None, '', None, None], [None, None, None, None, '', '', None, '', '', '', '', '', '', '', None, '', '', None, '', None, None, None], [None, None, None, '', 'POS', 'Competitor', None, 'Q', 'Tag', 'Team', 'Heat', 'Ln', 'Result', 'Pts', None, 'W/G', 'Remarks', None, 'NR', '', None, None], ['1 LIM WEI FENG 20 ACJC Finals 5 02:03.61 9\\n2 LEE WEN JIE 161 JPJC Finals 3 02:03.70 7\\n3 MERVYN ONG SHAO XUAN 25 ACJC Finals 2 02:04.76 6\\n4 TANMAY DESHPANDE 313 VJC Finals 4 02:05.48 5\\n5 THEJESVI MOHAN 183 MI Finals 1 02:06.10 4\\n6 LOW ERN KYE 304 VJC Finals 9 02:07.21 3\\n7 TAN SHWEE WEN ZACH 243 RI Finals 14 02:08.39 2\\n8 PRANAV MANIMURUGAN 180 MI Finals 7 02:08.87 1\\n9 SNG YUN LIANG, DAVID 252 RVH Finals 8 02:09.55\\n10 THAARMIN S/O THANA RAJAN 196 NJC Finals 11 02:09.63\\n11 CHONG AIK JIN JEREMY 44 ACS(I) Finals 13 02:09.77\\n12 ONG YAN ERN WAYNE 193 NJC Finals 12 02:11.68\\n13 FANG PIN XIN 298 VJC Finals 10 02:12.22\\n14 REUBEN HAN WEI CHOU 237 RI Finals 6 02:12.37\\n15 SEOW ENG KIAT, KYLE 240 RI Finals 16 02:14.24\\n16 CHAN JIN ZE 87 EJC Finals 15 02:14.57', '', '', '1 LIM WEI FENG 20 ACJC Finals 5 02:03.61 9\\n2 LEE WEN JIE 161 JPJC Finals 3 02:03.70 7\\n3 MERVYN ONG SHAO XUAN 25 ACJC Finals 2 02:04.76 6\\n4 TANMAY DESHPANDE 313 VJC Finals 4 02:05.48 5\\n5 THEJESVI MOHAN 183 MI Finals 1 02:06.10 4\\n6 LOW ERN KYE 304 VJC Finals 9 02:07.21 3\\n7 TAN SHWEE WEN ZACH 243 RI Finals 14 02:08.39 2\\n8 PRANAV MANIMURUGAN 180 MI Finals 7 02:08.87 1\\n9 SNG YUN LIANG, DAVID 252 RVH Finals 8 02:09.55\\n10 THAARMIN S/O THANA RAJAN 196 NJC Finals 11 02:09.63\\n11 CHONG AIK JIN JEREMY 44 ACS(I) Finals 13 02:09.77\\n12 ONG YAN ERN WAYNE 193 NJC Finals 12 02:11.68\\n13 FANG PIN XIN 298 VJC Finals 10 02:12.22\\n14 REUBEN HAN WEI CHOU 237 RI Finals 6 02:12.37\\n15 SEOW ENG KIAT, KYLE 240 RI Finals 16 02:14.24\\n16 CHAN JIN ZE 87 EJC Finals 15 02:14.57', '1', 'LIM WEI FENG', None, '', '20', 'ACJC', 'Finals', '5', '02:03.61', '9', None, '', '', None, '', None, None, None], [None, None, None, None, '2', 'LEE WEN JIE', None, '', '161', 'JPJC', 'Finals', '3', '02:03.70', '7', None, '', '', None, '', None, None, None], [None, None, None, None, '3', 'MERVYN ONG SHAO XUAN', None, '', '25', 'ACJC', 'Finals', '2', '02:04.76', '6', None, '', '', None, '', None, None, None], [None, None, None, None, '4', 'TANMAY DESHPANDE', None, '', '313', 'VJC', 'Finals', '4', '02:05.48', '5', None, '', '', None, '', None, None, None], [None, None, None, None, '5', 'THEJESVI MOHAN', None, '', '183', 'MI', 'Finals', '1', '02:06.10', '4', None, '', '', None, '', None, None, None], [None, None, None, None, '6', 'LOW ERN KYE', None, '', '304', 'VJC', 'Finals', '9', '02:07.21', '3', None, '', '', None, '', None, None, None], [None, None, None, None, '7', 'TAN SHWEE WEN ZACH', None, '', '243', 'RI', 'Finals', '14', '02:08.39', '2', None, '', '', None, '', None, None, None], [None, None, None, None, '8', 'PRANAV MANIMURUGAN', None, '', '180', 'MI', 'Finals', '7', '02:08.87', '1', None, '', '', None, '', None, None, None], [None, None, None, None, '9', 'SNG YUN LIANG, DAVID', None, '', '252', 'RVH', 'Finals', '8', '02:09.55', '', None, '', '', None, '', None, None, None], [None, None, None, None, '10', 'THAARMIN S/O THANA RAJAN', None, '', '196', 'NJC', 'Finals', '11', '02:09.63', '', None, '', '', None, '', None, None, None], [None, None, None, None, '11', 'CHONG AIK JIN JEREMY', None, '', '44', 'ACS(I)', 'Finals', '13', '02:09.77', '', None, '', '', None, '', None, None, None], [None, None, None, None, '12', 'ONG YAN ERN WAYNE', None, '', '193', 'NJC', 'Finals', '12', '02:11.68', '', None, '', '', None, '', None, None, None], [None, None, None, None, '13', 'FANG PIN XIN', None, '', '298', 'VJC', 'Finals', '10', '02:12.22', '', None, '', '', None, '', None, None, None], [None, None, None, None, '14', 'REUBEN HAN WEI CHOU', None, '', '237', 'RI', 'Finals', '6', '02:12.37', '', None, '', '', None, '', None, None, None], [None, None, None, None, '15', 'SEOW ENG KIAT, KYLE', None, '', '240', 'RI', 'Finals', '16', '02:14.24', '', None, '', '', None, '', None, None, None], [None, None, None, None, '16', 'CHAN JIN ZE', None, '', '87', 'EJC', 'Finals', '15', '02:14.57', '', None, '', '', None, '', None, None, None], [None, None, None, '', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e29abfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S01-01_TO_11_deconstructed_1-1.pdf', 'S01-01_TO_11_deconstructed_10-13.pdf', 'S01-01_TO_11_deconstructed_14-17.pdf', 'S01-01_TO_11_deconstructed_18-21.pdf', 'S01-01_TO_11_deconstructed_2-2.pdf', 'S01-01_TO_11_deconstructed_22-25.pdf', 'S01-01_TO_11_deconstructed_26-end.pdf', 'S01-01_TO_11_deconstructed_3-3.pdf', 'S01-01_TO_11_deconstructed_4-4.pdf', 'S01-01_TO_11_deconstructed_5-5.pdf', 'S01-01_TO_11_deconstructed_6-7.pdf', 'S01-01_TO_11_deconstructed_8-9.pdf']\n",
      "S01-01_TO_11_deconstructed_1-1.pdf\n",
      "row string Event: S0l-01 High Jump - B DIVISION GIRLS Finals r\n",
      "event  S0l-01 High Jump \n",
      "session list ['S0l-01']\n",
      "session S0l-01\n",
      "division B \n",
      "gender Female\n",
      "table[i] 1 BOBBI VICTORIA YANG YEN 117 HIJ Finals 4 1.48 9\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 27), match='1 BOBBI VICTORIA YANG YEN 1'> qpos None\n",
      "LIST ['117', 'HIJ', 'Finals', '4', '1.48', '9']\n",
      "split YEN\n",
      "rowX2 ['1', 'BOBBI VICTORIA YANG YEN ', ' 117', ' HIJ', ' Finals', ' 4', ' 1.48', ' 9', '  ']\n",
      "HERE2 ['1', 'BOBBI VICTORIA YANG YEN ', ' ', ' 117', ' HIJ', ' Finals', ' 4', ' 1.48', ' 9', '  ', ' ', ' ']\n",
      "table[i] (WENG XUAN)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] BOBBI VICTORIA YANG YEN  table[i] (WENG XUAN)\n",
      "padded full append list ['1', 'BOBBI VICTORIA YANG YEN (WENG XUAN)', ' ', ' 117', ' HIJ', ' Finals', ' 4', ' 1.48', ' 9', '  ', ' ', ' ']\n",
      "table[i] 2 VERBOON LARA 173 SNG Finals 9 1.48 7\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 16), match='2 VERBOON LARA 1'> qpos None\n",
      "LIST ['173', 'SNG', 'Finals', '9', '1.48', '7']\n",
      "split LARA\n",
      "rowX2 ['2', 'VERBOON LARA ', ' 173', ' SNG', ' Finals', ' 9', ' 1.48', ' 7', '  ']\n",
      "HERE2 ['2', 'VERBOON LARA ', ' ', ' 173', ' SNG', ' Finals', ' 9', ' 1.48', ' 7', '  ', ' ', ' ']\n",
      "table[i] 3 WONG XIN YU 253 OHS Finals 6 1.40 6\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 15), match='3 WONG XIN YU 2'> qpos None\n",
      "LIST ['253', 'OHS', 'Finals', '6', '1.40', '6']\n",
      "split YU\n",
      "rowX2 ['3', 'WONG XIN YU ', ' 253', ' OHS', ' Finals', ' 6', ' 1.40', ' 6', '  ']\n",
      "HERE2 ['3', 'WONG XIN YU ', ' ', ' 253', ' OHS', ' Finals', ' 6', ' 1.40', ' 6', '  ', ' ', ' ']\n",
      "table[i] 4 GAN MIN WEN LAUREN 246 OHS Finals 11 1.40 5\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='4 GAN MIN WEN LAUREN 2'> qpos None\n",
      "LIST ['246', 'OHS', 'Finals', '11', '1.40', '5']\n",
      "split LAUREN\n",
      "rowX2 ['4', 'GAN MIN WEN LAUREN ', ' 246', ' OHS', ' Finals', ' 11', ' 1.40', ' 5', '  ']\n",
      "HERE2 ['4', 'GAN MIN WEN LAUREN ', ' ', ' 246', ' OHS', ' Finals', ' 11', ' 1.40', ' 5', '  ', ' ', ' ']\n",
      "table[i] 5 HEIDI LEONG NGA! LING 61 CG Finals 1 1.35 4\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 25), match='5 HEIDI LEONG NGA! LING 6'> qpos None\n",
      "LIST ['61', 'CG', 'Finals', '1', '1.35', '4']\n",
      "split LING\n",
      "rowX2 ['5', 'HEIDI LEONG NGA! LING ', ' 61', ' CG', ' Finals', ' 1', ' 1.35', ' 4', '  ']\n",
      "HERE2 ['5', 'HEIDI LEONG NGA! LING ', ' ', ' 61', ' CG', ' Finals', ' 1', ' 1.35', ' 4', '  ', ' ', ' ']\n",
      "table[i] 5 GOH YEN YOUNG AMELIA 247 OHS Finals 13 1.35 4\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 24), match='5 GOH YEN YOUNG AMELIA 2'> qpos None\n",
      "LIST ['247', 'OHS', 'Finals', '13', '1.35', '4']\n",
      "split AMELIA\n",
      "rowX2 ['5', 'GOH YEN YOUNG AMELIA ', ' 247', ' OHS', ' Finals', ' 13', ' 1.35', ' 4', '  ']\n",
      "HERE2 ['5', 'GOH YEN YOUNG AMELIA ', ' ', ' 247', ' OHS', ' Finals', ' 13', ' 1.35', ' 4', '  ', ' ', ' ']\n",
      "table[i] 7 LARENE KOH 68 CG Finals 7 1.35 2\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 14), match='7 LARENE KOH 6'> qpos None\n",
      "LIST ['68', 'CG', 'Finals', '7', '1.35', '2']\n",
      "split KOH\n",
      "rowX2 ['7', 'LARENE KOH ', ' 68', ' CG', ' Finals', ' 7', ' 1.35', ' 2', '  ']\n",
      "HERE2 ['7', 'LARENE KOH ', ' ', ' 68', ' CG', ' Finals', ' 7', ' 1.35', ' 2', '  ', ' ', ' ']\n",
      "table[i] 8 YVETTE LEE 94 CG Finals 12 1.35 1\n",
      "MATCH <re.Match object; span=(0, 1), match='8'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 14), match='8 YVETTE LEE 9'> qpos None\n",
      "LIST ['94', 'CG', 'Finals', '12', '1.35', '1']\n",
      "split LEE\n",
      "rowX2 ['8', 'YVETTE LEE ', ' 94', ' CG', ' Finals', ' 12', ' 1.35', ' 1', '  ']\n",
      "HERE2 ['8', 'YVETTE LEE ', ' ', ' 94', ' CG', ' Finals', ' 12', ' 1.35', ' 1', '  ', ' ', ' ']\n",
      "table[i] 9 ASHLYN THANARAJ 143 SNG Finals 3 1.35\n",
      "MATCH <re.Match object; span=(0, 1), match='9'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 19), match='9 ASHLYN THANARAJ 1'> qpos None\n",
      "LIST ['143', 'SNG', 'Finals', '3', '1.35']\n",
      "split THANARAJ\n",
      "rowX2 ['9', 'ASHLYN THANARAJ ', ' 143', ' SNG', ' Finals', ' 3', ' 1.35', '  ']\n",
      "HERE2 ['9', 'ASHLYN THANARAJ ', ' ', ' 143', ' SNG', ' Finals', ' 3', ' 1.35', '  ', ' ', ' ', ' ']\n",
      "table[i] 10 LAU REINA 459 SSP Finals 5 1.35\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 14), match='0 LAU REINA 4'> qpos None\n",
      "LIST ['459', 'SSP', 'Finals', '5', '1.35']\n",
      "split REINA\n",
      "rowX2 ['10', 'LAU REINA ', ' 459', ' SSP', ' Finals', ' 5', ' 1.35', '  ']\n",
      "HERE2 ['10', 'LAU REINA ', ' ', ' 459', ' SSP', ' Finals', ' 5', ' 1.35', '  ', ' ', ' ', ' ']\n",
      "table[i] 11 AMANDA CHUA JIA YING (CAI 337 NYGH Finals 8 1.25\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='1 AMANDA CHUA JIA YING (CAI 3'> qpos None\n",
      "LIST ['337', 'NYGH', 'Finals', '8', '1.25']\n",
      "split (CAI\n",
      "rowX2 ['11', 'AMANDA CHUA JIA YING (CAI ', ' 337', ' NYGH', ' Finals', ' 8', ' 1.25', '  ']\n",
      "HERE2 ['11', 'AMANDA CHUA JIA YING (CAI ', ' ', ' 337', ' NYGH', ' Finals', ' 8', ' 1.25', '  ', ' ', ' ', ' ']\n",
      "table[i] JIAYING)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] AMANDA CHUA JIA YING (CAI  table[i] JIAYING)\n",
      "padded full append list ['11', 'AMANDA CHUA JIA YING (CAI JIAYING)', ' ', ' 337', ' NYGH', ' Finals', ' 8', ' 1.25', '  ', ' ', ' ', ' ']\n",
      "table[i] 11 LEE XIN LE, GRACE 346 NYGH Finals 2 1.25\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='1 LEE XIN LE, GRACE 3'> qpos None\n",
      "LIST ['346', 'NYGH', 'Finals', '2', '1.25']\n",
      "split GRACE\n",
      "rowX2 ['11', 'LEE XIN LE, GRACE ', ' 346', ' NYGH', ' Finals', ' 2', ' 1.25', '  ']\n",
      "HERE2 ['11', 'LEE XIN LE, GRACE ', ' ', ' 346', ' NYGH', ' Finals', ' 2', ' 1.25', '  ', ' ', ' ', ' ']\n",
      "table[i] 11 ALLYSON CHOO JIA YI 139 SNG Finals 14 1.25\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='1 ALLYSON CHOO JIA YI 1'> qpos None\n",
      "LIST ['139', 'SNG', 'Finals', '14', '1.25']\n",
      "split YI\n",
      "rowX2 ['11', 'ALLYSON CHOO JIA YI ', ' 139', ' SNG', ' Finals', ' 14', ' 1.25', '  ']\n",
      "HERE2 ['11', 'ALLYSON CHOO JIA YI ', ' ', ' 139', ' SNG', ' Finals', ' 14', ' 1.25', '  ', ' ', ' ', ' ']\n",
      "table[i] NG LYN SHUEN 353 NYGH Finals 10 NM\n",
      "MATCH None <re.Match object; span=(31, 34), match=' NM'>\n",
      "NM XXX NG LYN SHUEN 353 NYGH Finals 10 NM\n",
      "list [' ', 'NG LYN SHUEN ', ' ', '353', 'NYGH', 'Finals', '10', ' ', ' ', ' ', 'NM', ' ']\n",
      "table[i] 11\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "S01-01_TO_11_deconstructed_10-13.pdf\n",
      "row string Event: S0l-07 100m - B DIVISION BOYS Heats SLFinals on\n",
      "event  S0l-07 100m \n",
      "session list ['S0l-07']\n",
      "session S0l-07\n",
      "division B \n",
      "gender Male\n",
      "table[i] 1 BRAYDEN CHAN WEI JIE Q 472 RI h4 1 00:11.25 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 25), match='1 BRAYDEN CHAN WEI JIE Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '472', 'RI', 'h4', '1', '00:11.25', '-0.2']\n",
      "split Q\n",
      "rowX ['1', 'BRAYDEN CHAN WEI JIE ', 'Q', ' 472', ' RI', ' h4', ' 1', ' 00:11.25', '  ', ' -0.2']\n",
      "table[i] 2 SONG EN XU REAGAN Q 86 ACS(!) h2 5 00:11.41 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='2 SONG EN XU REAGAN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '86', 'ACS(!)', 'h2', '5', '00:11.41', '-0.1']\n",
      "split Q\n",
      "rowX ['2', 'SONG EN XU REAGAN ', 'Q', ' 86', ' ACS(!)', ' h2', ' 5', ' 00:11.41', '  ', ' -0.1']\n",
      "table[i] 3 EMIR BIN MUHAMMAD RASHID Q 532 SSP h2 1 00:11.68 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 29), match='3 EMIR BIN MUHAMMAD RASHID Q '> qpos <re.Match object; span=(26, 28), match=' Q'>\n",
      "LIST ['', '532', 'SSP', 'h2', '1', '00:11.68', '-0.1']\n",
      "split Q\n",
      "rowX ['3', 'EMIR BIN MUHAMMAD RASHID ', 'Q', ' 532', ' SSP', ' h2', ' 1', ' 00:11.68', '  ', ' -0.1']\n",
      "table[i] 4 LOW WEI YI DILLON Q 118 BV h3 3 00: 11.692 -0.6 11.6917\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='4 LOW WEI YI DILLON Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '118', 'BV', 'h3', '3', '00:11.692', '-0.6', '11.6917']\n",
      "split Q\n",
      "rowX ['4', 'LOW WEI YI DILLON ', 'Q', ' 118', ' BV', ' h3', ' 3', ' 00:11.692', '  ', ' -0.6', ' 11.6917']\n",
      "table[i] 5 TONG XIAN YAO Q 89 ACS(I) hl 2 00: 11.692 +0.1 11.6920\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='5 TONG XIAN YAO Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '89', 'ACS(I)', 'hl', '2', '00:11.692', '+0.1', '11.6920']\n",
      "split Q\n",
      "rowX ['5', 'TONG XIAN YAO ', 'Q', ' 89', ' ACS(I)', ' hl', ' 2', ' 00:11.692', '  ', ' +0.1', ' 11.6920']\n",
      "table[i] 6 MIKAIL EMRE WIJAYA Q 596 SPS h4 5 00:11.88 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 23), match='6 MIKAIL EMRE WIJAYA Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '596', 'SPS', 'h4', '5', '00:11.88', '-0.2']\n",
      "split Q\n",
      "rowX ['6', 'MIKAIL EMRE WIJAYA ', 'Q', ' 596', ' SPS', ' h4', ' 5', ' 00:11.88', '  ', ' -0.2']\n",
      "table[i] 7 TONG ZONG WEI Q 351 HCI hl 3 00: 11.91 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='7 TONG ZONG WEI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '351', 'HCI', 'hl', '3', '00:11.91', '+0.1']\n",
      "split Q\n",
      "rowX ['7', 'TONG ZONG WEI ', 'Q', ' 351', ' HCI', ' hl', ' 3', ' 00:11.91', '  ', ' +0.1']\n",
      "table[i] 8 VEREK CHUA HAO EN Q 391 MSH h9 1 00:11.92 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='8'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='8 VEREK CHUA HAO EN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '391', 'MSH', 'h9', '1', '00:11.92', '+0.2']\n",
      "split Q\n",
      "rowX ['8', 'VEREK CHUA HAO EN ', 'Q', ' 391', ' MSH', ' h9', ' 1', ' 00:11.92', '  ', ' +0.2']\n",
      "table[i] 9 JAVEN TEO YI KIAT Q 591 SPS hl0 1 00: 11.94 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='9'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='9 JAVEN TEO YI KIAT Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '591', 'SPS', 'hl0', '1', '00:11.94', '+0.2']\n",
      "split Q\n",
      "rowX ['9', 'JAVEN TEO YI KIAT ', 'Q', ' 591', ' SPS', ' hl0', ' 1', ' 00:11.94', '  ', ' +0.2']\n",
      "table[i] 10 SEAN CHUA JAYANDRAN Q 604 SPS h9 2 00:11.95 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='0 SEAN CHUA JAYANDRAN Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '604', 'SPS', 'h9', '2', '00:11.95', '+0.2']\n",
      "split Q\n",
      "rowX ['10', 'SEAN CHUA JAYANDRAN ', 'Q', ' 604', ' SPS', ' h9', ' 2', ' 00:11.95', '  ', ' +0.2']\n",
      "table[i] 11 LIM HAI LE MARCUS Q 613 TK h3 1 00: 11.96 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='1 LIM HAI LE MARCUS Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '613', 'TK', 'h3', '1', '00:11.96', '-0.6']\n",
      "split Q\n",
      "rowX ['11', 'LIM HAI LE MARCUS ', 'Q', ' 613', ' TK', ' h3', ' 1', ' 00:11.96', '  ', ' -0.6']\n",
      "table[i] 12 JOSHUA LEE SHYEN Q 73 ACS(!) h5 8 00: 11.98 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='2 JOSHUA LEE SHYEN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '73', 'ACS(!)', 'h5', '8', '00:11.98', '+0.1']\n",
      "split Q\n",
      "rowX ['12', 'JOSHUA LEE SHYEN ', 'Q', ' 73', ' ACS(!)', ' h5', ' 8', ' 00:11.98', '  ', ' +0.1']\n",
      "table[i] 13 SIM JUN YANG AMBROSE Q 95 ACS(INT) h6 2 00:12.04 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 SIM JUN YANG AMBROSE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '95', 'ACS(INT)', 'h6', '2', '00:12.04', '+0.3']\n",
      "split Q\n",
      "rowX ['13', 'SIM JUN YANG AMBROSE ', 'Q', ' 95', ' ACS(INT)', ' h6', ' 2', ' 00:12.04', '  ', ' +0.3']\n",
      "table[i] 14 OH SHENG KAI Q 181 CH h13 1 00:12.07 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='4 OH SHENG KAI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '181', 'CH', 'h13', '1', '00:12.07', '-0.2']\n",
      "split Q\n",
      "rowX ['14', 'OH SHENG KAI ', 'Q', ' 181', ' CH', ' h13', ' 1', ' 00:12.07', '  ', ' -0.2']\n",
      "table[i] 15 ADRYAN RYZZKI HAQEEM BIN Q 650 us h7 4 00:12.08 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='5 ADRYAN RYZZKI HAQEEM BIN Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "LIST ['', '650', 'us', 'h7', '4', '00:12.08', '0.0']\n",
      "split Q\n",
      "rowX ['15', 'ADRYAN RYZZKI HAQEEM BIN ', 'Q', ' 650', ' us', ' h7', ' 4', ' 00:12.08', '  ', ' 0.0']\n",
      "table[i] ABDULLAH\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] ADRYAN RYZZKI HAQEEM BIN  table[i] ABDULLAH\n",
      "padded full append list ['15', 'ADRYAN RYZZKI HAQEEM BIN ABDULLAH', 'Q', ' 650', ' us', ' h7', ' 4', ' 00:12.08', '  ', ' 0.0', ' ', ' ']\n",
      "table[i] 16 JONATHAN CHU WEN JIE Q 580 SJI (INT) h13 3 00:12.12 -0.2 12.1159\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='6 JONATHAN CHU WEN JIE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '580', 'SJI', '(INT)', 'h13', '3', '00:12.12', '-0.2', '12.1159']\n",
      "split Q\n",
      "rowX ['16', 'JONATHAN CHU WEN JIE ', 'Q', ' 580', ' SJI', ' (INT)', ' h13', ' 3', '  ', ' 00:12.12', ' -0.2', ' 12.1159']\n",
      "table[i] 17 KIERAN LIM YONG XIANG Q 142 BTV h12 7 00:12.12 +0.4 12.1160\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 27), match='7 KIERAN LIM YONG XIANG Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "LIST ['', '142', 'BTV', 'h12', '7', '00:12.12', '+0.4', '12.1160']\n",
      "split Q\n",
      "rowX ['17', 'KIERAN LIM YONG XIANG ', 'Q', ' 142', ' BTV', ' h12', ' 7', ' 00:12.12', '  ', ' +0.4', ' 12.1160']\n",
      "table[i] 18 SHAREEQ ESHAN BIN Q 708 vs hl0 6 00:12.13 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='8 SHAREEQ ESHAN BIN Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '708', 'vs', 'hl0', '6', '00:12.13', '+0.2']\n",
      "split Q\n",
      "rowX ['18', 'SHAREEQ ESHAN BIN ', 'Q', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', '  ', ' +0.2']\n",
      "table[i] MUHAMMAD SHAHRIL\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] SHAREEQ ESHAN BIN  table[i] MUHAMMAD SHAHRIL\n",
      "padded full append list ['18', 'SHAREEQ ESHAN BIN MUHAMMAD SHAHRIL', 'Q', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', '  ', ' +0.2', ' ', ' ']\n",
      "table[i] 19 XAVIER IAN TEO SHEN MING Q 513 RI h3 7 00:12.16 -0.6 12.154\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='9 XAVIER IAN TEO SHEN MING Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "LIST ['', '513', 'RI', 'h3', '7', '00:12.16', '-0.6', '12.154']\n",
      "split Q\n",
      "rowX ['19', 'XAVIER IAN TEO SHEN MING ', 'Q', ' 513', ' RI', ' h3', ' 7', ' 00:12.16', '  ', ' -0.6', ' 12.154']\n",
      "table[i] 20 CHAN JIE YAO JEROME (ZENG Q 675 vs h13 6 00:12.16 -0.2 12.158\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='0 CHAN JIE YAO JEROME (ZENG Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "LIST ['', '675', 'vs', 'h13', '6', '00:12.16', '-0.2', '12.158']\n",
      "split Q\n",
      "rowX ['20', 'CHAN JIE YAO JEROME (ZENG ', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158']\n",
      "table[i] JIEYAO)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG  table[i] JIEYAO)\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158', ' ']\n",
      "table[i] t\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG JIEYAO) table[i] t\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)t', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158', ' ']\n",
      "table[i] 21 CHONG CHOON-HOU RAFAEL Q 319 HCI h5 1 00:12.20 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='1 CHONG CHOON-HOU RAFAEL Q '> qpos <re.Match object; span=(25, 27), match=' Q'>\n",
      "LIST ['', '319', 'HCI', 'h5', '1', '00:12.20', '+0.1']\n",
      "split Q\n",
      "rowX ['21', 'CHONG CHOON-HOU RAFAEL ', 'Q', ' 319', ' HCI', ' h5', ' 1', ' 00:12.20', '  ', ' +0.1']\n",
      "table[i] 22 RAFAEL PEDRO ORTEGA Q 540 SSP hl 1 00:12.22 +0.1 12.214\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='2 RAFAEL PEDRO ORTEGA Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '540', 'SSP', 'hl', '1', '00:12.22', '+0.1', '12.214']\n",
      "split Q\n",
      "rowX ['22', 'RAFAEL PEDRO ORTEGA ', 'Q', ' 540', ' SSP', ' hl', ' 1', ' 00:12.22', '  ', ' +0.1', ' 12.214']\n",
      "table[i] 23 ASHTON WONG YHU JHAE Q 552 SJI h7 1 00:12.22 0.0 12.215\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 ASHTON WONG YHU JHAE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '552', 'SJI', 'h7', '1', '00:12.22', '0.0', '12.215']\n",
      "split Q\n",
      "rowX ['23', 'ASHTON WONG YHU JHAE ', 'Q', ' 552', ' SJI', ' h7', ' 1', ' 00:12.22', '  ', ' 0.0', ' 12.215']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row string Event: S0l-07 100m - B DIVISION BOYS Heats SLFinals on\n",
      "event  S0l-07 100m \n",
      "session list ['S0l-07']\n",
      "session S0l-07\n",
      "division B \n",
      "gender Male\n",
      "table[i] 1 BRAYDEN CHAN WEI JIE Q 472 RI h4 1 00:11.25 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 25), match='1 BRAYDEN CHAN WEI JIE Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '472', 'RI', 'h4', '1', '00:11.25', '-0.2']\n",
      "split Q\n",
      "rowX ['1', 'BRAYDEN CHAN WEI JIE ', 'Q', ' 472', ' RI', ' h4', ' 1', ' 00:11.25', '  ', ' -0.2']\n",
      "table[i] 2 SONG EN XU REAGAN Q 86 ACS(!) h2 5 00:11.41 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='2 SONG EN XU REAGAN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '86', 'ACS(!)', 'h2', '5', '00:11.41', '-0.1']\n",
      "split Q\n",
      "rowX ['2', 'SONG EN XU REAGAN ', 'Q', ' 86', ' ACS(!)', ' h2', ' 5', ' 00:11.41', '  ', ' -0.1']\n",
      "table[i] 3 EMIR BIN MUHAMMAD RASHID Q 532 SSP h2 1 00:11.68 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 29), match='3 EMIR BIN MUHAMMAD RASHID Q '> qpos <re.Match object; span=(26, 28), match=' Q'>\n",
      "LIST ['', '532', 'SSP', 'h2', '1', '00:11.68', '-0.1']\n",
      "split Q\n",
      "rowX ['3', 'EMIR BIN MUHAMMAD RASHID ', 'Q', ' 532', ' SSP', ' h2', ' 1', ' 00:11.68', '  ', ' -0.1']\n",
      "table[i] 4 LOW WEI YI DILLON Q 118 BV h3 3 00: 11.692 -0.6 11.6917\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='4 LOW WEI YI DILLON Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '118', 'BV', 'h3', '3', '00:11.692', '-0.6', '11.6917']\n",
      "split Q\n",
      "rowX ['4', 'LOW WEI YI DILLON ', 'Q', ' 118', ' BV', ' h3', ' 3', ' 00:11.692', '  ', ' -0.6', ' 11.6917']\n",
      "table[i] 5 TONG XIAN YAO Q 89 ACS(I) hl 2 00: 11.692 +0.1 11.6920\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='5 TONG XIAN YAO Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '89', 'ACS(I)', 'hl', '2', '00:11.692', '+0.1', '11.6920']\n",
      "split Q\n",
      "rowX ['5', 'TONG XIAN YAO ', 'Q', ' 89', ' ACS(I)', ' hl', ' 2', ' 00:11.692', '  ', ' +0.1', ' 11.6920']\n",
      "table[i] 6 MIKAIL EMRE WIJAYA Q 596 SPS h4 5 00:11.88 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 23), match='6 MIKAIL EMRE WIJAYA Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '596', 'SPS', 'h4', '5', '00:11.88', '-0.2']\n",
      "split Q\n",
      "rowX ['6', 'MIKAIL EMRE WIJAYA ', 'Q', ' 596', ' SPS', ' h4', ' 5', ' 00:11.88', '  ', ' -0.2']\n",
      "table[i] 7 TONG ZONG WEI Q 351 HCI hl 3 00: 11.91 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='7 TONG ZONG WEI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '351', 'HCI', 'hl', '3', '00:11.91', '+0.1']\n",
      "split Q\n",
      "rowX ['7', 'TONG ZONG WEI ', 'Q', ' 351', ' HCI', ' hl', ' 3', ' 00:11.91', '  ', ' +0.1']\n",
      "table[i] 8 VEREK CHUA HAO EN Q 391 MSH h9 1 00:11.92 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='8'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='8 VEREK CHUA HAO EN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '391', 'MSH', 'h9', '1', '00:11.92', '+0.2']\n",
      "split Q\n",
      "rowX ['8', 'VEREK CHUA HAO EN ', 'Q', ' 391', ' MSH', ' h9', ' 1', ' 00:11.92', '  ', ' +0.2']\n",
      "table[i] 9 JAVEN TEO YI KIAT Q 591 SPS hl0 1 00: 11.94 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='9'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='9 JAVEN TEO YI KIAT Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '591', 'SPS', 'hl0', '1', '00:11.94', '+0.2']\n",
      "split Q\n",
      "rowX ['9', 'JAVEN TEO YI KIAT ', 'Q', ' 591', ' SPS', ' hl0', ' 1', ' 00:11.94', '  ', ' +0.2']\n",
      "table[i] 10 SEAN CHUA JAYANDRAN Q 604 SPS h9 2 00:11.95 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='0 SEAN CHUA JAYANDRAN Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '604', 'SPS', 'h9', '2', '00:11.95', '+0.2']\n",
      "split Q\n",
      "rowX ['10', 'SEAN CHUA JAYANDRAN ', 'Q', ' 604', ' SPS', ' h9', ' 2', ' 00:11.95', '  ', ' +0.2']\n",
      "table[i] 11 LIM HAI LE MARCUS Q 613 TK h3 1 00: 11.96 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='1 LIM HAI LE MARCUS Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '613', 'TK', 'h3', '1', '00:11.96', '-0.6']\n",
      "split Q\n",
      "rowX ['11', 'LIM HAI LE MARCUS ', 'Q', ' 613', ' TK', ' h3', ' 1', ' 00:11.96', '  ', ' -0.6']\n",
      "table[i] 12 JOSHUA LEE SHYEN Q 73 ACS(!) h5 8 00: 11.98 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='2 JOSHUA LEE SHYEN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '73', 'ACS(!)', 'h5', '8', '00:11.98', '+0.1']\n",
      "split Q\n",
      "rowX ['12', 'JOSHUA LEE SHYEN ', 'Q', ' 73', ' ACS(!)', ' h5', ' 8', ' 00:11.98', '  ', ' +0.1']\n",
      "table[i] 13 SIM JUN YANG AMBROSE Q 95 ACS(INT) h6 2 00:12.04 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 SIM JUN YANG AMBROSE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '95', 'ACS(INT)', 'h6', '2', '00:12.04', '+0.3']\n",
      "split Q\n",
      "rowX ['13', 'SIM JUN YANG AMBROSE ', 'Q', ' 95', ' ACS(INT)', ' h6', ' 2', ' 00:12.04', '  ', ' +0.3']\n",
      "table[i] 14 OH SHENG KAI Q 181 CH h13 1 00:12.07 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='4 OH SHENG KAI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '181', 'CH', 'h13', '1', '00:12.07', '-0.2']\n",
      "split Q\n",
      "rowX ['14', 'OH SHENG KAI ', 'Q', ' 181', ' CH', ' h13', ' 1', ' 00:12.07', '  ', ' -0.2']\n",
      "table[i] 15 ADRYAN RYZZKI HAQEEM BIN Q 650 us h7 4 00:12.08 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='5 ADRYAN RYZZKI HAQEEM BIN Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "LIST ['', '650', 'us', 'h7', '4', '00:12.08', '0.0']\n",
      "split Q\n",
      "rowX ['15', 'ADRYAN RYZZKI HAQEEM BIN ', 'Q', ' 650', ' us', ' h7', ' 4', ' 00:12.08', '  ', ' 0.0']\n",
      "table[i] ABDULLAH\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] ADRYAN RYZZKI HAQEEM BIN  table[i] ABDULLAH\n",
      "padded full append list ['15', 'ADRYAN RYZZKI HAQEEM BIN ABDULLAH', 'Q', ' 650', ' us', ' h7', ' 4', ' 00:12.08', '  ', ' 0.0', ' ', ' ']\n",
      "table[i] 16 JONATHAN CHU WEN JIE Q 580 SJI (INT) h13 3 00:12.12 -0.2 12.1159\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='6 JONATHAN CHU WEN JIE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '580', 'SJI', '(INT)', 'h13', '3', '00:12.12', '-0.2', '12.1159']\n",
      "split Q\n",
      "rowX ['16', 'JONATHAN CHU WEN JIE ', 'Q', ' 580', ' SJI', ' (INT)', ' h13', ' 3', '  ', ' 00:12.12', ' -0.2', ' 12.1159']\n",
      "table[i] 17 KIERAN LIM YONG XIANG Q 142 BTV h12 7 00:12.12 +0.4 12.1160\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 27), match='7 KIERAN LIM YONG XIANG Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "LIST ['', '142', 'BTV', 'h12', '7', '00:12.12', '+0.4', '12.1160']\n",
      "split Q\n",
      "rowX ['17', 'KIERAN LIM YONG XIANG ', 'Q', ' 142', ' BTV', ' h12', ' 7', ' 00:12.12', '  ', ' +0.4', ' 12.1160']\n",
      "table[i] 18 SHAREEQ ESHAN BIN Q 708 vs hl0 6 00:12.13 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='8 SHAREEQ ESHAN BIN Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '708', 'vs', 'hl0', '6', '00:12.13', '+0.2']\n",
      "split Q\n",
      "rowX ['18', 'SHAREEQ ESHAN BIN ', 'Q', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', '  ', ' +0.2']\n",
      "table[i] MUHAMMAD SHAHRIL\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] SHAREEQ ESHAN BIN  table[i] MUHAMMAD SHAHRIL\n",
      "padded full append list ['18', 'SHAREEQ ESHAN BIN MUHAMMAD SHAHRIL', 'Q', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', '  ', ' +0.2', ' ', ' ']\n",
      "table[i] 19 XAVIER IAN TEO SHEN MING Q 513 RI h3 7 00:12.16 -0.6 12.154\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='9 XAVIER IAN TEO SHEN MING Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "LIST ['', '513', 'RI', 'h3', '7', '00:12.16', '-0.6', '12.154']\n",
      "split Q\n",
      "rowX ['19', 'XAVIER IAN TEO SHEN MING ', 'Q', ' 513', ' RI', ' h3', ' 7', ' 00:12.16', '  ', ' -0.6', ' 12.154']\n",
      "table[i] 20 CHAN JIE YAO JEROME (ZENG Q 675 vs h13 6 00:12.16 -0.2 12.158\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='0 CHAN JIE YAO JEROME (ZENG Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "LIST ['', '675', 'vs', 'h13', '6', '00:12.16', '-0.2', '12.158']\n",
      "split Q\n",
      "rowX ['20', 'CHAN JIE YAO JEROME (ZENG ', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158']\n",
      "table[i] JIEYAO)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG  table[i] JIEYAO)\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158', ' ']\n",
      "table[i] t\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG JIEYAO) table[i] t\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)t', 'Q', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', '  ', ' -0.2', ' 12.158', ' ']\n",
      "table[i] 21 CHONG CHOON-HOU RAFAEL Q 319 HCI h5 1 00:12.20 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='1 CHONG CHOON-HOU RAFAEL Q '> qpos <re.Match object; span=(25, 27), match=' Q'>\n",
      "LIST ['', '319', 'HCI', 'h5', '1', '00:12.20', '+0.1']\n",
      "split Q\n",
      "rowX ['21', 'CHONG CHOON-HOU RAFAEL ', 'Q', ' 319', ' HCI', ' h5', ' 1', ' 00:12.20', '  ', ' +0.1']\n",
      "table[i] 22 RAFAEL PEDRO ORTEGA Q 540 SSP hl 1 00:12.22 +0.1 12.214\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='2 RAFAEL PEDRO ORTEGA Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '540', 'SSP', 'hl', '1', '00:12.22', '+0.1', '12.214']\n",
      "split Q\n",
      "rowX ['22', 'RAFAEL PEDRO ORTEGA ', 'Q', ' 540', ' SSP', ' hl', ' 1', ' 00:12.22', '  ', ' +0.1', ' 12.214']\n",
      "table[i] 23 ASHTON WONG YHU JHAE Q 552 SJI h7 1 00:12.22 0.0 12.215\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 ASHTON WONG YHU JHAE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '552', 'SJI', 'h7', '1', '00:12.22', '0.0', '12.215']\n",
      "split Q\n",
      "rowX ['23', 'ASHTON WONG YHU JHAE ', 'Q', ' 552', ' SJI', ' h7', ' 1', ' 00:12.22', '  ', ' 0.0', ' 12.215']\n",
      "table[i] 24 sA UZE MARTIN J EAN-RAYMOND Q 550 s G hl 2 4 00 :12.23 +0 .4\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 33), match='4 sA UZE MARTIN J EAN-RAYMOND Q '> qpos <re.Match object; span=(30, 32), match=' Q'>\n",
      "LIST ['', '550', 's', 'G', 'hl', '2', '4', '00', ':12.23', '+0', '.4']\n",
      "split Q\n",
      "rowX ['24', 'sA UZE MARTIN J EAN-RAYMOND ', 'Q', ' 550', ' s', ' G', ' hl', ' 2', '  ', ' 4', ' 00', ' :12.23', ' +0', ' .4']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [208], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtext\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m     55\u001b[0m     splitted\u001b[38;5;241m.\u001b[39mextend(temp)\n\u001b[0;32m---> 57\u001b[0m     temp_df\u001b[38;5;241m=\u001b[39m\u001b[43mextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m master_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([master_df, temp_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn [105], line 196\u001b[0m, in \u001b[0;36mextraction\u001b[0;34m(table, master_df)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW/G\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m columns: \u001b[38;5;66;03m# new format     \u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     master_df\u001b[38;5;241m=\u001b[39m\u001b[43mnew_format_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# call parser function\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSession\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39msession   \u001b[38;5;66;03m# add session  NEW\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDivision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdivision \u001b[38;5;66;03m# add division NEW\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [207], line 337\u001b[0m, in \u001b[0;36mnew_format_parser\u001b[0;34m(row_index, names, table, master_df)\u001b[0m\n\u001b[1;32m    333\u001b[0m     pad_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(row)\n\u001b[1;32m    335\u001b[0m     final_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mrow, \u001b[38;5;241m*\u001b[39m[pad_value] \u001b[38;5;241m*\u001b[39m pad_size]  \u001b[38;5;66;03m# add extra columns to make it 12\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     \u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m final_list\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrowX2\u001b[39m\u001b[38;5;124m'\u001b[39m, row)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:2306\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[1;32m   2304\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 2306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2308\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# 2023 ONLY #\n",
    "# Test iteration over more than one page and multiple files in directory\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1/S01-01_TO_11_deconstructed_22-25.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/Session_20.pdf\"\n",
    "\n",
    "directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1\"\n",
    "\n",
    "    \n",
    "    \n",
    "# Iterate over files in directory\n",
    "\n",
    "sorted_items=sort_directory(directory)\n",
    "\n",
    "temp_df=pd.DataFrame()  # initialize empty temp df\n",
    "\n",
    "master_df=pd.DataFrame()\n",
    "\n",
    "splitted=None\n",
    "\n",
    "print(sorted_items)\n",
    "\n",
    "for file in sorted_items:\n",
    "    \n",
    "    print(file)\n",
    "\n",
    "\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "        for i in range(len(pdf.pages)):\n",
    "        \n",
    "            temp=splitted\n",
    "        \n",
    "            page = pdf.pages[i]  # can iterate over different pages\n",
    "            table=page.extract_table()\n",
    "            text=page.extract_text()\n",
    "                \n",
    "            if i==0:\n",
    "        \n",
    "                splitted=text.splitlines()\n",
    "            \n",
    "                temp_df=extraction(splitted, temp_df)\n",
    "            \n",
    "            else: # stitch list from second page\n",
    "            \n",
    "                temp=text.splitlines()\n",
    "            \n",
    "                splitted.extend(temp)\n",
    "            \n",
    "                temp_df=extraction(splitted, temp_df)\n",
    "                        \n",
    "            master_df=pd.concat([master_df, temp_df], axis=0)\n",
    "\n",
    "\n",
    "            \n",
    "    #master_df=extraction(splitted, master_df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7a4b1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTED ['Updated On: 10-04-2023 Audited List', '4:52 PM', 'Event: S0l-07 100m - B DIVISION BOYS Heats SLFinals on', '505 SLFinals', 'on 505', 'Schools National Record Mak Lee Ren ACS(!) (ET)00: 10.59s 2022', 'Championships Record Hong Jinsheng JT 00: 10.8s 1985', 'Championships Record Joshua Chua Hanwei RI (ET)00: 10.87s 2016', 'POS Competitor Q Tag Team Heat Ln Result Pts W/G Remarks NR', '1 BRAYDEN CHAN WEI JIE Q 472 RI h4 1 00:11.25 -0.2', '2 SONG EN XU REAGAN Q 86 ACS(!) h2 5 00:11.41 -0.1', '3 EMIR BIN MUHAMMAD RASHID Q 532 SSP h2 1 00:11.68 -0.1', '4 LOW WEI YI DILLON Q 118 BV h3 3 00: 11.692 -0.6 11.6917', '5 TONG XIAN YAO Q 89 ACS(I) hl 2 00: 11.692 +0.1 11.6920', '6 MIKAIL EMRE WIJAYA Q 596 SPS h4 5 00:11.88 -0.2', '7 TONG ZONG WEI Q 351 HCI hl 3 00: 11.91 +0.1', '8 VEREK CHUA HAO EN Q 391 MSH h9 1 00:11.92 +0.2', '9 JAVEN TEO YI KIAT Q 591 SPS hl0 1 00: 11.94 +0.2', '10 SEAN CHUA JAYANDRAN Q 604 SPS h9 2 00:11.95 +0.2', '11 LIM HAI LE MARCUS Q 613 TK h3 1 00: 11.96 -0.6', '12 JOSHUA LEE SHYEN Q 73 ACS(!) h5 8 00: 11.98 +0.1', '13 SIM JUN YANG AMBROSE Q 95 ACS(INT) h6 2 00:12.04 +0.3', '14 OH SHENG KAI Q 181 CH h13 1 00:12.07 -0.2', '15 ADRYAN RYZZKI HAQEEM BIN Q 650 us h7 4 00:12.08 0.0', 'ABDULLAH', '16 JONATHAN CHU WEN JIE Q 580 SJI (INT) h13 3 00:12.12 -0.2 12.1159', '17 KIERAN LIM YONG XIANG Q 142 BTV h12 7 00:12.12 +0.4 12.1160', '18 SHAREEQ ESHAN BIN Q 708 vs hl0 6 00:12.13 +0.2', 'MUHAMMAD SHAHRIL', '19 XAVIER IAN TEO SHEN MING Q 513 RI h3 7 00:12.16 -0.6 12.154', '20 CHAN JIE YAO JEROME (ZENG Q 675 vs h13 6 00:12.16 -0.2 12.158', 'JIEYAO)', 't', '21 CHONG CHOON-HOU RAFAEL Q 319 HCI h5 1 00:12.20 +0.1', '22 RAFAEL PEDRO ORTEGA Q 540 SSP hl 1 00:12.22 +0.1 12.214', '23 ASHTON WONG YHU JHAE Q 552 SJI h7 1 00:12.22 0.0 12.215', '24 sA UZE MARTIN J EAN-RAYMOND Q 550 s G hl 2 4 00 :12.23 +0 .4', '25 TE 0 LIN 581 SJI (I NT) h8 8 00 :12.24 -0. 1', '26 KEE CHENGXI,TO MAS 169 CH h6 7 00 :12.26 +o .3', '27 GA N ZI RUI, TREV IS 323 HC I h2 6 00 :12.27 -0. 1', '28 TA N JING KHAI 407 NC H hl 1 6 00 :12.27 +0 .1', '29 LI M SONG CHERN JAYDEN 45 AC S(B R) hl 1 7 00 :12.28 +0 .1', '30 D ESHANN CAYDEN OOI 531 ss p h5 3 00 :12.33 +o .1', '31 NA SH SING HII LY NAM 663 us h6 6 00 :12.33 +o .3', '32 KW EK JIN TAO 402 NC H h3 2 00 :12.34 -0. 6', '33 H UDSON LIN 26 AI s hl 0 5 00 : 12.45 +0 .2', '34 M UHAMMAD RIZQ SYAHEED BIN 645 TM s hl 7 00 : 12.46 +o .1', 'A BDUL RAZAK', '35 PAN G CHENG HE NG 312 HY hl 1 5 00 : 12.46 +0 .1', '36 JA RREL KHOO YU FENG 638 TM s h2 3 00 : 12.47 -0. 1', '37 LOW YU XUAN, DA MIEN 175 CH hl 4 6 00 : 12.47 +0 .1', '38 w EI ZE AN 629 TK h5 7 00 : 12.49 +o .1', '39 KAYDEN LOW 691 vs h8 4 00 :12.50 -0. 1', '40 C HUA WEE TION G MELVIN 306 HY h9 4 00 :12.51 +0 .2', '41 M UHAMMAD ARFA N BIN NOOR 366 JY h6 4 00 :12.53 +0 .3', 'A RIFF', '42 0 NG HAO EN ZA CHARY 621 TK hl 1 8 00 :12.56 +o .1', '43 TA N YI XI CAEDM ON 429 NA S hl 2 2 00 :12.57 +o .4', '44 PAN G JING WEN LUCAS 666 us hl 4 5 00 :12.58 +0 .1', '45 EVA N LUAH KAY LE 140 BT V hl 6 00 :12.59 +0 .1', '46 IA N LEE RAY MIN G 557 SJ h6 3 00 :12.59 +o .3', '47 A QEEL FARHAN BI N KHAIRUL 430 NV h7 6 00 :12.60 0. 0', 'AZ MEE', '48 VE NKATACHALAPA THY NAREN 649 TM s hl 2 6 00 :12.60 +o .4', 'KARTHIK', '49 B RANDON TEO G UAN HAO 296 HSC h8 1 00 :12.64 -0. 1', '50 wO NG QIWEN KAV ENN 409 NC H h5 5 00 :12.64 +o .1', '51 LI M JUN JIE 435 NV hl 4 3 00 :12.65 +0 .1', '52 YA K YUN CHEN, JO VAN 246 D HS h7 7 00 :12.66 0. 0', '53 TA N WEI XIAN 14 A DSS h8 6 00 :12.69 -0. 1', '54 TI MOTHYWONG WEN FENG 97 AE s hl 4 4 00 :12.72 +o .1', '- - -- - - - - - -', '55 y OW HOI KIT, LUCA S 578 SJ hl 4 2 00 :12.73 +0 .1', '56 LEE ZHE ANN 362 JY h7 5 00 :12.77 0. 0', '57 IL HAN FAHEEM BI N ZAINAL 27 AIs h4 4 00 :12.82 -0. 2', 'A BIDIN', '58 FO0 SHIN WEI KEA NE 431 NV h6 1 00 :12.82 +0 .3', '59 LOH WEN JUN 117 BV h9 8 00 :12.83 +0 .2', '60 NG IA WEN CHEN 235 DY hl 4 00 :12.92 +o .1', '61 sA MUEL ONG HO NGYU 206 cc s hl 0 8 00 :12.93 +o .2', '62 LOW CHUN KAI 8 A DSS hl 3 7 00 :12.96 -0. 2', '63 JO NAS TUNG JIE JUN 387 MS H h4 6 00 :12.98 -0. 2', '64 TI TUS ANG 422 NJC hl 5 00 :13.01 +o .1', '65 TH AW ZIN 00 742 YCs h2 7 00 :13.03 -0. 1', '66 IS AIAH LING EN JI E 386 MS H hl 0 2 00 :13.03 +0 .2', '67 LI M ZHIRUI, ETHAN 116 BV h4 3 00 :13.04 -0. 2', '68 SE NTHIL KUMAR JERRIL VIVEK 738 YCs hl 1 1 00 :13.05 +0 .1', '69 LAI JAY YOUNG 487 RI h9 6 00 :13.07 +o .2', '70 wO NG YIT TERNG ETHAN 456 N USHS h8 5 00 :13.10 -0. 1', '71 TA N YI QUAN 208 cc s h4 8 00 :13.12 -0. 2', '72 JAY DEN CHEN HO NG YI 229 DY h2 8 00 :13.18 -0. 1', '73 TA I YI-HSUAN 244 D HS hl 2 1 00 :13.18 +o .4', '74 CH EN SIHENG LOU IS 297 HSC hl 0 3 00 :13.20 +o .2', '75 IA N CHAN 42 AC S(B R) h3 8 00 :13.23 -0. 6', '76 FO0 SHI MING CA DMUS 225 DY h5 6 00 :13.24 +0 .1', '77 DO NAGHAN FOO MING ZHOU 92 AC S(I NT) hl 2 5 00 : 13.41 +o .4', '78 YA MANO TETSU 719 ws ss h9 7 00 : 13.43 +o .2', '79 wA YNE CHONG Z HI QI 149 BT V h7 2 00 : 13.44 0. 0', '80 JA RRETT CHEW ME NG HERN 307 HY h3 6 00 : 13.44 -0. 6', '81 AS HRAF BIN HANA FI 358 JY hl 2 3 00 : 13.45 +o .4', '82 JOA QUIN HO TIN YIK (HE 718 ws ss h4 2 00 :13.50 -0. 2', 'TI NGYI)', '83 RI DZUAN BIN OT HMAN 224 C RS hl 1 4 00 :13.51 +0 .1', '84 z HANG SHUXING 457 N USHS hl 0 4 00 :13.62 +0 .2', '85 LO JUN WEI 129 BD M h2 2 00 :13.64 -0. 1', '86 wI LSON TAN RI KAI 107 BD S hl 0 7 00 :13.69 +o .2', '- - -- - - - - - -', '87 NUR HAERYL IHSAN BIN 380 JSS h8 7 00:13.81 -0.1', 'CHAIRILYANY', '88 MUHAMMAD FAIQ BIN MOHD 222 CRS h9 5 00:13.87 +0.2', 'FAM!', 't', '89 HAN YI XUAN, MIKEL 524 SST hll 3 00:13.94 +0.1', '90 NICHOLAS PANG XIANG RONG 301 HSC h4 7 00:13.97 -0.2', '91 LI JIAZHE 733 YCS h5 2 00:14.04 +0.1', '92 ETHAN KHALED MERNONE 104 BDS h8 3 00:14.05 -0.1', '93 MUHAMMAD SYAH IZWANDI BIN 223 CRS h3 4 00:14.11 -0.6', 'ABDULLAH', '94 KUMARESAN JAI VISHWA 417 NJC h2 4 00:14.19 -0.1', '95 BONG YEE TA 103 BDS h13 5 00:14.21 -0.2', '96 JERRY LIZ 7 ADSS h14 8 00:14.28 +0.1', '97 CHAN KIN YANG 720 WDL h3 5 00:14.34 -0.6', '98 GOH SHAO ZHI, CORNELIUS 202 ccs h8 2 00:14.50 -0.1', '99 MOHAMMAD FIRMAN SHAH BIN 31 AIS h9 3 00:14.78 +0.2', 'HAZLE', '100 KLAUS TAN WEI XIAN 128 BDM h5 4 00:14.84 +0.1', '101 ANDY ZHU WEI MING 371 JSS h14 7 00:14.91 +0.1', '102 ADEN CHIANG YU KAI 123 BDM hll 2 00:15.38 +0.1', '103 IMAN SHEIK AFKAR BIN 282 GOS h14 1 00:16.37 +0.1', 'MOHAMMAD ALI', '104 DANIEL YEOW BOON HOWE 280 GOS h6 5 00:17.05 +0.3', '105 LEWIS TAN KAI SHUEN 453 NUSHS h13 8 -0.2 DQ', '106 NG MING HAO DANIEL 94 ACS(INT) h7 3 0.0 DNS', '107 KHOR GIN WEI 375 JSS h13 2 -0.2 DNS', '108 NORD! BIN MAMAT 283 GOS h13 4 -0.2 DNS']\n",
      "row string Event: S0l-07 100m - B DIVISION BOYS Heats SLFinals on\n",
      "event  S0l-07 100m \n",
      "session list ['S0l-07']\n",
      "session S0l-07\n",
      "division B \n",
      "gender Male\n",
      "table[i] 1 BRAYDEN CHAN WEI JIE Q 472 RI h4 1 00:11.25 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 25), match='1 BRAYDEN CHAN WEI JIE Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['1', 'BRAYDEN CHAN WEI JIE ', ' ', ' 472', ' RI', ' h4', ' 1', ' 00:11.25', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] 2 SONG EN XU REAGAN Q 86 ACS(!) h2 5 00:11.41 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='2 SONG EN XU REAGAN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['2', 'SONG EN XU REAGAN ', ' ', ' 86', ' ACS(!)', ' h2', ' 5', ' 00:11.41', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 3 EMIR BIN MUHAMMAD RASHID Q 532 SSP h2 1 00:11.68 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 29), match='3 EMIR BIN MUHAMMAD RASHID Q '> qpos <re.Match object; span=(26, 28), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['3', 'EMIR BIN MUHAMMAD RASHID ', ' ', ' 532', ' SSP', ' h2', ' 1', ' 00:11.68', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 4 LOW WEI YI DILLON Q 118 BV h3 3 00: 11.692 -0.6 11.6917\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='4 LOW WEI YI DILLON Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['4', 'LOW WEI YI DILLON ', ' ', ' 118', ' BV', ' h3', ' 3', ' 00:11.692', ' -0.6', ' 11.6917', ' ', ' ']\n",
      "table[i] 5 TONG XIAN YAO Q 89 ACS(I) hl 2 00: 11.692 +0.1 11.6920\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='5 TONG XIAN YAO Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['5', 'TONG XIAN YAO ', ' ', ' 89', ' ACS(I)', ' hl', ' 2', ' 00:11.692', ' +0.1', ' 11.6920', ' ', ' ']\n",
      "table[i] 6 MIKAIL EMRE WIJAYA Q 596 SPS h4 5 00:11.88 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 23), match='6 MIKAIL EMRE WIJAYA Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['6', 'MIKAIL EMRE WIJAYA ', ' ', ' 596', ' SPS', ' h4', ' 5', ' 00:11.88', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] 7 TONG ZONG WEI Q 351 HCI hl 3 00: 11.91 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='7 TONG ZONG WEI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['7', 'TONG ZONG WEI ', ' ', ' 351', ' HCI', ' hl', ' 3', ' 00:11.91', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 8 VEREK CHUA HAO EN Q 391 MSH h9 1 00:11.92 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='8'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='8 VEREK CHUA HAO EN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['8', 'VEREK CHUA HAO EN ', ' ', ' 391', ' MSH', ' h9', ' 1', ' 00:11.92', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 9 JAVEN TEO YI KIAT Q 591 SPS hl0 1 00: 11.94 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='9'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='9 JAVEN TEO YI KIAT Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['9', 'JAVEN TEO YI KIAT ', ' ', ' 591', ' SPS', ' hl0', ' 1', ' 00:11.94', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 10 SEAN CHUA JAYANDRAN Q 604 SPS h9 2 00:11.95 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='0 SEAN CHUA JAYANDRAN Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['10', 'SEAN CHUA JAYANDRAN ', ' ', ' 604', ' SPS', ' h9', ' 2', ' 00:11.95', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 11 LIM HAI LE MARCUS Q 613 TK h3 1 00: 11.96 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='1 LIM HAI LE MARCUS Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['11', 'LIM HAI LE MARCUS ', ' ', ' 613', ' TK', ' h3', ' 1', ' 00:11.96', ' -0.6', ' ', ' ', ' ']\n",
      "table[i] 12 JOSHUA LEE SHYEN Q 73 ACS(!) h5 8 00: 11.98 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='2 JOSHUA LEE SHYEN Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['12', 'JOSHUA LEE SHYEN ', ' ', ' 73', ' ACS(!)', ' h5', ' 8', ' 00:11.98', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 13 SIM JUN YANG AMBROSE Q 95 ACS(INT) h6 2 00:12.04 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 SIM JUN YANG AMBROSE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['13', 'SIM JUN YANG AMBROSE ', ' ', ' 95', ' ACS(INT)', ' h6', ' 2', ' 00:12.04', ' +0.3', ' ', ' ', ' ']\n",
      "table[i] 14 OH SHENG KAI Q 181 CH h13 1 00:12.07 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='4 OH SHENG KAI Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['14', 'OH SHENG KAI ', ' ', ' 181', ' CH', ' h13', ' 1', ' 00:12.07', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] 15 ADRYAN RYZZKI HAQEEM BIN Q 650 us h7 4 00:12.08 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='5 ADRYAN RYZZKI HAQEEM BIN Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['15', 'ADRYAN RYZZKI HAQEEM BIN ', ' ', ' 650', ' us', ' h7', ' 4', ' 00:12.08', ' 0.0', ' ', ' ', ' ']\n",
      "table[i] ABDULLAH\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] ADRYAN RYZZKI HAQEEM BIN  table[i] ABDULLAH\n",
      "padded full append list ['15', 'ADRYAN RYZZKI HAQEEM BIN ABDULLAH', ' ', ' 650', ' us', ' h7', ' 4', ' 00:12.08', ' 0.0', ' ', ' ', ' ']\n",
      "table[i] 16 JONATHAN CHU WEN JIE Q 580 SJI (INT) h13 3 00:12.12 -0.2 12.1159\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='6 JONATHAN CHU WEN JIE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['16', 'JONATHAN CHU WEN JIE ', ' ', ' 580', ' SJI', ' (INT)', ' h13', ' 3', ' 00:12.12', ' -0.2', ' 12.1159', ' ']\n",
      "table[i] 17 KIERAN LIM YONG XIANG Q 142 BTV h12 7 00:12.12 +0.4 12.1160\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 27), match='7 KIERAN LIM YONG XIANG Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['17', 'KIERAN LIM YONG XIANG ', ' ', ' 142', ' BTV', ' h12', ' 7', ' 00:12.12', ' +0.4', ' 12.1160', ' ', ' ']\n",
      "table[i] 18 SHAREEQ ESHAN BIN Q 708 vs hl0 6 00:12.13 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='8 SHAREEQ ESHAN BIN Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['18', 'SHAREEQ ESHAN BIN ', ' ', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] MUHAMMAD SHAHRIL\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] SHAREEQ ESHAN BIN  table[i] MUHAMMAD SHAHRIL\n",
      "padded full append list ['18', 'SHAREEQ ESHAN BIN MUHAMMAD SHAHRIL', ' ', ' 708', ' vs', ' hl0', ' 6', ' 00:12.13', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 19 XAVIER IAN TEO SHEN MING Q 513 RI h3 7 00:12.16 -0.6 12.154\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='9 XAVIER IAN TEO SHEN MING Q '> qpos <re.Match object; span=(27, 29), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['19', 'XAVIER IAN TEO SHEN MING ', ' ', ' 513', ' RI', ' h3', ' 7', ' 00:12.16', ' -0.6', ' 12.154', ' ', ' ']\n",
      "table[i] 20 CHAN JIE YAO JEROME (ZENG Q 675 vs h13 6 00:12.16 -0.2 12.158\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='0 CHAN JIE YAO JEROME (ZENG Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['20', 'CHAN JIE YAO JEROME (ZENG ', ' ', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', ' -0.2', ' 12.158', ' ', ' ']\n",
      "table[i] JIEYAO)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG  table[i] JIEYAO)\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)', ' ', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', ' -0.2', ' 12.158', ' ', ' ']\n",
      "table[i] t\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHAN JIE YAO JEROME (ZENG JIEYAO) table[i] t\n",
      "padded full append list ['20', 'CHAN JIE YAO JEROME (ZENG JIEYAO)t', ' ', ' 675', ' vs', ' h13', ' 6', ' 00:12.16', ' -0.2', ' 12.158', ' ', ' ']\n",
      "table[i] 21 CHONG CHOON-HOU RAFAEL Q 319 HCI h5 1 00:12.20 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='1 CHONG CHOON-HOU RAFAEL Q '> qpos <re.Match object; span=(25, 27), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['21', 'CHONG CHOON-HOU RAFAEL ', ' ', ' 319', ' HCI', ' h5', ' 1', ' 00:12.20', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 22 RAFAEL PEDRO ORTEGA Q 540 SSP hl 1 00:12.22 +0.1 12.214\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='2 RAFAEL PEDRO ORTEGA Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['22', 'RAFAEL PEDRO ORTEGA ', ' ', ' 540', ' SSP', ' hl', ' 1', ' 00:12.22', ' +0.1', ' 12.214', ' ', ' ']\n",
      "table[i] 23 ASHTON WONG YHU JHAE Q 552 SJI h7 1 00:12.22 0.0 12.215\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='3 ASHTON WONG YHU JHAE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['23', 'ASHTON WONG YHU JHAE ', ' ', ' 552', ' SJI', ' h7', ' 1', ' 00:12.22', ' 0.0', ' 12.215', ' ', ' ']\n",
      "table[i] 24 SAUZE MARTIN JEAN-RAYMOND Q 550 s G hl 2 4 00:12.23 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='4 SAUZE MARTIN JEAN-RAYMOND Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "split Q\n",
      "HERE1 ['24', 'SAUZE MARTIN JEAN-RAYMOND ', ' ', ' 550', ' s', ' G', ' hl', ' 2', ' 4', ' 00:12.23', ' +0.4', ' ']\n",
      "table[i] 25 TEO LIN 581 SJI(INT) h8 8 00:12.24 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 12), match='5 TEO LIN 5'> qpos None\n",
      "split LIN\n",
      "row ['25', 'TEO LIN ', ' 581', ' SJI(INT)', ' h8', ' 8', ' 00:12.24', ' -0.1']\n",
      "HERE2 ['25', 'TEO LIN ', ' ', ' 581', ' SJI(INT)', ' h8', ' 8', ' 00:12.24', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 26 KEE CHENGXI,TO MAS 169 CH h6 7 00 :12.26 +o .3\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='6 KEE CHENGXI,TO MAS 1'> qpos None\n",
      "split MAS\n",
      "row ['26', 'KEE CHENGXI,TO MAS ', ' 169', ' CH', ' h6', ' 7', ' 00', ' :12.26', ' +o', ' .3']\n",
      "HERE2 ['26', 'KEE CHENGXI,TO MAS ', ' ', ' 169', ' CH', ' h6', ' 7', ' 00', ' :12.26', ' +o', ' .3', ' ']\n",
      "table[i] 27 GA N ZI RUI, TREV IS 323 HC I h2 6 00 :12.27 -0. 1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='7 GA N ZI RUI, TREV IS 3'> qpos None\n",
      "split IS\n",
      "row ['27', 'GA N ZI RUI, TREV IS ', ' 323', ' HC', ' I', ' h2', ' 6', ' 00', ' :12.27', ' -0.', ' 1']\n",
      "HERE2 ['27', 'GA N ZI RUI, TREV IS ', ' ', ' 323', ' HC', ' I', ' h2', ' 6', ' 00', ' :12.27', ' -0.', ' 1']\n",
      "table[i] 28 TAN JING KHAI 407 NC H hl 1 6 00 :12.27 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='8 TAN JING KHAI 4'> qpos None\n",
      "split KHAI\n",
      "row ['28', 'TAN JING KHAI ', ' 407', ' NC', ' H', ' hl', ' 1', ' 6', ' 00', ' :12.27', ' +0.1']\n",
      "HERE2 ['28', 'TAN JING KHAI ', ' ', ' 407', ' NC', ' H', ' hl', ' 1', ' 6', ' 00', ' :12.27', ' +0.1']\n",
      "table[i] 29 LIM SONG CHERN JAYDEN 45 ACS(BR) hl 1 7 00:12.28 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='9 LIM SONG CHERN JAYDEN 4'> qpos None\n",
      "split JAYDEN\n",
      "row ['29', 'LIM SONG CHERN JAYDEN ', ' 45', ' ACS(BR)', ' hl', ' 1', ' 7', ' 00:12.28', ' +0.1']\n",
      "HERE2 ['29', 'LIM SONG CHERN JAYDEN ', ' ', ' 45', ' ACS(BR)', ' hl', ' 1', ' 7', ' 00:12.28', ' +0.1', ' ', ' ']\n",
      "table[i] 30 D ESHANN CAYDEN OOI 531 ss p h5 3 00 :12.33 +o .1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='0 D ESHANN CAYDEN OOI 5'> qpos None\n",
      "split OOI\n",
      "row ['30', 'D ESHANN CAYDEN OOI ', ' 531', ' ss', ' p', ' h5', ' 3', ' 00', ' :12.33', ' +o', ' .1']\n",
      "HERE2 ['30', 'D ESHANN CAYDEN OOI ', ' ', ' 531', ' ss', ' p', ' h5', ' 3', ' 00', ' :12.33', ' +o', ' .1']\n",
      "table[i] 31 NA SH SING HII LY NAM 663 us h6 6 00 :12.33 +o .3\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='1 NA SH SING HII LY NAM 6'> qpos None\n",
      "split NAM\n",
      "row ['31', 'NA SH SING HII LY NAM ', ' 663', ' us', ' h6', ' 6', ' 00', ' :12.33', ' +o', ' .3']\n",
      "HERE2 ['31', 'NA SH SING HII LY NAM ', ' ', ' 663', ' us', ' h6', ' 6', ' 00', ' :12.33', ' +o', ' .3', ' ']\n",
      "table[i] 32 KW EK JIN TAO 402 NC H h3 2 00 :12.34 -0. 6\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='2 KW EK JIN TAO 4'> qpos None\n",
      "split TAO\n",
      "row ['32', 'KW EK JIN TAO ', ' 402', ' NC', ' H', ' h3', ' 2', ' 00', ' :12.34', ' -0.', ' 6']\n",
      "HERE2 ['32', 'KW EK JIN TAO ', ' ', ' 402', ' NC', ' H', ' h3', ' 2', ' 00', ' :12.34', ' -0.', ' 6']\n",
      "table[i] 33 HUDSON LIN 26 AI s hl 0 5 00:12.45 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 15), match='3 HUDSON LIN 2'> qpos None\n",
      "split LIN\n",
      "row ['33', 'HUDSON LIN ', ' 26', ' AI', ' s', ' hl', ' 0', ' 5', ' 00:12.45', ' +0.2']\n",
      "HERE2 ['33', 'HUDSON LIN ', ' ', ' 26', ' AI', ' s', ' hl', ' 0', ' 5', ' 00:12.45', ' +0.2', ' ']\n",
      "table[i] 34 MUHAMMAD RIZQ SYAHEED BIN 645 TM s hl 7 00:12.46 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='4 MUHAMMAD RIZQ SYAHEED BIN 6'> qpos None\n",
      "split BIN\n",
      "row ['34', 'MUHAMMAD RIZQ SYAHEED BIN ', ' 645', ' TM', ' s', ' hl', ' 7', ' 00:12.46', ' +0.1']\n",
      "HERE2 ['34', 'MUHAMMAD RIZQ SYAHEED BIN ', ' ', ' 645', ' TM', ' s', ' hl', ' 7', ' 00:12.46', ' +0.1', ' ', ' ']\n",
      "table[i] A BDUL RAZAK\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] MUHAMMAD RIZQ SYAHEED BIN  table[i] A BDUL RAZAK\n",
      "padded full append list ['34', 'MUHAMMAD RIZQ SYAHEED BIN A BDUL RAZAK', ' ', ' 645', ' TM', ' s', ' hl', ' 7', ' 00:12.46', ' +0.1', ' ', ' ']\n",
      "table[i] 35 PANG CHENG HENG 312 HY hl 1 5 00:12.46 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 20), match='5 PANG CHENG HENG 3'> qpos None\n",
      "split HENG\n",
      "row ['35', 'PANG CHENG HENG ', ' 312', ' HY', ' hl', ' 1', ' 5', ' 00:12.46', ' +0.1']\n",
      "HERE2 ['35', 'PANG CHENG HENG ', ' ', ' 312', ' HY', ' hl', ' 1', ' 5', ' 00:12.46', ' +0.1', ' ', ' ']\n",
      "table[i] 36 JARREL KHOO YU FENG 638 TM s h2 3 00:12.47 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='6 JARREL KHOO YU FENG 6'> qpos None\n",
      "split FENG\n",
      "row ['36', 'JARREL KHOO YU FENG ', ' 638', ' TM', ' s', ' h2', ' 3', ' 00:12.47', ' -0.1']\n",
      "HERE2 ['36', 'JARREL KHOO YU FENG ', ' ', ' 638', ' TM', ' s', ' h2', ' 3', ' 00:12.47', ' -0.1', ' ', ' ']\n",
      "table[i] 37 LOW YU XUAN, DA MIEN 175 CH hl 4 6 00 : 12.47 +0 .1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='7 LOW YU XUAN, DA MIEN 1'> qpos None\n",
      "split MIEN\n",
      "row ['37', 'LOW YU XUAN, DA MIEN ', ' 175', ' CH', ' hl', ' 4', ' 6', ' 00', ' :12.47', ' +0', ' .1']\n",
      "HERE2 ['37', 'LOW YU XUAN, DA MIEN ', ' ', ' 175', ' CH', ' hl', ' 4', ' 6', ' 00', ' :12.47', ' +0', ' .1']\n",
      "table[i] 38 WEI ZE AN 629 TK h5 7 00:12.49 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 14), match='8 WEI ZE AN 6'> qpos None\n",
      "split AN\n",
      "row ['38', 'WEI ZE AN ', ' 629', ' TK', ' h5', ' 7', ' 00:12.49', ' +0.1']\n",
      "HERE2 ['38', 'WEI ZE AN ', ' ', ' 629', ' TK', ' h5', ' 7', ' 00:12.49', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 39 KAYDEN LOW 691 vs h8 4 00:12.50 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 15), match='9 KAYDEN LOW 6'> qpos None\n",
      "split LOW\n",
      "row ['39', 'KAYDEN LOW ', ' 691', ' vs', ' h8', ' 4', ' 00:12.50', ' -0.1']\n",
      "HERE2 ['39', 'KAYDEN LOW ', ' ', ' 691', ' vs', ' h8', ' 4', ' 00:12.50', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 40 CHUA WEE TIONG MELVIN 306 HY h9 4 00:12.51 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='0 CHUA WEE TIONG MELVIN 3'> qpos None\n",
      "split MELVIN\n",
      "row ['40', 'CHUA WEE TIONG MELVIN ', ' 306', ' HY', ' h9', ' 4', ' 00:12.51', ' +0.2']\n",
      "HERE2 ['40', 'CHUA WEE TIONG MELVIN ', ' ', ' 306', ' HY', ' h9', ' 4', ' 00:12.51', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 41 MUHAMMAD ARFAN BIN NOOR 366 JY h6 4 00:12.53 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='1 MUHAMMAD ARFAN BIN NOOR 3'> qpos None\n",
      "split NOOR\n",
      "row ['41', 'MUHAMMAD ARFAN BIN NOOR ', ' 366', ' JY', ' h6', ' 4', ' 00:12.53', ' +0.3']\n",
      "HERE2 ['41', 'MUHAMMAD ARFAN BIN NOOR ', ' ', ' 366', ' JY', ' h6', ' 4', ' 00:12.53', ' +0.3', ' ', ' ', ' ']\n",
      "table[i] A RIFF\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] MUHAMMAD ARFAN BIN NOOR  table[i] A RIFF\n",
      "padded full append list ['41', 'MUHAMMAD ARFAN BIN NOOR A RIFF', ' ', ' 366', ' JY', ' h6', ' 4', ' 00:12.53', ' +0.3', ' ', ' ', ' ']\n",
      "table[i] 42 ONG HAO EN ZACHARY 621 TK hl 1 8 00:12.56 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='2 ONG HAO EN ZACHARY 6'> qpos None\n",
      "split ZACHARY\n",
      "row ['42', 'ONG HAO EN ZACHARY ', ' 621', ' TK', ' hl', ' 1', ' 8', ' 00:12.56', ' +0.1']\n",
      "HERE2 ['42', 'ONG HAO EN ZACHARY ', ' ', ' 621', ' TK', ' hl', ' 1', ' 8', ' 00:12.56', ' +0.1', ' ', ' ']\n",
      "table[i] 43 TAN YI XI CAEDMON 429 NA S hl 2 2 00:12.57 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='3 TAN YI XI CAEDMON 4'> qpos None\n",
      "split CAEDMON\n",
      "row ['43', 'TAN YI XI CAEDMON ', ' 429', ' NA', ' S', ' hl', ' 2', ' 2', ' 00:12.57', ' +0.4']\n",
      "HERE2 ['43', 'TAN YI XI CAEDMON ', ' ', ' 429', ' NA', ' S', ' hl', ' 2', ' 2', ' 00:12.57', ' +0.4', ' ']\n",
      "table[i] 44 PANG JING WEN LUCAS 666 us hl 4 5 00:12.58 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='4 PANG JING WEN LUCAS 6'> qpos None\n",
      "split LUCAS\n",
      "row ['44', 'PANG JING WEN LUCAS ', ' 666', ' us', ' hl', ' 4', ' 5', ' 00:12.58', ' +0.1']\n",
      "HERE2 ['44', 'PANG JING WEN LUCAS ', ' ', ' 666', ' us', ' hl', ' 4', ' 5', ' 00:12.58', ' +0.1', ' ', ' ']\n",
      "table[i] 45 EVAN LUAH KAY LE 140 BT V hl 6 00:12.59 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 21), match='5 EVAN LUAH KAY LE 1'> qpos None\n",
      "split LE\n",
      "row ['45', 'EVAN LUAH KAY LE ', ' 140', ' BT', ' V', ' hl', ' 6', ' 00:12.59', ' +0.1']\n",
      "HERE2 ['45', 'EVAN LUAH KAY LE ', ' ', ' 140', ' BT', ' V', ' hl', ' 6', ' 00:12.59', ' +0.1', ' ', ' ']\n",
      "table[i] 46 IAN LEE RAY MIN G 557 SJ h6 3 00:12.59 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='6 IAN LEE RAY MIN G 5'> qpos None\n",
      "split G\n",
      "row ['46', 'IAN LEE RAY MIN G ', ' 557', ' SJ', ' h6', ' 3', ' 00:12.59', ' +0.3']\n",
      "HERE2 ['46', 'IAN LEE RAY MIN G ', ' ', ' 557', ' SJ', ' h6', ' 3', ' 00:12.59', ' +0.3', ' ', ' ', ' ']\n",
      "table[i] 47 AQEEL FARHAN BIN KHAIRUL 430 NV h7 6 00:12.60 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 29), match='7 AQEEL FARHAN BIN KHAIRUL 4'> qpos None\n",
      "split KHAIRUL\n",
      "row ['47', 'AQEEL FARHAN BIN KHAIRUL ', ' 430', ' NV', ' h7', ' 6', ' 00:12.60', ' 0.0']\n",
      "HERE2 ['47', 'AQEEL FARHAN BIN KHAIRUL ', ' ', ' 430', ' NV', ' h7', ' 6', ' 00:12.60', ' 0.0', ' ', ' ', ' ']\n",
      "table[i] AZ MEE\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] AQEEL FARHAN BIN KHAIRUL  table[i] AZ MEE\n",
      "padded full append list ['47', 'AQEEL FARHAN BIN KHAIRUL AZ MEE', ' ', ' 430', ' NV', ' h7', ' 6', ' 00:12.60', ' 0.0', ' ', ' ', ' ']\n",
      "table[i] 48 VENKATACHALAPA THY NAREN 649 TM s hl 2 6 00:12.60 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 29), match='8 VENKATACHALAPA THY NAREN 6'> qpos None\n",
      "split NAREN\n",
      "row ['48', 'VENKATACHALAPA THY NAREN ', ' 649', ' TM', ' s', ' hl', ' 2', ' 6', ' 00:12.60', ' +0.4']\n",
      "HERE2 ['48', 'VENKATACHALAPA THY NAREN ', ' ', ' 649', ' TM', ' s', ' hl', ' 2', ' 6', ' 00:12.60', ' +0.4', ' ']\n",
      "table[i] KARTHIK\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] VENKATACHALAPA THY NAREN  table[i] KARTHIK\n",
      "padded full append list ['48', 'VENKATACHALAPA THY NAREN KARTHIK', ' ', ' 649', ' TM', ' s', ' hl', ' 2', ' 6', ' 00:12.60', ' +0.4', ' ']\n",
      "table[i] 49 BRANDON TEO GUAN HAO 296 HSC h8 1 00:12.64 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='9 BRANDON TEO GUAN HAO 2'> qpos None\n",
      "split HAO\n",
      "row ['49', 'BRANDON TEO GUAN HAO ', ' 296', ' HSC', ' h8', ' 1', ' 00:12.64', ' -0.1']\n",
      "HERE2 ['49', 'BRANDON TEO GUAN HAO ', ' ', ' 296', ' HSC', ' h8', ' 1', ' 00:12.64', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 50 WONG QIWEN KAV ENN 409 NC H h5 5 00:12.64 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='0 WONG QIWEN KAV ENN 4'> qpos <re.Match object; span=(7, 9), match=' Q'>\n",
      "split ENN\n",
      "row ['50', 'WONG QIWEN KAV ENN ', ' 409', ' NC', ' H', ' h5', ' 5', ' 00:12.64', ' +0.1']\n",
      "HERE2 ['50', 'WONG QIWEN KAV ENN ', ' ', ' 409', ' NC', ' H', ' h5', ' 5', ' 00:12.64', ' +0.1', ' ', ' ']\n",
      "table[i] 51 LIM JUN JIE 435 NV hl 4 3 00:12.65 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='1 LIM JUN JIE 4'> qpos None\n",
      "split JIE\n",
      "row ['51', 'LIM JUN JIE ', ' 435', ' NV', ' hl', ' 4', ' 3', ' 00:12.65', ' +0.1']\n",
      "HERE2 ['51', 'LIM JUN JIE ', ' ', ' 435', ' NV', ' hl', ' 4', ' 3', ' 00:12.65', ' +0.1', ' ', ' ']\n",
      "table[i] 52 YAK YUN CHEN, JO VAN 246 D HS h7 7 00:12.66 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='2 YAK YUN CHEN, JO VAN 2'> qpos None\n",
      "split VAN\n",
      "row ['52', 'YAK YUN CHEN, JO VAN ', ' 246', ' D', ' HS', ' h7', ' 7', ' 00:12.66', ' 0.0']\n",
      "HERE2 ['52', 'YAK YUN CHEN, JO VAN ', ' ', ' 246', ' D', ' HS', ' h7', ' 7', ' 00:12.66', ' 0.0', ' ', ' ']\n",
      "table[i] 53 TAN WEI XIAN 14 A DSS h8 6 00:12.69 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='3 TAN WEI XIAN 1'> qpos None\n",
      "split XIAN\n",
      "row ['53', 'TAN WEI XIAN ', ' 14', ' A', ' DSS', ' h8', ' 6', ' 00:12.69', ' -0.1']\n",
      "HERE2 ['53', 'TAN WEI XIAN ', ' ', ' 14', ' A', ' DSS', ' h8', ' 6', ' 00:12.69', ' -0.1', ' ', ' ']\n",
      "table[i] 54 TIMOTHY WONG WEN FENG 97 AE s hl 4 4 00:12.72 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='4 TIMOTHY WONG WEN FENG 9'> qpos None\n",
      "split FENG\n",
      "row ['54', 'TIMOTHY WONG WEN FENG ', ' 97', ' AE', ' s', ' hl', ' 4', ' 4', ' 00:12.72', ' +0.1']\n",
      "HERE2 ['54', 'TIMOTHY WONG WEN FENG ', ' ', ' 97', ' AE', ' s', ' hl', ' 4', ' 4', ' 00:12.72', ' +0.1', ' ']\n",
      "table[i] - - -- - - - - - -\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] TIMOTHY WONG WEN FENG  table[i] - - -- - - - - - -\n",
      "padded full append list ['54', 'TIMOTHY WONG WEN FENG - - -- - - - - - -', ' ', ' 97', ' AE', ' s', ' hl', ' 4', ' 4', ' 00:12.72', ' +0.1', ' ']\n",
      "table[i] 55 YOW HOI KIT, LUCAS 578 SJ hl 4 2 00:12.73 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='5 YOW HOI KIT, LUCAS 5'> qpos None\n",
      "split LUCAS\n",
      "row ['55', 'YOW HOI KIT, LUCAS ', ' 578', ' SJ', ' hl', ' 4', ' 2', ' 00:12.73', ' +0.1']\n",
      "HERE2 ['55', 'YOW HOI KIT, LUCAS ', ' ', ' 578', ' SJ', ' hl', ' 4', ' 2', ' 00:12.73', ' +0.1', ' ', ' ']\n",
      "table[i] 56 LEE ZHE ANN 362 JY h7 5 00:12.77 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='6 LEE ZHE ANN 3'> qpos None\n",
      "split ANN\n",
      "row ['56', 'LEE ZHE ANN ', ' 362', ' JY', ' h7', ' 5', ' 00:12.77', ' 0.0']\n",
      "HERE2 ['56', 'LEE ZHE ANN ', ' ', ' 362', ' JY', ' h7', ' 5', ' 00:12.77', ' 0.0', ' ', ' ', ' ']\n",
      "table[i] 57 IL HAN FAHEEM BIN ZAINAL 27 AIS h4 4 00:12.82 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 29), match='7 IL HAN FAHEEM BIN ZAINAL 2'> qpos None\n",
      "split ZAINAL\n",
      "row ['57', 'IL HAN FAHEEM BIN ZAINAL ', ' 27', ' AIS', ' h4', ' 4', ' 00:12.82', ' -0.2']\n",
      "HERE2 ['57', 'IL HAN FAHEEM BIN ZAINAL ', ' ', ' 27', ' AIS', ' h4', ' 4', ' 00:12.82', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] A BIDIN\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] IL HAN FAHEEM BIN ZAINAL  table[i] A BIDIN\n",
      "padded full append list ['57', 'IL HAN FAHEEM BIN ZAINAL A BIDIN', ' ', ' 27', ' AIS', ' h4', ' 4', ' 00:12.82', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] 58 FOO SHIN WEI KEANE 431 NV h6 1 00:12.82 +0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='8 FOO SHIN WEI KEANE 4'> qpos None\n",
      "split KEANE\n",
      "row ['58', 'FOO SHIN WEI KEANE ', ' 431', ' NV', ' h6', ' 1', ' 00:12.82', ' +0.3']\n",
      "HERE2 ['58', 'FOO SHIN WEI KEANE ', ' ', ' 431', ' NV', ' h6', ' 1', ' 00:12.82', ' +0.3', ' ', ' ', ' ']\n",
      "table[i] 59 LOH WEN JUN 117 BV h9 8 00:12.83 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='9 LOH WEN JUN 1'> qpos None\n",
      "split JUN\n",
      "row ['59', 'LOH WEN JUN ', ' 117', ' BV', ' h9', ' 8', ' 00:12.83', ' +0.2']\n",
      "HERE2 ['59', 'LOH WEN JUN ', ' ', ' 117', ' BV', ' h9', ' 8', ' 00:12.83', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 60 NGIA WEN CHEN 235 DY hl 4 00:12.92 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='0 NGIA WEN CHEN 2'> qpos None\n",
      "split CHEN\n",
      "row ['60', 'NGIA WEN CHEN ', ' 235', ' DY', ' hl', ' 4', ' 00:12.92', ' +0.1']\n",
      "HERE2 ['60', 'NGIA WEN CHEN ', ' ', ' 235', ' DY', ' hl', ' 4', ' 00:12.92', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 61 SAMUEL ONG HONG YU 206 CCS h10 8 00:12.93 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='1 SAMUEL ONG HONG YU 2'> qpos None\n",
      "split YU\n",
      "row ['61', 'SAMUEL ONG HONG YU ', ' 206', ' CCS', ' h10', ' 8', ' 00:12.93', ' +0.2']\n",
      "HERE2 ['61', 'SAMUEL ONG HONG YU ', ' ', ' 206', ' CCS', ' h10', ' 8', ' 00:12.93', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 62 LOW CHUN KAI 8 ADSS hl 3 7 00:12.96 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='2 LOW CHUN KAI 8'> qpos None\n",
      "split KAI\n",
      "row ['62', 'LOW CHUN KAI ', ' 8', ' ADSS', ' hl', ' 3', ' 7', ' 00:12.96', ' -0.2']\n",
      "HERE2 ['62', 'LOW CHUN KAI ', ' ', ' 8', ' ADSS', ' hl', ' 3', ' 7', ' 00:12.96', ' -0.2', ' ', ' ']\n",
      "table[i] 63 JONAS TUNG JIE JUN 387 MS H h4 6 00:12.98 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='3 JONAS TUNG JIE JUN 3'> qpos None\n",
      "split JUN\n",
      "row ['63', 'JONAS TUNG JIE JUN ', ' 387', ' MS', ' H', ' h4', ' 6', ' 00:12.98', ' -0.2']\n",
      "HERE2 ['63', 'JONAS TUNG JIE JUN ', ' ', ' 387', ' MS', ' H', ' h4', ' 6', ' 00:12.98', ' -0.2', ' ', ' ']\n",
      "table[i] 64 TITUS ANG 422 NJC hl 5 00:13.01 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 14), match='4 TITUS ANG 4'> qpos None\n",
      "split ANG\n",
      "row ['64', 'TITUS ANG ', ' 422', ' NJC', ' hl', ' 5', ' 00:13.01', ' +0.1']\n",
      "HERE2 ['64', 'TITUS ANG ', ' ', ' 422', ' NJC', ' hl', ' 5', ' 00:13.01', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 65 THAW ZIN OO 742 YCS h2 7 00:13.03 -0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='5 THAW ZIN OO 7'> qpos None\n",
      "split OO\n",
      "row ['65', 'THAW ZIN OO ', ' 742', ' YCS', ' h2', ' 7', ' 00:13.03', ' -0.1']\n",
      "HERE2 ['65', 'THAW ZIN OO ', ' ', ' 742', ' YCS', ' h2', ' 7', ' 00:13.03', ' -0.1', ' ', ' ', ' ']\n",
      "table[i] 66 ISAIAH LING EN JIE 386 MSH h10 2 00:13.03 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='6 ISAIAH LING EN JIE 3'> qpos None\n",
      "split JIE\n",
      "row ['66', 'ISAIAH LING EN JIE ', ' 386', ' MSH', ' h10', ' 2', ' 00:13.03', ' +0.2']\n",
      "HERE2 ['66', 'ISAIAH LING EN JIE ', ' ', ' 386', ' MSH', ' h10', ' 2', ' 00:13.03', ' +0.2', ' ', ' ', ' ']\n",
      "table[i] 67 LIM ZHIRUI, ETHAN 116 BV h4 3 00:13.04 -0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='7 LIM ZHIRUI, ETHAN 1'> qpos None\n",
      "split ETHAN\n",
      "row ['67', 'LIM ZHIRUI, ETHAN ', ' 116', ' BV', ' h4', ' 3', ' 00:13.04', ' -0.2']\n",
      "HERE2 ['67', 'LIM ZHIRUI, ETHAN ', ' ', ' 116', ' BV', ' h4', ' 3', ' 00:13.04', ' -0.2', ' ', ' ', ' ']\n",
      "table[i] 68 SENTHIL KUMAR JERRIL VIVEK 738 YCS h11 1 00:13.05 +0.1\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='8 SENTHIL KUMAR JERRIL VIVEK 7'> qpos None\n",
      "split VIVEK\n",
      "row ['68', 'SENTHIL KUMAR JERRIL VIVEK ', ' 738', ' YCS', ' h11', ' 1', ' 00:13.05', ' +0.1']\n",
      "HERE2 ['68', 'SENTHIL KUMAR JERRIL VIVEK ', ' ', ' 738', ' YCS', ' h11', ' 1', ' 00:13.05', ' +0.1', ' ', ' ', ' ']\n",
      "table[i] 69 LAI JAY YOUNG 487 RI h9 6 00 :13.07 +o .2\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='9 LAI JAY YOUNG 4'> qpos None\n",
      "split YOUNG\n",
      "row ['69', 'LAI JAY YOUNG ', ' 487', ' RI', ' h9', ' 6', ' 00', ' :13.07', ' +o', ' .2']\n",
      "HERE2 ['69', 'LAI JAY YOUNG ', ' ', ' 487', ' RI', ' h9', ' 6', ' 00', ' :13.07', ' +o', ' .2', ' ']\n",
      "table[i] 70 wO NG YIT TERNG ETHAN 456 N USHS h8 5 00 :13.10 -0. 1\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='0 wO NG YIT TERNG ETHAN 4'> qpos None\n",
      "split ETHAN\n",
      "row ['70', 'wO NG YIT TERNG ETHAN ', ' 456', ' N', ' USHS', ' h8', ' 5', ' 00', ' :13.10', ' -0.', ' 1']\n",
      "HERE2 ['70', 'wO NG YIT TERNG ETHAN ', ' ', ' 456', ' N', ' USHS', ' h8', ' 5', ' 00', ' :13.10', ' -0.', ' 1']\n",
      "table[i] 71 TA N YI QUAN 208 cc s h4 8 00 :13.12 -0. 2\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='1 TA N YI QUAN 2'> qpos <re.Match object; span=(10, 12), match=' Q'>\n",
      "split QUAN\n",
      "row ['71', 'TA N YI QUAN ', ' 208', ' cc', ' s', ' h4', ' 8', ' 00', ' :13.12', ' -0.', ' 2']\n",
      "HERE2 ['71', 'TA N YI QUAN ', ' ', ' 208', ' cc', ' s', ' h4', ' 8', ' 00', ' :13.12', ' -0.', ' 2']\n",
      "table[i] 72 JAY DEN CHEN HO NG YI 229 DY h2 8 00 :13.18 -0. 1\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='2 JAY DEN CHEN HO NG YI 2'> qpos None\n",
      "split YI\n",
      "row ['72', 'JAY DEN CHEN HO NG YI ', ' 229', ' DY', ' h2', ' 8', ' 00', ' :13.18', ' -0.', ' 1']\n",
      "HERE2 ['72', 'JAY DEN CHEN HO NG YI ', ' ', ' 229', ' DY', ' h2', ' 8', ' 00', ' :13.18', ' -0.', ' 1', ' ']\n",
      "table[i] 73 TA I YI-HSUAN 244 D HS hl 2 1 00 :13.18 +o .4\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='3 TA I YI-HSUAN 2'> qpos None\n",
      "split YI-HSUAN\n",
      "row ['73', 'TA I YI-HSUAN ', ' 244', ' D', ' HS', ' hl', ' 2', ' 1', ' 00', ' :13.18', ' +o', ' .4']\n",
      "HERE2 ['73', 'TA I YI-HSUAN ', ' ', ' 244', ' D', ' HS', ' hl', ' 2', ' 1', ' 00', ' :13.18', ' +o', ' .4']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [184], line 194\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m splitted[j] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m68 SE NTHIL KUMAR JERRIL VIVEK 738 YCs hl 1 1 00 :13.05 +0 .1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    191\u001b[0m         splitted[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m68 SENTHIL KUMAR JERRIL VIVEK 738 YCS h11 1 00:13.05 +0.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 194\u001b[0m master_df\u001b[38;5;241m=\u001b[39m\u001b[43mextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [105], line 196\u001b[0m, in \u001b[0;36mextraction\u001b[0;34m(table, master_df)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW/G\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m columns: \u001b[38;5;66;03m# new format     \u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     master_df\u001b[38;5;241m=\u001b[39m\u001b[43mnew_format_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# call parser function\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSession\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39msession   \u001b[38;5;66;03m# add session  NEW\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDivision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdivision \u001b[38;5;66;03m# add division NEW\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [183], line 359\u001b[0m, in \u001b[0;36mnew_format_parser\u001b[0;34m(row_index, names, table, master_df)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHERE2\u001b[39m\u001b[38;5;124m'\u001b[39m, final_list)\n\u001b[1;32m    356\u001b[0m                 \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m.\u001b[39mappend(final_list)\n\u001b[0;32m--> 359\u001b[0m                 \u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m final_list\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# QAed to this point for a stranded pdf. Need to figure out how to attach stranded row to master df\u001b[39;00m\n\u001b[1;32m    366\u001b[0m             \n\u001b[1;32m    367\u001b[0m             \n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m#            master_df=new_df      # previous   \u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:2306\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[1;32m   2304\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 2306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2308\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# 2023 ONLY #\n",
    "# NEW TEST CODE#\n",
    "\n",
    "# Test iteration over more than one page and multiple files in directory\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\n",
    "\n",
    "file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1/S01-01_TO_11_deconstructed_10-13.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/Session_20.pdf\"\n",
    "\n",
    "#directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1\"\n",
    "\n",
    "    \n",
    "    \n",
    "# Iterate over files in directory\n",
    "\n",
    "#sorted_items=sort_directory(directory)\n",
    "\n",
    "temp_df=pd.DataFrame()  # initialize empty temp df\n",
    "\n",
    "master_df=pd.DataFrame()\n",
    "\n",
    "splitted=None\n",
    "\n",
    "#print(sorted_items)\n",
    "\n",
    "#for file in sorted_items:\n",
    "    \n",
    "#    print(file)\n",
    "\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "    for i in range(len(pdf.pages)):\n",
    "        \n",
    "        temp=splitted\n",
    "        \n",
    "        page = pdf.pages[i]  # can iterate over different pages\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()\n",
    "                \n",
    "        if i==0:\n",
    "        \n",
    "            splitted=text.splitlines()\n",
    "            \n",
    "     #       temp_df=extraction(splitted, temp_df)\n",
    "            \n",
    "        else: # stitch following pages to create one continuous page\n",
    "            \n",
    "            temp=text.splitlines()\n",
    "            \n",
    "            splitted.extend(temp)\n",
    "            \n",
    "       #     temp_df=extraction(splitted, temp_df)\n",
    "                        \n",
    "       # master_df=pd.concat([master_df, temp_df], axis=0)\n",
    "\n",
    "print('SPLITTED', splitted)\n",
    "\n",
    "# Correct formatting errors in source data\n",
    "\n",
    "for j in range(len(splitted)):\n",
    "    \n",
    "    if splitted[j] == '24 sA UZE MARTIN J EAN-RAYMOND Q 550 s G hl 2 4 00 :12.23 +0 .4':\n",
    "        splitted[j] = '24 SAUZE MARTIN JEAN-RAYMOND Q 550 s G hl 2 4 00:12.23 +0.4'\n",
    "               \n",
    "    if splitted[j] == '25 TE 0 LIN 581 SJI (I NT) h8 8 00 :12.24 -0. 1':\n",
    "        splitted[j] = '25 TEO LIN 581 SJI(INT) h8 8 00:12.24 -0.1'\n",
    "        \n",
    "    if splitted[j] == '28 TA N JING KHAI 407 NC H hl 1 6 00 :12.27 +0 .1':\n",
    "        splitted[j] = '28 TAN JING KHAI 407 NC H hl 1 6 00 :12.27 +0.1'\n",
    "        \n",
    "    if splitted[j] == '29 LI M SONG CHERN JAYDEN 45 AC S(B R) hl 1 7 00 :12.28 +0 .1':\n",
    "        splitted[j] = '29 LIM SONG CHERN JAYDEN 45 ACS(BR) hl 1 7 00:12.28 +0.1'\n",
    "        \n",
    "    if splitted[j] == '33 H UDSON LIN 26 AI s hl 0 5 00 : 12.45 +0 .2':\n",
    "        splitted[j] = '33 HUDSON LIN 26 AI s hl 0 5 00:12.45 +0.2'\n",
    "        \n",
    "    if splitted[j] == '34 M UHAMMAD RIZQ SYAHEED BIN 645 TM s hl 7 00 : 12.46 +o .1':\n",
    "        splitted[j] = '34 MUHAMMAD RIZQ SYAHEED BIN 645 TM s hl 7 00:12.46 +0.1'\n",
    "\n",
    "    if splitted[j] == '35 PAN G CHENG HE NG 312 HY hl 1 5 00 : 12.46 +0 .1':\n",
    "        splitted[j] = '35 PANG CHENG HENG 312 HY hl 1 5 00:12.46 +0.1'\n",
    "\n",
    "    if splitted[j] == '36 JA RREL KHOO YU FENG 638 TM s h2 3 00 : 12.47 -0. 1':\n",
    "        splitted[j] = '36 JARREL KHOO YU FENG 638 TM s h2 3 00:12.47 -0.1'\n",
    "\n",
    "    if splitted[j] == '38 w EI ZE AN 629 TK h5 7 00 : 12.49 +o .1':\n",
    "        splitted[j] = '38 WEI ZE AN 629 TK h5 7 00:12.49 +0.1'\n",
    "\n",
    "    if splitted[j] == '39 KAYDEN LOW 691 vs h8 4 00 :12.50 -0. 1':\n",
    "        splitted[j] = '39 KAYDEN LOW 691 vs h8 4 00:12.50 -0.1'\n",
    "\n",
    "    if splitted[j] == '40 C HUA WEE TION G MELVIN 306 HY h9 4 00 :12.51 +0 .2':\n",
    "        splitted[j] = '40 CHUA WEE TIONG MELVIN 306 HY h9 4 00:12.51 +0.2'\n",
    "\n",
    "    if splitted[j] == '41 M UHAMMAD ARFA N BIN NOOR 366 JY h6 4 00 :12.53 +0 .3':\n",
    "        splitted[j] = '41 MUHAMMAD ARFAN BIN NOOR 366 JY h6 4 00:12.53 +0.3'\n",
    "\n",
    "    if splitted[j] == '42 0 NG HAO EN ZA CHARY 621 TK hl 1 8 00 :12.56 +o .1':\n",
    "        splitted[j] = '42 ONG HAO EN ZACHARY 621 TK hl 1 8 00:12.56 +0.1'\n",
    "\n",
    "    if splitted[j] == '43 TA N YI XI CAEDM ON 429 NA S hl 2 2 00 :12.57 +o .4':\n",
    "        splitted[j] = '43 TAN YI XI CAEDMON 429 NA S hl 2 2 00:12.57 +0.4'\n",
    "\n",
    "    if splitted[j] == '44 PAN G JING WEN LUCAS 666 us hl 4 5 00 :12.58 +0 .1':\n",
    "        splitted[j] = '44 PANG JING WEN LUCAS 666 us hl 4 5 00:12.58 +0.1'\n",
    "\n",
    "    if splitted[j] == '45 EVA N LUAH KAY LE 140 BT V hl 6 00 :12.59 +0 .1':\n",
    "        splitted[j] = '45 EVAN LUAH KAY LE 140 BT V hl 6 00:12.59 +0.1'\n",
    "\n",
    "    if splitted[j] == '46 IA N LEE RAY MIN G 557 SJ h6 3 00 :12.59 +o .3':\n",
    "        splitted[j] = '46 IAN LEE RAY MIN G 557 SJ h6 3 00:12.59 +0.3'\n",
    "\n",
    "    if splitted[j] == '47 A QEEL FARHAN BI N KHAIRUL 430 NV h7 6 00 :12.60 0. 0':\n",
    "        splitted[j] = '47 AQEEL FARHAN BIN KHAIRUL 430 NV h7 6 00:12.60 0.0'\n",
    "\n",
    "    if splitted[j] == '48 VE NKATACHALAPA THY NAREN 649 TM s hl 2 6 00 :12.60 +o .4':\n",
    "        splitted[j] = '48 VENKATACHALAPA THY NAREN 649 TM s hl 2 6 00:12.60 +0.4'\n",
    "\n",
    "    if splitted[j] == '49 B RANDON TEO G UAN HAO 296 HSC h8 1 00 :12.64 -0. 1':\n",
    "        splitted[j] = '49 BRANDON TEO GUAN HAO 296 HSC h8 1 00:12.64 -0.1'\n",
    "        \n",
    "    if splitted[j] == '50 wO NG QIWEN KAV ENN 409 NC H h5 5 00 :12.64 +o .1':\n",
    "        splitted[j] = '50 WONG QIWEN KAV ENN 409 NC H h5 5 00:12.64 +0.1'\n",
    "\n",
    "    if splitted[j] == '51 LI M JUN JIE 435 NV hl 4 3 00 :12.65 +0 .1':\n",
    "        splitted[j] = '51 LIM JUN JIE 435 NV hl 4 3 00:12.65 +0.1'\n",
    "\n",
    "    if splitted[j] == '52 YA K YUN CHEN, JO VAN 246 D HS h7 7 00 :12.66 0. 0':\n",
    "        splitted[j] = '52 YAK YUN CHEN, JO VAN 246 D HS h7 7 00:12.66 0.0'\n",
    "\n",
    "    if splitted[j] == '53 TA N WEI XIAN 14 A DSS h8 6 00 :12.69 -0. 1':\n",
    "        splitted[j] = '53 TAN WEI XIAN 14 A DSS h8 6 00:12.69 -0.1'\n",
    "\n",
    "    if splitted[j] == '54 TI MOTHYWONG WEN FENG 97 AE s hl 4 4 00 :12.72 +o .1':\n",
    "        splitted[j] = '54 TIMOTHY WONG WEN FENG 97 AE s hl 4 4 00:12.72 +0.1'\n",
    "\n",
    "    if splitted[j] == '55 y OW HOI KIT, LUCA S 578 SJ hl 4 2 00 :12.73 +0 .1':\n",
    "        splitted[j] = '55 YOW HOI KIT, LUCAS 578 SJ hl 4 2 00:12.73 +0.1'\n",
    "        \n",
    "    if splitted[j] == '56 LEE ZHE ANN 362 JY h7 5 00 :12.77 0. 0':\n",
    "        splitted[j] = '56 LEE ZHE ANN 362 JY h7 5 00:12.77 0.0'\n",
    "  \n",
    "    if splitted[j] == '57 IL HAN FAHEEM BI N ZAINAL 27 AIs h4 4 00 :12.82 -0. 2':\n",
    "        splitted[j] = '57 IL HAN FAHEEM BIN ZAINAL 27 AIS h4 4 00:12.82 -0.2'\n",
    "\n",
    "    if splitted[j] == '58 FO0 SHIN WEI KEA NE 431 NV h6 1 00 :12.82 +0 .3':\n",
    "        splitted[j] = '58 FOO SHIN WEI KEANE 431 NV h6 1 00:12.82 +0.3'\n",
    "        \n",
    "    if splitted[j] == '59 LOH WEN JUN 117 BV h9 8 00 :12.83 +0 .2':\n",
    "        splitted[j] = '59 LOH WEN JUN 117 BV h9 8 00:12.83 +0.2'\n",
    "   \n",
    "    if splitted[j] == '60 NG IA WEN CHEN 235 DY hl 4 00 :12.92 +o .1':\n",
    "        splitted[j] = '60 NGIA WEN CHEN 235 DY hl 4 00:12.92 +0.1'\n",
    "\n",
    "    if splitted[j] == '61 sA MUEL ONG HO NGYU 206 cc s hl 0 8 00 :12.93 +o .2':\n",
    "        splitted[j] = '61 SAMUEL ONG HONG YU 206 CCS h10 8 00:12.93 +0.2'\n",
    "\n",
    "    if splitted[j] == '62 LOW CHUN KAI 8 A DSS hl 3 7 00 :12.96 -0. 2':\n",
    "        splitted[j] = '62 LOW CHUN KAI 8 ADSS hl 3 7 00:12.96 -0.2'\n",
    "\n",
    "    if splitted[j] == '63 JO NAS TUNG JIE JUN 387 MS H h4 6 00 :12.98 -0. 2':\n",
    "        splitted[j] = '63 JONAS TUNG JIE JUN 387 MS H h4 6 00:12.98 -0.2'\n",
    "\n",
    "    if splitted[j] == '64 TI TUS ANG 422 NJC hl 5 00 :13.01 +o .1':\n",
    "        splitted[j] = '64 TITUS ANG 422 NJC hl 5 00:13.01 +0.1'\n",
    "\n",
    "    if splitted[j] == '65 TH AW ZIN 00 742 YCs h2 7 00 :13.03 -0. 1':\n",
    "        splitted[j] = '65 THAW ZIN OO 742 YCS h2 7 00:13.03 -0.1'\n",
    "\n",
    "    if splitted[j] == '66 IS AIAH LING EN JI E 386 MS H hl 0 2 00 :13.03 +0 .2':\n",
    "        splitted[j] = '66 ISAIAH LING EN JIE 386 MSH h10 2 00:13.03 +0.2'\n",
    "\n",
    "\n",
    "    if splitted[j] == '66 IS AIAH LING EN JI E 386 MS H hl 0 2 00 :13.03 +0 .2':\n",
    "        splitted[j] = '66 ISAIAH LING EN JIE 386 MSH h10 2 00:13.03 +0.2'\n",
    "\n",
    "    if splitted[j] == '67 LI M ZHIRUI, ETHAN 116 BV h4 3 00 :13.04 -0. 2':\n",
    "        splitted[j] = '67 LIM ZHIRUI, ETHAN 116 BV h4 3 00:13.04 -0.2'\n",
    "  \n",
    "    if splitted[j] == '67 LI M ZHIRUI, ETHAN 116 BV h4 3 00 :13.04 -0. 2':\n",
    "        splitted[j] = '67 LIM ZHIRUI, ETHAN 116 BV h4 3 00:13.04 -0.2'\n",
    "\n",
    "    if splitted[j] == '68 SE NTHIL KUMAR JERRIL VIVEK 738 YCs hl 1 1 00 :13.05 +0 .1':\n",
    "        splitted[j] = '68 SENTHIL KUMAR JERRIL VIVEK 738 YCS h11 1 00:13.05 +0.1'\n",
    "\n",
    "\n",
    "master_df=extraction(splitted, master_df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "44a25e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTED ['Updated On: 10-04-2023 Audited List', '4:34 PM', 'Event: S0l-08 100m - B DIVISION GIRLS Heats SlFinals on', 'S05 SlFinals', 'on S05', 'Schools National Record Prema Govindan AMK 00: 12.0s 1983', 'Schools National Record Ismi Zakiah Bte Kashful Anwar SSP (ET)00:12.35s 2018', 'Championships Record Mona Kunalan STC 00: 12.2s 1987', 'Championships Record Bernice Liew Yee Ling NYG (ET)00:12.37s 2018', 'POS Competitor Q Tag Team Heat Ln Result Pts W/G Remarks NR', '1 TEH YING SHAN Q 528 CCHY h8 8 00: 12.94 +0.7', '2 CHLOE CHEE EN-YA Q 309 MGS h6 1 00: 13.17 -0.5', '3 JAYME NG SOK CHEE Q 156 SNG h9 2 00: 13.25 +0.4', '4 MEGAN ANNE YING KA MUN Q 76 CG h9 1 00: 13.27 +0.4', '5 SOH HWEI EN, RACHEL (SU Q 358 NYGH h3 1 00: 13.30 -0.3', \"HUI'EN RACHEL)\", '6 LIM YEE CHERN CLARA Q 440 RGS h8 4 00: 13.33 +0.7', '7 KOH JING XUAN, BERNYCE Q 457 SSP h6 5 00: 13.39 -0.5', '8 NEO EN YU Q 462 SSP h5 4 00:13.43 -0.6', '9 EMILY ANNE CHOI YI SIU Q 182 STC h4 7 00: 13.50 +0.2', '10 ELIZABETH LEE SHYIN Q 149 SNG h6 8 00: 13.57 -0.5', '11 KOH SHI XUAN, BEVLYN Q 458 SSP h9 3 00: 13.69 +0.4', '12 CHLOE SARAHENA TAN HUI EN Q 120 HIJ h7 4 00: 13.72 -0.4', '13 SOH YING SHARLENE Q 83 CG h5 6 00: 13.80 -0.6', '14 NG LIN YEE CAYLYNE Q 416 PLMGS h2 5 00: 13.98 0.0', '15 TNG YUE EN Q 252 OHS h2 1 00: 14.06 0.0 f', '16 YEO PEY WENN Q 448 RGS h3 7 00: 14.15 -0.3', '17 SHANNON POK HENN YEE Q 453 SST hll 4 00: 14.21 -0.9', '18 LAI REI EN Q 438 RGS hlO 4 00: 14.22 -1.0', '19 YEOW KAI XIN, CHARIS Q 175 SNG h5 2 00: 14.26 -0.6', '20 AYRA AZMAN TAN Q 47 CG h6 3 00: 14.31 -0.5', '21 AMANDA CHUA JIA YING (CAI Q 337 NYGH h8 6 00: 14.44 +0.7', 'JIAYING)', '22 SHARIFFAH NABILAH CHISHTY Q 500 TMS hl 6 00: 14.51 -0.3', 'l', '23 ARINA CHERNOVA Q 21 ACS(INT) h2 2 00: 14.56 0.0', '24 JEANETTE LIM KA NGTING Q 322 NCH h2 8 00: 14.58 0.0', '25 CAI YAWEN 37 BTV h7 5 00: 14.60 -0.4', '26 DRAGON CAITLI N ANNE 107 KC h8 7 00: 14.61 +0.7', '27 CHERELLE LOW (LIU XUAN) 468 SAC h4 4 00: 14.61 +0.2', '28 TANG LOK-YEE M ERRILYN 492 TK h7 2 00: 14.74 -0.4', '29 YERIN LEYSEN 385 NJC hl 5 00: 14.77 -0.3', '30 SOH WEN XIN 479 SAC h8 2 00: 14.88 +0.7', '31 RUBY TJIPTO 466 SPF h2 6 00: 14.90 0.0', '32 DANIELLE GOH 279 GDL h8 1 00: 14.93 +0.7', '33 CRYSTAL LAI JIA MIN 230 DY hll 5 00: 14.96 -0.9', '34 KIMBERLY YONG LI KIM 110 KC h3 3 00: 15.03 -0.3', '35 KYLA MAK YA XUA N 124 HIJ hll 8 00: 15.04 -0.9', '36 LEONG SOOK MEI (LIANG 470 SAC hl0 3 00: 15.07 -1.0', 'SHUWEI)', '37 KAN REN TONG KAYLER 186 STC hlO 5 00: 15.09 -1.0', '38 GAN MIN WEN LAU REN 246 DHS h9 7 00: 15.10 +0.4', '39 MASYA SUFIA BI NTI 454 ss hl 1 00:15.21 -0.3', 'MUHAMMAD RID HUAN', '40 NUHA ALIA BINT E JAABIR 293 JY hll 1 00: 15.22 -0.9', 'ABDUL KHAALIQ', '41 FAITH KIMBERLY NG 313 MGS h9 6 00: 15.22 +0.4', '42 SHRIYA NATARAJ AN 221 CGS h3 5 00: 15.26 -0.3', '43 LIEW AN XIN 509 us h5 1 00: 15.28 -0.6', '44 TAN JIA XIN 501 TMS h6 7 00: 15.32 -0.5', '45 CLARA THAM KEI (TAN QI) 229 DY hl 7 00: 15.33 -0.3', '46 TAW SHIRLYN 287 HY h3 2 00: 15.35 -0.3', '47 TAN REGINE 223 CGS h7 3 00: 15.36 -0.4', '48 LIM JIA YING, SI ENNA 325 NCH h4 8 00:15.42 +0.2', '49 ARYANNA ZAHARA BINTE 102 KC hl0 7 00:15.44 -1.0', 'MOHAMED RAFI', '50 NG JING XUAN ( HUANG 129 HIJ hl 8 00:15.48 -0.3', 'JINGXUAN)', '51 TEO YI JIE 33 BV h3 4 00:15.49 -0.3', '52 BELLELYN ONG 11 AIS h6 4 00:15.49 -0.5', '53 NURUL ALIYA BI NTE 294 JY hl 3 00: 15.54 -0.3', 'JAMALUDDIN', '54 C HUA SHYN YIN N, SHERMAINE 28 BV h8 3 00 : 15.56 +0 .7', 'HA NNAH', '55 M ELISSA BOO 426 QT SS h4 6 00 : 15.58 +o .2', '56 EM ILIA KOH MIK I 289 JY h7 6 00 : 15.58 -0. 4', '57 A NNABEL TANG 209 CG S h8 5 00 : 15.60 +0 .7', '58 TA N MENG YEE ( CHEN MINGYI) 327 NC H hl 0 1 00 : 15.62 -1. 0', '59 KO NG YE WEN RE N 248 D HS h5 8 00 : 15.62 -0. 6', '60 A NDRAMADA DES TINY BINTE 176 STC h2 3 00 : 15.76 0. 0', 'K HAIRIL ANWAR', '61 N G LE XIN 236 Dy h6 6 00 : 15.78 -0. 5', '62 BEH YI EN CLARA 96 cc s h2 7 00 : 15.83 0. 0', '63 FEL ICIA TEO KA HEN 506 us h9 4 00 : 15.83 +o .4', '64 YA P LI LING 384 NJC hl 1 7 00 : 15.87 -0. 9', '65 H ERLYNN ISZURA BINTE IMRAN 15 AI s h9 5 00 : 16.09 +0 .4', '66 KO H LEXUAN, KAY LA 317 MG S h5 7 00 : 16.21 -0. 6', '67 AL !CIA KELLY IM MANUEL 22 APs h4 2 00 : 16.28 +o .2', '68 D ESSY ZULASTR I BINTE 97 cc s h4 1 00 : 16.41 +o .2', 'zU LKIFLI', '69 sA M ZU YI 8 A DSS hl 2 00 : 16.54 -0. 3', '70 N UR QISTINA BI NTE KASWANI 7 A DSS hl 1 6 00 : 16.55 -0. 9', '71 KO H YA XIN CHE LSEA 495 TM s hl 1 2 00 : 16.61 -0. 9', '72 NA URA NUR ADI QAH BINTE 517 w DL h2 4 00 : 16.73 0. 0', 'sA NI', '73 C HAN JIA XIN 38 BT V hl 1 3 00 : 16.82 -0. 9', '74 N UR EILIYAH BI NTE NUR 489 TK h3 6 00 : 17.06 -0. 3', 'M UHAMAD', '75 DI NA AFIAH BIN TE MOHAMMAD 39 BT V hl 4 00 : 17.07 -0. 3', 'D ZULKIFLI', '76 LI NG RUI XUAN, KANDICE 452 ssT h7 1 00 : 17.20 -0. 4', '77 TE 0 ZHI YEE 518 w DL h4 3 00 : 17.22 +o .2', '78 LI MEN FEI 396 NLs h6 2 00 : 17.58 -0. 5', '79 N OOR SHAFIQA H BINTI 25 BD S hl 0 6 00 : 17.75 -1. 0', 'sA RIBIN', '80 N OORAISYAH BI NTE 397 NLs h9 8 00 : 18.50 +o .4', 'M UHAMMED NASS IR', '81 PUT RI QATRUNNA DA BIVI 18 AI s h5 5 00 : 18.53 -0. 6', 'BI NTE TARMIZI KHAN', '- - -- - - - -- - - -- - -- ---', '82 DEW! FATIHAH BINTE MOHD 276 GOS h4 5 00: 19.48 +0.2', 'FERDAUS', 'I', 't', '83 STELL LAW RUIEN 278 GOS hl0 2 00:21.06 -1.0', '~', '84 TAY JIA HUI DAYNA 382 NJC h7 7 -0.4 DNS', '85 PEH HUI YEE 398 NLS h5 3 -0.6 DNS', '86 TAN ZHI SHAN 526 YCS hlO 8 I -1.0 DNS']\n",
      "row string Event: S0l-08 100m - B DIVISION GIRLS Heats SlFinals on\n",
      "event  S0l-08 100m \n",
      "session list ['S0l-08']\n",
      "session S0l-08\n",
      "division B \n",
      "gender Female\n",
      "table[i] 1 TEH YING SHAN Q 528 CCHY h8 8 00: 12.94 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 18), match='1 TEH YING SHAN Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '528', 'CCHY', 'h8', '8', '00:12.94', '+0.7']\n",
      "split Q\n",
      "rowX ['1', 'TEH YING SHAN ', 'Q', ' 528', ' CCHY', ' h8', ' 8', ' 00:12.94', '  ', ' +0.7']\n",
      "table[i] 2 CHLOE CHEE EN-YA Q 309 MGS h6 1 00: 13.17 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 21), match='2 CHLOE CHEE EN-YA Q '> qpos <re.Match object; span=(18, 20), match=' Q'>\n",
      "LIST ['', '309', 'MGS', 'h6', '1', '00:13.17', '-0.5']\n",
      "split Q\n",
      "rowX ['2', 'CHLOE CHEE EN-YA ', 'Q', ' 309', ' MGS', ' h6', ' 1', ' 00:13.17', '  ', ' -0.5']\n",
      "table[i] 3 JAYME NG SOK CHEE Q 156 SNG h9 2 00: 13.25 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 22), match='3 JAYME NG SOK CHEE Q '> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['', '156', 'SNG', 'h9', '2', '00:13.25', '+0.4']\n",
      "split Q\n",
      "rowX ['3', 'JAYME NG SOK CHEE ', 'Q', ' 156', ' SNG', ' h9', ' 2', ' 00:13.25', '  ', ' +0.4']\n",
      "table[i] 4 MEGAN ANNE YING KA MUN Q 76 CG h9 1 00: 13.27 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 27), match='4 MEGAN ANNE YING KA MUN Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "LIST ['', '76', 'CG', 'h9', '1', '00:13.27', '+0.4']\n",
      "split Q\n",
      "rowX ['4', 'MEGAN ANNE YING KA MUN ', 'Q', ' 76', ' CG', ' h9', ' 1', ' 00:13.27', '  ', ' +0.4']\n",
      "table[i] 5 SOH HWEI EN, RACHEL (SU Q 358 NYGH h3 1 00: 13.30 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 28), match='5 SOH HWEI EN, RACHEL (SU Q '> qpos <re.Match object; span=(25, 27), match=' Q'>\n",
      "LIST ['', '358', 'NYGH', 'h3', '1', '00:13.30', '-0.3']\n",
      "split Q\n",
      "rowX ['5', 'SOH HWEI EN, RACHEL (SU ', 'Q', ' 358', ' NYGH', ' h3', ' 1', ' 00:13.30', '  ', ' -0.3']\n",
      "table[i] HUI'EN RACHEL)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] SOH HWEI EN, RACHEL (SU  table[i] HUI'EN RACHEL)\n",
      "padded full append list ['5', \"SOH HWEI EN, RACHEL (SU HUI'EN RACHEL)\", 'Q', ' 358', ' NYGH', ' h3', ' 1', ' 00:13.30', '  ', ' -0.3', ' ', ' ']\n",
      "table[i] 6 LIM YEE CHERN CLARA Q 440 RGS h8 4 00: 13.33 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='6'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 24), match='6 LIM YEE CHERN CLARA Q '> qpos <re.Match object; span=(21, 23), match=' Q'>\n",
      "LIST ['', '440', 'RGS', 'h8', '4', '00:13.33', '+0.7']\n",
      "split Q\n",
      "rowX ['6', 'LIM YEE CHERN CLARA ', 'Q', ' 440', ' RGS', ' h8', ' 4', ' 00:13.33', '  ', ' +0.7']\n",
      "table[i] 7 KOH JING XUAN, BERNYCE Q 457 SSP h6 5 00: 13.39 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='7'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 27), match='7 KOH JING XUAN, BERNYCE Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "LIST ['', '457', 'SSP', 'h6', '5', '00:13.39', '-0.5']\n",
      "split Q\n",
      "rowX ['7', 'KOH JING XUAN, BERNYCE ', 'Q', ' 457', ' SSP', ' h6', ' 5', ' 00:13.39', '  ', ' -0.5']\n",
      "table[i] 8 NEO EN YU Q 462 SSP h5 4 00:13.43 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='8'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 14), match='8 NEO EN YU Q '> qpos <re.Match object; span=(11, 13), match=' Q'>\n",
      "LIST ['', '462', 'SSP', 'h5', '4', '00:13.43', '-0.6']\n",
      "split Q\n",
      "rowX ['8', 'NEO EN YU ', 'Q', ' 462', ' SSP', ' h5', ' 4', ' 00:13.43', '  ', ' -0.6']\n",
      "table[i] 9 EMILY ANNE CHOI YI SIU Q 182 STC h4 7 00: 13.50 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='9'> None\n",
      "lpos <re.Match object; span=(1, 2), match=' '> rpos <re.Match object; span=(0, 27), match='9 EMILY ANNE CHOI YI SIU Q '> qpos <re.Match object; span=(24, 26), match=' Q'>\n",
      "LIST ['', '182', 'STC', 'h4', '7', '00:13.50', '+0.2']\n",
      "split Q\n",
      "rowX ['9', 'EMILY ANNE CHOI YI SIU ', 'Q', ' 182', ' STC', ' h4', ' 7', ' 00:13.50', '  ', ' +0.2']\n",
      "table[i] 10 ELIZABETH LEE SHYIN Q 149 SNG h6 8 00: 13.57 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='0 ELIZABETH LEE SHYIN Q '> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['', '149', 'SNG', 'h6', '8', '00:13.57', '-0.5']\n",
      "split Q\n",
      "rowX ['10', 'ELIZABETH LEE SHYIN ', 'Q', ' 149', ' SNG', ' h6', ' 8', ' 00:13.57', '  ', ' -0.5']\n",
      "table[i] 11 KOH SHI XUAN, BEVLYN Q 458 SSP h9 3 00: 13.69 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='1 KOH SHI XUAN, BEVLYN Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '458', 'SSP', 'h9', '3', '00:13.69', '+0.4']\n",
      "split Q\n",
      "rowX ['11', 'KOH SHI XUAN, BEVLYN ', 'Q', ' 458', ' SSP', ' h9', ' 3', ' 00:13.69', '  ', ' +0.4']\n",
      "table[i] 12 CHLOE SARAHENA TAN HUI EN Q 120 HIJ h7 4 00: 13.72 -0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='2 CHLOE SARAHENA TAN HUI EN Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "LIST ['', '120', 'HIJ', 'h7', '4', '00:13.72', '-0.4']\n",
      "split Q\n",
      "rowX ['12', 'CHLOE SARAHENA TAN HUI EN ', 'Q', ' 120', ' HIJ', ' h7', ' 4', ' 00:13.72', '  ', ' -0.4']\n",
      "table[i] 13 SOH YING SHARLENE Q 83 CG h5 6 00: 13.80 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='3 SOH YING SHARLENE Q '> qpos <re.Match object; span=(20, 22), match=' Q'>\n",
      "LIST ['', '83', 'CG', 'h5', '6', '00:13.80', '-0.6']\n",
      "split Q\n",
      "rowX ['13', 'SOH YING SHARLENE ', 'Q', ' 83', ' CG', ' h5', ' 6', ' 00:13.80', '  ', ' -0.6']\n",
      "table[i] 14 NG LIN YEE CAYLYNE Q 416 PLMGS h2 5 00: 13.98 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='4 NG LIN YEE CAYLYNE Q '> qpos <re.Match object; span=(21, 23), match=' Q'>\n",
      "LIST ['', '416', 'PLMGS', 'h2', '5', '00:13.98', '0.0']\n",
      "split Q\n",
      "rowX ['14', 'NG LIN YEE CAYLYNE ', 'Q', ' 416', ' PLMGS', ' h2', ' 5', ' 00:13.98', '  ', ' 0.0']\n",
      "table[i] 15 TNG YUE EN Q 252 OHS h2 1 00: 14.06 0.0 f\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='5 TNG YUE EN Q '> qpos <re.Match object; span=(13, 15), match=' Q'>\n",
      "LIST ['', '252', 'OHS', 'h2', '1', '00:14.06', '0.0', 'f']\n",
      "split Q\n",
      "rowX ['15', 'TNG YUE EN ', 'Q', ' 252', ' OHS', ' h2', ' 1', ' 00:14.06', '  ', ' 0.0', ' f']\n",
      "table[i] 16 YEO PEY WENN Q 448 RGS h3 7 00: 14.15 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 18), match='6 YEO PEY WENN Q '> qpos <re.Match object; span=(15, 17), match=' Q'>\n",
      "LIST ['', '448', 'RGS', 'h3', '7', '00:14.15', '-0.3']\n",
      "split Q\n",
      "rowX ['16', 'YEO PEY WENN ', 'Q', ' 448', ' RGS', ' h3', ' 7', ' 00:14.15', '  ', ' -0.3']\n",
      "table[i] 17 SHANNON POK HENN YEE Q 453 SST hll 4 00: 14.21 -0.9\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='7 SHANNON POK HENN YEE Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '453', 'SST', 'hll', '4', '00:14.21', '-0.9']\n",
      "split Q\n",
      "rowX ['17', 'SHANNON POK HENN YEE ', 'Q', ' 453', ' SST', ' hll', ' 4', ' 00:14.21', '  ', ' -0.9']\n",
      "table[i] 18 LAI REI EN Q 438 RGS hlO 4 00: 14.22 -1.0\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='8 LAI REI EN Q '> qpos <re.Match object; span=(13, 15), match=' Q'>\n",
      "LIST ['', '438', 'RGS', 'hlO', '4', '00:14.22', '-1.0']\n",
      "split Q\n",
      "rowX ['18', 'LAI REI EN ', 'Q', ' 438', ' RGS', ' hlO', ' 4', ' 00:14.22', '  ', ' -1.0']\n",
      "table[i] 19 YEOW KAI XIN, CHARIS Q 175 SNG h5 2 00: 14.26 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='1'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='9 YEOW KAI XIN, CHARIS Q '> qpos <re.Match object; span=(23, 25), match=' Q'>\n",
      "LIST ['', '175', 'SNG', 'h5', '2', '00:14.26', '-0.6']\n",
      "split Q\n",
      "rowX ['19', 'YEOW KAI XIN, CHARIS ', 'Q', ' 175', ' SNG', ' h5', ' 2', ' 00:14.26', '  ', ' -0.6']\n",
      "table[i] 20 AYRA AZMAN TAN Q 47 CG h6 3 00: 14.31 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 20), match='0 AYRA AZMAN TAN Q '> qpos <re.Match object; span=(17, 19), match=' Q'>\n",
      "LIST ['', '47', 'CG', 'h6', '3', '00:14.31', '-0.5']\n",
      "split Q\n",
      "rowX ['20', 'AYRA AZMAN TAN ', 'Q', ' 47', ' CG', ' h6', ' 3', ' 00:14.31', '  ', ' -0.5']\n",
      "table[i] 21 AMANDA CHUA JIA YING (CAI Q 337 NYGH h8 6 00: 14.44 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='1 AMANDA CHUA JIA YING (CAI Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "LIST ['', '337', 'NYGH', 'h8', '6', '00:14.44', '+0.7']\n",
      "split Q\n",
      "rowX ['21', 'AMANDA CHUA JIA YING (CAI ', 'Q', ' 337', ' NYGH', ' h8', ' 6', ' 00:14.44', '  ', ' +0.7']\n",
      "table[i] JIAYING)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] AMANDA CHUA JIA YING (CAI  table[i] JIAYING)\n",
      "padded full append list ['21', 'AMANDA CHUA JIA YING (CAI JIAYING)', 'Q', ' 337', ' NYGH', ' h8', ' 6', ' 00:14.44', '  ', ' +0.7', ' ', ' ']\n",
      "table[i] 22 SHARIFFAH NABILAH CHISHTY Q 500 TMS hl 6 00: 14.51 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 31), match='2 SHARIFFAH NABILAH CHISHTY Q '> qpos <re.Match object; span=(28, 30), match=' Q'>\n",
      "LIST ['', '500', 'TMS', 'hl', '6', '00:14.51', '-0.3']\n",
      "split Q\n",
      "rowX ['22', 'SHARIFFAH NABILAH CHISHTY ', 'Q', ' 500', ' TMS', ' hl', ' 6', ' 00:14.51', '  ', ' -0.3']\n",
      "table[i] l\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] SHARIFFAH NABILAH CHISHTY  table[i] l\n",
      "padded full append list ['22', 'SHARIFFAH NABILAH CHISHTY l', 'Q', ' 500', ' TMS', ' hl', ' 6', ' 00:14.51', '  ', ' -0.3', ' ', ' ']\n",
      "table[i] 23 ARINA CHERNOVA Q 21 ACS(INT) h2 2 00: 14.56 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 20), match='3 ARINA CHERNOVA Q '> qpos <re.Match object; span=(17, 19), match=' Q'>\n",
      "LIST ['', '21', 'ACS(INT)', 'h2', '2', '00:14.56', '0.0']\n",
      "split Q\n",
      "rowX ['23', 'ARINA CHERNOVA ', 'Q', ' 21', ' ACS(INT)', ' h2', ' 2', ' 00:14.56', '  ', ' 0.0']\n",
      "table[i] 24 JEANETTE LIM KA NGTING Q 322 NCH h2 8 00: 14.58 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='4 JEANETTE LIM KA NGTING Q '> qpos <re.Match object; span=(25, 27), match=' Q'>\n",
      "LIST ['', '322', 'NCH', 'h2', '8', '00:14.58', '0.0']\n",
      "split Q\n",
      "rowX ['24', 'JEANETTE LIM KA NGTING ', 'Q', ' 322', ' NCH', ' h2', ' 8', ' 00:14.58', '  ', ' 0.0']\n",
      "table[i] 25 CAI YAWEN 37 BTV h7 5 00: 14.60 -0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 14), match='5 CAI YAWEN 3'> qpos None\n",
      "LIST ['37', 'BTV', 'h7', '5', '00:14.60', '-0.4']\n",
      "split YAWEN\n",
      "rowX2 ['25', 'CAI YAWEN ', ' 37', ' BTV', ' h7', ' 5', ' 00:14.60', ' -0.4', '  ']\n",
      "HERE2 ['25', 'CAI YAWEN ', ' ', ' 37', ' BTV', ' h7', ' 5', ' 00:14.60', ' ', ' -0.4', '  ', ' ']\n",
      "table[i] 26 DRAGON CAITLI N ANNE 107 KC h8 7 00: 14.61 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='6 DRAGON CAITLI N ANNE 1'> qpos None\n",
      "LIST ['107', 'KC', 'h8', '7', '00:14.61', '+0.7']\n",
      "split ANNE\n",
      "rowX2 ['26', 'DRAGON CAITLI N ANNE ', ' 107', ' KC', ' h8', ' 7', ' 00:14.61', ' +0.7', '  ']\n",
      "HERE2 ['26', 'DRAGON CAITLI N ANNE ', ' ', ' 107', ' KC', ' h8', ' 7', ' 00:14.61', ' ', ' +0.7', '  ', ' ']\n",
      "table[i] 27 CHERELLE LOW (LIU XUAN) 468 SAC h4 4 00: 14.61 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='7 CHERELLE LOW (LIU XUAN) 4'> qpos None\n",
      "LIST ['468', 'SAC', 'h4', '4', '00:14.61', '+0.2']\n",
      "split XUAN)\n",
      "rowX2 ['27', 'CHERELLE LOW (LIU XUAN) ', ' 468', ' SAC', ' h4', ' 4', ' 00:14.61', ' +0.2', '  ']\n",
      "HERE2 ['27', 'CHERELLE LOW (LIU XUAN) ', ' ', ' 468', ' SAC', ' h4', ' 4', ' 00:14.61', ' ', ' +0.2', '  ', ' ']\n",
      "table[i] 28 TANG LOK-YEE M ERRILYN 492 TK h7 2 00: 14.74 -0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 27), match='8 TANG LOK-YEE M ERRILYN 4'> qpos None\n",
      "LIST ['492', 'TK', 'h7', '2', '00:14.74', '-0.4']\n",
      "split ERRILYN\n",
      "rowX2 ['28', 'TANG LOK-YEE M ERRILYN ', ' 492', ' TK', ' h7', ' 2', ' 00:14.74', ' -0.4', '  ']\n",
      "HERE2 ['28', 'TANG LOK-YEE M ERRILYN ', ' ', ' 492', ' TK', ' h7', ' 2', ' 00:14.74', ' ', ' -0.4', '  ', ' ']\n",
      "table[i] 29 YERIN LEYSEN 385 NJC hl 5 00: 14.77 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='2'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='9 YERIN LEYSEN 3'> qpos None\n",
      "LIST ['385', 'NJC', 'hl', '5', '00:14.77', '-0.3']\n",
      "split LEYSEN\n",
      "rowX2 ['29', 'YERIN LEYSEN ', ' 385', ' NJC', ' hl', ' 5', ' 00:14.77', ' -0.3', '  ']\n",
      "HERE2 ['29', 'YERIN LEYSEN ', ' ', ' 385', ' NJC', ' hl', ' 5', ' 00:14.77', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 30 SOH WEN XIN 479 SAC h8 2 00: 14.88 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='0 SOH WEN XIN 4'> qpos None\n",
      "LIST ['479', 'SAC', 'h8', '2', '00:14.88', '+0.7']\n",
      "split XIN\n",
      "rowX2 ['30', 'SOH WEN XIN ', ' 479', ' SAC', ' h8', ' 2', ' 00:14.88', ' +0.7', '  ']\n",
      "HERE2 ['30', 'SOH WEN XIN ', ' ', ' 479', ' SAC', ' h8', ' 2', ' 00:14.88', ' ', ' +0.7', '  ', ' ']\n",
      "table[i] 31 RUBY TJIPTO 466 SPF h2 6 00: 14.90 0.0\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='1 RUBY TJIPTO 4'> qpos None\n",
      "LIST ['466', 'SPF', 'h2', '6', '00:14.90', '0.0']\n",
      "split TJIPTO\n",
      "rowX2 ['31', 'RUBY TJIPTO ', ' 466', ' SPF', ' h2', ' 6', ' 00:14.90', ' 0.0', '  ']\n",
      "HERE2 ['31', 'RUBY TJIPTO ', ' ', ' 466', ' SPF', ' h2', ' 6', ' 00:14.90', ' ', ' 0.0', '  ', ' ']\n",
      "table[i] 32 DANIELLE GOH 279 GDL h8 1 00: 14.93 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='2 DANIELLE GOH 2'> qpos None\n",
      "LIST ['279', 'GDL', 'h8', '1', '00:14.93', '+0.7']\n",
      "split GOH\n",
      "rowX2 ['32', 'DANIELLE GOH ', ' 279', ' GDL', ' h8', ' 1', ' 00:14.93', ' +0.7', '  ']\n",
      "HERE2 ['32', 'DANIELLE GOH ', ' ', ' 279', ' GDL', ' h8', ' 1', ' 00:14.93', ' ', ' +0.7', '  ', ' ']\n",
      "table[i] 33 CRYSTAL LAI JIA MIN 230 DY hll 5 00: 14.96 -0.9\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='3 CRYSTAL LAI JIA MIN 2'> qpos None\n",
      "LIST ['230', 'DY', 'hll', '5', '00:14.96', '-0.9']\n",
      "split MIN\n",
      "rowX2 ['33', 'CRYSTAL LAI JIA MIN ', ' 230', ' DY', ' hll', ' 5', ' 00:14.96', ' -0.9', '  ']\n",
      "HERE2 ['33', 'CRYSTAL LAI JIA MIN ', ' ', ' 230', ' DY', ' hll', ' 5', ' 00:14.96', ' ', ' -0.9', '  ', ' ']\n",
      "table[i] 34 KIMBERLY YONG LI KIM 110 KC h3 3 00: 15.03 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='4 KIMBERLY YONG LI KIM 1'> qpos None\n",
      "LIST ['110', 'KC', 'h3', '3', '00:15.03', '-0.3']\n",
      "split KIM\n",
      "rowX2 ['34', 'KIMBERLY YONG LI KIM ', ' 110', ' KC', ' h3', ' 3', ' 00:15.03', ' -0.3', '  ']\n",
      "HERE2 ['34', 'KIMBERLY YONG LI KIM ', ' ', ' 110', ' KC', ' h3', ' 3', ' 00:15.03', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 35 KYLA MAK YA XUA N 124 HIJ hll 8 00: 15.04 -0.9\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='5 KYLA MAK YA XUA N 1'> qpos None\n",
      "LIST ['124', 'HIJ', 'hll', '8', '00:15.04', '-0.9']\n",
      "split N\n",
      "rowX2 ['35', 'KYLA MAK YA XUA N ', ' 124', ' HIJ', ' hll', ' 8', ' 00:15.04', ' -0.9', '  ']\n",
      "HERE2 ['35', 'KYLA MAK YA XUA N ', ' ', ' 124', ' HIJ', ' hll', ' 8', ' 00:15.04', ' ', ' -0.9', '  ', ' ']\n",
      "table[i] 36 LEONG SOOK MEI (LIANG 470 SAC hl0 3 00: 15.07 -1.0\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='6 LEONG SOOK MEI (LIANG 4'> qpos None\n",
      "LIST ['470', 'SAC', 'hl0', '3', '00:15.07', '-1.0']\n",
      "split (LIANG\n",
      "rowX2 ['36', 'LEONG SOOK MEI (LIANG ', ' 470', ' SAC', ' hl0', ' 3', ' 00:15.07', ' -1.0', '  ']\n",
      "HERE2 ['36', 'LEONG SOOK MEI (LIANG ', ' ', ' 470', ' SAC', ' hl0', ' 3', ' 00:15.07', ' ', ' -1.0', '  ', ' ']\n",
      "table[i] SHUWEI)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] LEONG SOOK MEI (LIANG  table[i] SHUWEI)\n",
      "padded full append list ['36', 'LEONG SOOK MEI (LIANG SHUWEI)', ' ', ' 470', ' SAC', ' hl0', ' 3', ' 00:15.07', ' ', ' -1.0', '  ', ' ']\n",
      "table[i] 37 KAN REN TONG KAYLER 186 STC hlO 5 00: 15.09 -1.0\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='7 KAN REN TONG KAYLER 1'> qpos None\n",
      "LIST ['186', 'STC', 'hlO', '5', '00:15.09', '-1.0']\n",
      "split KAYLER\n",
      "rowX2 ['37', 'KAN REN TONG KAYLER ', ' 186', ' STC', ' hlO', ' 5', ' 00:15.09', ' -1.0', '  ']\n",
      "HERE2 ['37', 'KAN REN TONG KAYLER ', ' ', ' 186', ' STC', ' hlO', ' 5', ' 00:15.09', ' ', ' -1.0', '  ', ' ']\n",
      "table[i] 38 GAN MIN WEN LAU REN 246 DHS h9 7 00: 15.10 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 24), match='8 GAN MIN WEN LAU REN 2'> qpos None\n",
      "LIST ['246', 'DHS', 'h9', '7', '00:15.10', '+0.4']\n",
      "split REN\n",
      "rowX2 ['38', 'GAN MIN WEN LAU REN ', ' 246', ' DHS', ' h9', ' 7', ' 00:15.10', ' +0.4', '  ']\n",
      "HERE2 ['38', 'GAN MIN WEN LAU REN ', ' ', ' 246', ' DHS', ' h9', ' 7', ' 00:15.10', ' ', ' +0.4', '  ', ' ']\n",
      "table[i] 39 MASYA SUFIA BI NTI 454 ss hl 1 00:15.21 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='3'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='9 MASYA SUFIA BI NTI 4'> qpos None\n",
      "LIST ['454', 'ss', 'hl', '1', '00:15.21', '-0.3']\n",
      "split NTI\n",
      "rowX2 ['39', 'MASYA SUFIA BI NTI ', ' 454', ' ss', ' hl', ' 1', ' 00:15.21', ' -0.3', '  ']\n",
      "HERE2 ['39', 'MASYA SUFIA BI NTI ', ' ', ' 454', ' ss', ' hl', ' 1', ' 00:15.21', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] MUHAMMAD RID HUAN\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] MASYA SUFIA BI NTI  table[i] MUHAMMAD RID HUAN\n",
      "padded full append list ['39', 'MASYA SUFIA BI NTI MUHAMMAD RID HUAN', ' ', ' 454', ' ss', ' hl', ' 1', ' 00:15.21', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 40 NUHA ALIA BINT E JAABIR 293 JY hll 1 00: 15.22 -0.9\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='0 NUHA ALIA BINT E JAABIR 2'> qpos None\n",
      "LIST ['293', 'JY', 'hll', '1', '00:15.22', '-0.9']\n",
      "split JAABIR\n",
      "rowX2 ['40', 'NUHA ALIA BINT E JAABIR ', ' 293', ' JY', ' hll', ' 1', ' 00:15.22', ' -0.9', '  ']\n",
      "HERE2 ['40', 'NUHA ALIA BINT E JAABIR ', ' ', ' 293', ' JY', ' hll', ' 1', ' 00:15.22', ' ', ' -0.9', '  ', ' ']\n",
      "table[i] ABDUL KHAALIQ\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] NUHA ALIA BINT E JAABIR  table[i] ABDUL KHAALIQ\n",
      "padded full append list ['40', 'NUHA ALIA BINT E JAABIR ABDUL KHAALIQ', ' ', ' 293', ' JY', ' hll', ' 1', ' 00:15.22', ' ', ' -0.9', '  ', ' ']\n",
      "table[i] 41 FAITH KIMBERLY NG 313 MGS h9 6 00: 15.22 +0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='1 FAITH KIMBERLY NG 3'> qpos None\n",
      "LIST ['313', 'MGS', 'h9', '6', '00:15.22', '+0.4']\n",
      "split NG\n",
      "rowX2 ['41', 'FAITH KIMBERLY NG ', ' 313', ' MGS', ' h9', ' 6', ' 00:15.22', ' +0.4', '  ']\n",
      "HERE2 ['41', 'FAITH KIMBERLY NG ', ' ', ' 313', ' MGS', ' h9', ' 6', ' 00:15.22', ' ', ' +0.4', '  ', ' ']\n",
      "table[i] 42 SHRIYA NATARAJ AN 221 CGS h3 5 00: 15.26 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 22), match='2 SHRIYA NATARAJ AN 2'> qpos None\n",
      "LIST ['221', 'CGS', 'h3', '5', '00:15.26', '-0.3']\n",
      "split AN\n",
      "rowX2 ['42', 'SHRIYA NATARAJ AN ', ' 221', ' CGS', ' h3', ' 5', ' 00:15.26', ' -0.3', '  ']\n",
      "HERE2 ['42', 'SHRIYA NATARAJ AN ', ' ', ' 221', ' CGS', ' h3', ' 5', ' 00:15.26', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 43 LIEW AN XIN 509 us h5 1 00: 15.28 -0.6\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='3 LIEW AN XIN 5'> qpos None\n",
      "LIST ['509', 'us', 'h5', '1', '00:15.28', '-0.6']\n",
      "split XIN\n",
      "rowX2 ['43', 'LIEW AN XIN ', ' 509', ' us', ' h5', ' 1', ' 00:15.28', ' -0.6', '  ']\n",
      "HERE2 ['43', 'LIEW AN XIN ', ' ', ' 509', ' us', ' h5', ' 1', ' 00:15.28', ' ', ' -0.6', '  ', ' ']\n",
      "table[i] 44 TAN JIA XIN 501 TMS h6 7 00: 15.32 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='4 TAN JIA XIN 5'> qpos None\n",
      "LIST ['501', 'TMS', 'h6', '7', '00:15.32', '-0.5']\n",
      "split XIN\n",
      "rowX2 ['44', 'TAN JIA XIN ', ' 501', ' TMS', ' h6', ' 7', ' 00:15.32', ' -0.5', '  ']\n",
      "HERE2 ['44', 'TAN JIA XIN ', ' ', ' 501', ' TMS', ' h6', ' 7', ' 00:15.32', ' ', ' -0.5', '  ', ' ']\n",
      "table[i] 45 CLARA THAM KEI (TAN QI) 229 DY hl 7 00: 15.33 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 28), match='5 CLARA THAM KEI (TAN QI) 2'> qpos <re.Match object; span=(22, 24), match=' Q'>\n",
      "LIST ['229', 'DY', 'hl', '7', '00:15.33', '-0.3']\n",
      "split QI)\n",
      "rowX2 ['45', 'CLARA THAM KEI (TAN QI) ', ' 229', ' DY', ' hl', ' 7', ' 00:15.33', ' -0.3', '  ']\n",
      "HERE2 ['45', 'CLARA THAM KEI (TAN QI) ', ' ', ' 229', ' DY', ' hl', ' 7', ' 00:15.33', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 46 TAW SHIRLYN 287 HY h3 2 00: 15.35 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 16), match='6 TAW SHIRLYN 2'> qpos None\n",
      "LIST ['287', 'HY', 'h3', '2', '00:15.35', '-0.3']\n",
      "split SHIRLYN\n",
      "rowX2 ['46', 'TAW SHIRLYN ', ' 287', ' HY', ' h3', ' 2', ' 00:15.35', ' -0.3', '  ']\n",
      "HERE2 ['46', 'TAW SHIRLYN ', ' ', ' 287', ' HY', ' h3', ' 2', ' 00:15.35', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 47 TAN REGINE 223 CGS h7 3 00: 15.36 -0.4\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 15), match='7 TAN REGINE 2'> qpos None\n",
      "LIST ['223', 'CGS', 'h7', '3', '00:15.36', '-0.4']\n",
      "split REGINE\n",
      "rowX2 ['47', 'TAN REGINE ', ' 223', ' CGS', ' h7', ' 3', ' 00:15.36', ' -0.4', '  ']\n",
      "HERE2 ['47', 'TAN REGINE ', ' ', ' 223', ' CGS', ' h7', ' 3', ' 00:15.36', ' ', ' -0.4', '  ', ' ']\n",
      "table[i] 48 LIM JIA YING, SI ENNA 325 NCH h4 8 00:15.42 +0.2\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 26), match='8 LIM JIA YING, SI ENNA 3'> qpos None\n",
      "LIST ['325', 'NCH', 'h4', '8', '00:15.42', '+0.2']\n",
      "split ENNA\n",
      "rowX2 ['48', 'LIM JIA YING, SI ENNA ', ' 325', ' NCH', ' h4', ' 8', ' 00:15.42', ' +0.2', '  ']\n",
      "HERE2 ['48', 'LIM JIA YING, SI ENNA ', ' ', ' 325', ' NCH', ' h4', ' 8', ' 00:15.42', ' ', ' +0.2', '  ', ' ']\n",
      "table[i] 49 ARYANNA ZAHARA BINTE 102 KC hl0 7 00:15.44 -1.0\n",
      "MATCH <re.Match object; span=(0, 1), match='4'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='9 ARYANNA ZAHARA BINTE 1'> qpos None\n",
      "LIST ['102', 'KC', 'hl0', '7', '00:15.44', '-1.0']\n",
      "split BINTE\n",
      "rowX2 ['49', 'ARYANNA ZAHARA BINTE ', ' 102', ' KC', ' hl0', ' 7', ' 00:15.44', ' -1.0', '  ']\n",
      "HERE2 ['49', 'ARYANNA ZAHARA BINTE ', ' ', ' 102', ' KC', ' hl0', ' 7', ' 00:15.44', ' ', ' -1.0', '  ', ' ']\n",
      "table[i] MOHAMED RAFI\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] ARYANNA ZAHARA BINTE  table[i] MOHAMED RAFI\n",
      "padded full append list ['49', 'ARYANNA ZAHARA BINTE MOHAMED RAFI', ' ', ' 102', ' KC', ' hl0', ' 7', ' 00:15.44', ' ', ' -1.0', '  ', ' ']\n",
      "table[i] 50 NG JING XUAN ( HUANG 129 HIJ hl 8 00:15.48 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 25), match='0 NG JING XUAN ( HUANG 1'> qpos None\n",
      "LIST ['129', 'HIJ', 'hl', '8', '00:15.48', '-0.3']\n",
      "split HUANG\n",
      "rowX2 ['50', 'NG JING XUAN ( HUANG ', ' 129', ' HIJ', ' hl', ' 8', ' 00:15.48', ' -0.3', '  ']\n",
      "HERE2 ['50', 'NG JING XUAN ( HUANG ', ' ', ' 129', ' HIJ', ' hl', ' 8', ' 00:15.48', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] JINGXUAN)\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] NG JING XUAN ( HUANG  table[i] JINGXUAN)\n",
      "padded full append list ['50', 'NG JING XUAN ( HUANG JINGXUAN)', ' ', ' 129', ' HIJ', ' hl', ' 8', ' 00:15.48', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 51 TEO YI JIE 33 BV h3 4 00:15.49 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 15), match='1 TEO YI JIE 3'> qpos None\n",
      "LIST ['33', 'BV', 'h3', '4', '00:15.49', '-0.3']\n",
      "split JIE\n",
      "rowX2 ['51', 'TEO YI JIE ', ' 33', ' BV', ' h3', ' 4', ' 00:15.49', ' -0.3', '  ']\n",
      "HERE2 ['51', 'TEO YI JIE ', ' ', ' 33', ' BV', ' h3', ' 4', ' 00:15.49', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 52 BELLELYN ONG 11 AIS h6 4 00:15.49 -0.5\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='2 BELLELYN ONG 1'> qpos None\n",
      "LIST ['11', 'AIS', 'h6', '4', '00:15.49', '-0.5']\n",
      "split ONG\n",
      "rowX2 ['52', 'BELLELYN ONG ', ' 11', ' AIS', ' h6', ' 4', ' 00:15.49', ' -0.5', '  ']\n",
      "HERE2 ['52', 'BELLELYN ONG ', ' ', ' 11', ' AIS', ' h6', ' 4', ' 00:15.49', ' ', ' -0.5', '  ', ' ']\n",
      "table[i] 53 NURUL ALIYA BI NTE 294 JY hl 3 00: 15.54 -0.3\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 23), match='3 NURUL ALIYA BI NTE 2'> qpos None\n",
      "LIST ['294', 'JY', 'hl', '3', '00:15.54', '-0.3']\n",
      "split NTE\n",
      "rowX2 ['53', 'NURUL ALIYA BI NTE ', ' 294', ' JY', ' hl', ' 3', ' 00:15.54', ' -0.3', '  ']\n",
      "HERE2 ['53', 'NURUL ALIYA BI NTE ', ' ', ' 294', ' JY', ' hl', ' 3', ' 00:15.54', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] JAMALUDDIN\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] NURUL ALIYA BI NTE  table[i] JAMALUDDIN\n",
      "padded full append list ['53', 'NURUL ALIYA BI NTE JAMALUDDIN', ' ', ' 294', ' JY', ' hl', ' 3', ' 00:15.54', ' ', ' -0.3', '  ', ' ']\n",
      "table[i] 54 CHUA SHYN YINN, SHERMAINE 28 BV h8 3 00:15.56 +0.7\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 30), match='4 CHUA SHYN YINN, SHERMAINE 2'> qpos None\n",
      "LIST ['28', 'BV', 'h8', '3', '00:15.56', '+0.7']\n",
      "split SHERMAINE\n",
      "rowX2 ['54', 'CHUA SHYN YINN, SHERMAINE ', ' 28', ' BV', ' h8', ' 3', ' 00:15.56', ' +0.7', '  ']\n",
      "HERE2 ['54', 'CHUA SHYN YINN, SHERMAINE ', ' ', ' 28', ' BV', ' h8', ' 3', ' 00:15.56', ' ', ' +0.7', '  ', ' ']\n",
      "table[i] HA NNAH\n",
      "MATCH None None\n",
      "stranded name checkpoint\n",
      "reattaching stranded name checkpoint\n",
      "row[1] CHUA SHYN YINN, SHERMAINE  table[i] HA NNAH\n",
      "padded full append list ['54', 'CHUA SHYN YINN, SHERMAINE HA NNAH', ' ', ' 28', ' BV', ' h8', ' 3', ' 00:15.56', ' ', ' +0.7', '  ', ' ']\n",
      "table[i] 55 M ELISSA BOO 426 QT SS h4 6 00 : 15.58 +o .2\n",
      "MATCH <re.Match object; span=(0, 1), match='5'> None\n",
      "lpos <re.Match object; span=(2, 3), match=' '> rpos <re.Match object; span=(1, 17), match='5 M ELISSA BOO 4'> qpos <re.Match object; span=(19, 21), match=' Q'>\n",
      "LIST ['426', 'QT', 'SS', 'h4', '6', '00', ':15.58', '+o', '.2']\n",
      "split BOO\n",
      "rowX2 ['55', 'M ELISSA BOO ', ' 426', ' QT', ' SS', ' h4', ' 6', ' 00', '  ', ' :15.58', ' +o', ' .2']\n",
      "HERE2 ['55', 'M ELISSA BOO ', ' ', ' 426', ' QT', ' SS', ' h4', ' 6', ' ', ' 00', '  ', ' :15.58', ' +o', ' .2']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [236], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m splitted[j] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m54 C HUA SHYN YIN N, SHERMAINE 28 BV h8 3 00 : 15.56 +0 .7\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m         splitted[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m54 CHUA SHYN YINN, SHERMAINE 28 BV h8 3 00:15.56 +0.7\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 75\u001b[0m master_df\u001b[38;5;241m=\u001b[39m\u001b[43mextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [105], line 196\u001b[0m, in \u001b[0;36mextraction\u001b[0;34m(table, master_df)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW/G\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m columns: \u001b[38;5;66;03m# new format     \u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     master_df\u001b[38;5;241m=\u001b[39m\u001b[43mnew_format_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_df\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# call parser function\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSession\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39msession   \u001b[38;5;66;03m# add session  NEW\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDivision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdivision \u001b[38;5;66;03m# add division NEW\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [231], line 375\u001b[0m, in \u001b[0;36mnew_format_parser\u001b[0;34m(row_index, names, table, master_df)\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHERE2\u001b[39m\u001b[38;5;124m'\u001b[39m, final_list)\n\u001b[1;32m    372\u001b[0m                 \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m.\u001b[39mappend(final_list)\n\u001b[0;32m--> 375\u001b[0m                 \u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m final_list\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# QAed to this point for a stranded pdf. Need to figure out how to attach stranded row to master df\u001b[39;00m\n\u001b[1;32m    382\u001b[0m             \n\u001b[1;32m    383\u001b[0m             \n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m#            master_df=new_df      # previous   \u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:1932\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SAA/lib/python3.10/site-packages/pandas/core/indexing.py:2306\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[1;32m   2304\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 2306\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2308\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# 2023 ONLY #\n",
    "# NEW TEST CODE#\n",
    "\n",
    "# Test iteration over more than one page and multiple files in directory\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/')\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/Session 13_1-4/Session 13_5-6.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/sectrack_result_01p_1-1/sectrack_result_01p_1-1.pdf\"\n",
    "\n",
    "file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1/S01-01_TO_11_deconstructed_14-17.pdf\"\n",
    "\n",
    "#file = \"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/Session_20.pdf\"\n",
    "\n",
    "#directory = r\"/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2023/S01-01_TO_11_deconstructed_1-1\"\n",
    "\n",
    "    \n",
    "    \n",
    "# Iterate over files in directory\n",
    "\n",
    "#sorted_items=sort_directory(directory)\n",
    "\n",
    "temp_df=pd.DataFrame()  # initialize empty temp df\n",
    "\n",
    "master_df=pd.DataFrame()\n",
    "\n",
    "splitted=None\n",
    "\n",
    "#print(sorted_items)\n",
    "\n",
    "#for file in sorted_items:\n",
    "    \n",
    "#    print(file)\n",
    "\n",
    "\n",
    "with pdfplumber.open(file) as pdf:\n",
    "    \n",
    "    for i in range(len(pdf.pages)):\n",
    "        \n",
    "        temp=splitted\n",
    "        \n",
    "        page = pdf.pages[i]  # can iterate over different pages\n",
    "        table=page.extract_table()\n",
    "        text=page.extract_text()\n",
    "                \n",
    "        if i==0:\n",
    "        \n",
    "            splitted=text.splitlines()\n",
    "            \n",
    "     #       temp_df=extraction(splitted, temp_df)\n",
    "            \n",
    "        else: # stitch following pages to create one continuous page\n",
    "            \n",
    "            temp=text.splitlines()\n",
    "            \n",
    "            splitted.extend(temp)\n",
    "            \n",
    "       #     temp_df=extraction(splitted, temp_df)\n",
    "                        \n",
    "       # master_df=pd.concat([master_df, temp_df], axis=0)\n",
    "\n",
    "print('SPLITTED', splitted)\n",
    "\n",
    "# Correct formatting errors in source data\n",
    "\n",
    "for j in range(len(splitted)):\n",
    "    \n",
    "    if splitted[j] == '34 ANG TZE YEN, CLAIRE 144 RI h2 4 f -0.1 DNS':\n",
    "        splitted[j] = '34 ANG TZE YEN, CLAIRE 144 RI h2 4 -0.1 DNS'\n",
    "\n",
    "    if splitted[j] == '54 C HUA SHYN YIN N, SHERMAINE 28 BV h8 3 00 : 15.56 +0 .7':\n",
    "        splitted[j] = '54 CHUA SHYN YINN, SHERMAINE 28 BV h8 3 00:15.56 +0.7'\n",
    "\n",
    "master_df=extraction(splitted, master_df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "630602d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c6fef",
   "metadata": {},
   "source": [
    "# Processing for BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4313a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and processing output from 2023/24 NSG CSV for uploading into BigQuery\n",
    "\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2024/')\n",
    "\n",
    "df = pd.read_csv(\"NSG_2324.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "330b30cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Competitor</th>\n",
       "      <th>Team</th>\n",
       "      <th>Result</th>\n",
       "      <th>Heat Number</th>\n",
       "      <th>Lane Nnmber</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Event</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Division</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Year</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Region</th>\n",
       "      <th>Wind m/s</th>\n",
       "      <th>Data Source</th>\n",
       "      <th>SimpleEvent</th>\n",
       "      <th>Remarks_Corrected</th>\n",
       "      <th>Aggr_Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>A A Ayu Teja Gayatri</td>\n",
       "      <td>SJC</td>\n",
       "      <td>00:18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CHIJ St. Joseph's Convent</td>\n",
       "      <td>100m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>DNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DNF Hai Sing Catholic School</td>\n",
       "      <td>1500m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Mid</td>\n",
       "      <td>DNF</td>\n",
       "      <td>1500m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Hai Sing Catholic School</td>\n",
       "      <td>3000m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>12:10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hai Sing Catholic School</td>\n",
       "      <td>3000m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>AALIYAH ZULAIKHA BINTE ZULKIFLI</td>\n",
       "      <td>HSC</td>\n",
       "      <td>05:30.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500m - B DIVISION GIRLS Heats</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>h2</td>\n",
       "      <td>2023</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Mid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>ZULFAHMI BIN SANUSI</td>\n",
       "      <td>BBS</td>\n",
       "      <td>11:27.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m - B DIVISION BOYS Heats</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>h1</td>\n",
       "      <td>2023</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : lane infringement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400m</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>SF</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st to 2nd runner baton passed out of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st runner lane infringement @150m curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : Replaced Shuen Ho (He Shu'an)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long Jump</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Jump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long Jump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9913 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       POS    Tag                       Competitor  \\\n",
       "0     86.0  537.0             A A Ayu Teja Gayatri   \n",
       "1      NaN  357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "2      NaN  357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "3      4.0  357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "4      4.0  286.0  AALIYAH ZULAIKHA BINTE ZULKIFLI   \n",
       "...    ...    ...                              ...   \n",
       "9908  25.0  136.0              ZULFAHMI BIN SANUSI   \n",
       "9909   NaN    NaN                              NaN   \n",
       "9910   NaN    NaN                              NaN   \n",
       "9911   NaN    NaN                              NaN   \n",
       "9912   NaN    NaN                              NaN   \n",
       "\n",
       "                                                   Team   Result  Heat Number  \\\n",
       "0                                                   SJC  00:18.0          8.0   \n",
       "1                                                   HSC      DNF          1.0   \n",
       "2                                                   HSC      NaN          3.0   \n",
       "3                                                   HSC  12:10.5          1.0   \n",
       "4                                                   HSC  05:30.6          NaN   \n",
       "...                                                 ...      ...          ...   \n",
       "9908                                                BBS  11:27.5          NaN   \n",
       "9909                         Reason : lane infringement      NaN          NaN   \n",
       "9910  Reason : 1st to 2nd runner baton passed out of...      NaN          NaN   \n",
       "9911  Reason : 1st runner lane infringement @150m curve      NaN          NaN   \n",
       "9912             Reason : Replaced Shuen Ho (He Shu'an)      NaN          NaN   \n",
       "\n",
       "      Lane Nnmber                       Remarks  \\\n",
       "0             5.0     CHIJ St. Joseph's Convent   \n",
       "1             5.0  DNF Hai Sing Catholic School   \n",
       "2            15.0      Hai Sing Catholic School   \n",
       "3             3.0      Hai Sing Catholic School   \n",
       "4             2.0                           NaN   \n",
       "...           ...                           ...   \n",
       "9908         10.0                           NaN   \n",
       "9909          NaN                           NaN   \n",
       "9910          NaN                           NaN   \n",
       "9911          NaN                           NaN   \n",
       "9912          NaN                           NaN   \n",
       "\n",
       "                               Event  Gender Division  Stage  Year  \\\n",
       "0                              100m   Female        B  Heats  2024   \n",
       "1                             1500m   Female        B  Final  2024   \n",
       "2                             3000m   Female        B  Heats  2024   \n",
       "3                             3000m   Female        B  Final  2024   \n",
       "4     1500m - B DIVISION GIRLS Heats  Female        B     h2  2023   \n",
       "...                              ...     ...      ...    ...   ...   \n",
       "9908   3000m - B DIVISION BOYS Heats    Male        B     h1  2023   \n",
       "9909                           400m     Male        C     SF  2024   \n",
       "9910                   4x400m Relay     Male        B  Heats  2024   \n",
       "9911                   4x400m Relay     Male        B  Heats  2024   \n",
       "9912                      Long Jump     Male        B  Final  2024   \n",
       "\n",
       "     Competition Region  Wind m/s Data Source SimpleEvent Remarks_Corrected  \\\n",
       "0            NSG  Local       NaN         PDF      Sprint               NaN   \n",
       "1            NSG  Local       NaN         PDF         Mid               DNF   \n",
       "2            NSG  Local       NaN         PDF        Long               NaN   \n",
       "3            NSG  Local       NaN         PDF        Long               NaN   \n",
       "4            NSG  Local       NaN         PDF         Mid               NaN   \n",
       "...          ...    ...       ...         ...         ...               ...   \n",
       "9908         NSG  Local       NaN         PDF        Long               NaN   \n",
       "9909         NSG  Local       NaN         PDF      Sprint               NaN   \n",
       "9910         NSG  Local       NaN         PDF       Relay               NaN   \n",
       "9911         NSG  Local       NaN         PDF       Relay               NaN   \n",
       "9912         NSG  Local       NaN         PDF        Jump               NaN   \n",
       "\n",
       "         Aggr_Event  \n",
       "0             100m   \n",
       "1            1500m   \n",
       "2            3000m   \n",
       "3            3000m   \n",
       "4            1500m   \n",
       "...             ...  \n",
       "9908         3000m   \n",
       "9909          400m   \n",
       "9910  4x400m Relay   \n",
       "9911  4x400m Relay   \n",
       "9912     Long Jump   \n",
       "\n",
       "[9913 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c650e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={0: \"RANK\", 1: \"TAG_ID\", 2: \"NAME\", 3: \"TEAM\", 4: \"RESULT\", 5: \"HEAT\", 6: \"LANE\", 7: \"REMARKS.1\", 8: \"EVENT.1\", \n",
    "            9: \"GENDER\", 10: \"DIVISION\", 11: \"STAGE\", 12: \"DATE\", 13: \"COMPETITION\", 14: \"REGION\", 15: \"WIND\", 16: \"SOURCE\",\n",
    "            17: \"CATEGORY_EVENT\", 18: \"REMARKS\", 19: \"EVENT\"},\n",
    "            inplace=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d0ca938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"RANK\", \"TAG_ID\", \"NAME\", \"TEAM\", \"RESULT\", \"HEAT\", \"LANE\", \"REMARKS.1\", \"EVENT.1\", \"GENDER\", \n",
    "             \"DIVISION\", \"STAGE\", \"DATE\", \"COMPETITION\", \"REGION\", \"WIND\", \"SOURCE\", \"CATEGORY_EVENT\", \n",
    "             \"REMARKS\", \"EVENT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68cf0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>REMARKS.1</th>\n",
       "      <th>EVENT.1</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STAGE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>COMPETITION</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WIND</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>CATEGORY_EVENT</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>A A Ayu Teja Gayatri</td>\n",
       "      <td>SJC</td>\n",
       "      <td>00:18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CHIJ St. Joseph's Convent</td>\n",
       "      <td>100m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>DNF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DNF Hai Sing Catholic School</td>\n",
       "      <td>1500m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Mid</td>\n",
       "      <td>DNF</td>\n",
       "      <td>1500m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Hai Sing Catholic School</td>\n",
       "      <td>3000m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>12:10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hai Sing Catholic School</td>\n",
       "      <td>3000m</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>AALIYAH ZULAIKHA BINTE ZULKIFLI</td>\n",
       "      <td>HSC</td>\n",
       "      <td>05:30.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500m - B DIVISION GIRLS Heats</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>h2</td>\n",
       "      <td>2023</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Mid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>ZULFAHMI BIN SANUSI</td>\n",
       "      <td>BBS</td>\n",
       "      <td>11:27.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m - B DIVISION BOYS Heats</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>h1</td>\n",
       "      <td>2023</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : lane infringement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400m</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>SF</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st to 2nd runner baton passed out of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st runner lane infringement @150m curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Heats</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4x400m Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : Replaced Shuen Ho (He Shu'an)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long Jump</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>Final</td>\n",
       "      <td>2024</td>\n",
       "      <td>NSG</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>Jump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long Jump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9913 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RANK  TAG_ID                             NAME  \\\n",
       "0     86.0   537.0             A A Ayu Teja Gayatri   \n",
       "1      NaN   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "2      NaN   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "3      4.0   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "4      4.0   286.0  AALIYAH ZULAIKHA BINTE ZULKIFLI   \n",
       "...    ...     ...                              ...   \n",
       "9908  25.0   136.0              ZULFAHMI BIN SANUSI   \n",
       "9909   NaN     NaN                              NaN   \n",
       "9910   NaN     NaN                              NaN   \n",
       "9911   NaN     NaN                              NaN   \n",
       "9912   NaN     NaN                              NaN   \n",
       "\n",
       "                                                   TEAM   RESULT  HEAT  LANE  \\\n",
       "0                                                   SJC  00:18.0   8.0   5.0   \n",
       "1                                                   HSC      DNF   1.0   5.0   \n",
       "2                                                   HSC      NaN   3.0  15.0   \n",
       "3                                                   HSC  12:10.5   1.0   3.0   \n",
       "4                                                   HSC  05:30.6   NaN   2.0   \n",
       "...                                                 ...      ...   ...   ...   \n",
       "9908                                                BBS  11:27.5   NaN  10.0   \n",
       "9909                         Reason : lane infringement      NaN   NaN   NaN   \n",
       "9910  Reason : 1st to 2nd runner baton passed out of...      NaN   NaN   NaN   \n",
       "9911  Reason : 1st runner lane infringement @150m curve      NaN   NaN   NaN   \n",
       "9912             Reason : Replaced Shuen Ho (He Shu'an)      NaN   NaN   NaN   \n",
       "\n",
       "                         REMARKS.1                         EVENT.1  GENDER  \\\n",
       "0        CHIJ St. Joseph's Convent                           100m   Female   \n",
       "1     DNF Hai Sing Catholic School                          1500m   Female   \n",
       "2         Hai Sing Catholic School                          3000m   Female   \n",
       "3         Hai Sing Catholic School                          3000m   Female   \n",
       "4                              NaN  1500m - B DIVISION GIRLS Heats  Female   \n",
       "...                            ...                             ...     ...   \n",
       "9908                           NaN   3000m - B DIVISION BOYS Heats    Male   \n",
       "9909                           NaN                           400m     Male   \n",
       "9910                           NaN                   4x400m Relay     Male   \n",
       "9911                           NaN                   4x400m Relay     Male   \n",
       "9912                           NaN                      Long Jump     Male   \n",
       "\n",
       "     DIVISION  STAGE  DATE COMPETITION REGION  WIND SOURCE CATEGORY_EVENT  \\\n",
       "0           B  Heats  2024         NSG  Local   NaN    PDF         Sprint   \n",
       "1           B  Final  2024         NSG  Local   NaN    PDF            Mid   \n",
       "2           B  Heats  2024         NSG  Local   NaN    PDF           Long   \n",
       "3           B  Final  2024         NSG  Local   NaN    PDF           Long   \n",
       "4           B     h2  2023         NSG  Local   NaN    PDF            Mid   \n",
       "...       ...    ...   ...         ...    ...   ...    ...            ...   \n",
       "9908        B     h1  2023         NSG  Local   NaN    PDF           Long   \n",
       "9909        C     SF  2024         NSG  Local   NaN    PDF         Sprint   \n",
       "9910        B  Heats  2024         NSG  Local   NaN    PDF          Relay   \n",
       "9911        B  Heats  2024         NSG  Local   NaN    PDF          Relay   \n",
       "9912        B  Final  2024         NSG  Local   NaN    PDF           Jump   \n",
       "\n",
       "     REMARKS          EVENT  \n",
       "0        NaN          100m   \n",
       "1        DNF         1500m   \n",
       "2        NaN         3000m   \n",
       "3        NaN         3000m   \n",
       "4        NaN         1500m   \n",
       "...      ...            ...  \n",
       "9908     NaN         3000m   \n",
       "9909     NaN          400m   \n",
       "9910     NaN  4x400m Relay   \n",
       "9911     NaN  4x400m Relay   \n",
       "9912     NaN     Long Jump   \n",
       "\n",
       "[9913 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33602521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QUALIFICATION']=''\n",
    "df['POINTS']=''\n",
    "df['UNIQUE_ID']=''\n",
    "df['COUNTRY']=''\n",
    "df['DICT_RESULTS']=''\n",
    "df['GROUP']=''\n",
    "df['TIMESTAMP']=''\n",
    "df['FREE_FIELD']=''\n",
    "df['FREE_FIELD2']=''\n",
    "df['FREE_FIELD3']=''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b851fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns= ['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION', 'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', \n",
    "                            'POINTS', 'AGE', 'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'DATE', 'COMPETITION', 'REGION', 'DOB','GROUP', 'CATEGORY_EVENT', \n",
    "                            'ATHLETE_ID', 'SOURCE', 'REMARKS', 'TIMESTAMP', 'FREE_FIELD', 'FREE_FIELD2', 'FREE_FIELD3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c93bb781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>QUALIFICATION</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>WIND</th>\n",
       "      <th>...</th>\n",
       "      <th>DOB</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>CATEGORY_EVENT</th>\n",
       "      <th>ATHLETE_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FREE_FIELD</th>\n",
       "      <th>FREE_FIELD2</th>\n",
       "      <th>FREE_FIELD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>A A Ayu Teja Gayatri</td>\n",
       "      <td>SJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:18.0</td>\n",
       "      <td></td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNF</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>DNF</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>Aaliyah Zulaikha Binte Zulkifli</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:10.5</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>AALIYAH ZULAIKHA BINTE ZULKIFLI</td>\n",
       "      <td>HSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05:30.6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Mid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>ZULFAHMI BIN SANUSI</td>\n",
       "      <td>BBS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:27.5</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : lane infringement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st to 2nd runner baton passed out of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : 1st runner lane infringement @150m curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reason : Replaced Shuen Ho (He Shu'an)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Jump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9913 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RANK  TAG_ID                             NAME  \\\n",
       "0     86.0   537.0             A A Ayu Teja Gayatri   \n",
       "1      NaN   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "2      NaN   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "3      4.0   357.0  Aaliyah Zulaikha Binte Zulkifli   \n",
       "4      4.0   286.0  AALIYAH ZULAIKHA BINTE ZULKIFLI   \n",
       "...    ...     ...                              ...   \n",
       "9908  25.0   136.0              ZULFAHMI BIN SANUSI   \n",
       "9909   NaN     NaN                              NaN   \n",
       "9910   NaN     NaN                              NaN   \n",
       "9911   NaN     NaN                              NaN   \n",
       "9912   NaN     NaN                              NaN   \n",
       "\n",
       "                                                   TEAM  SEED   RESULT  \\\n",
       "0                                                   SJC   NaN  00:18.0   \n",
       "1                                                   HSC   NaN      DNF   \n",
       "2                                                   HSC   NaN      NaN   \n",
       "3                                                   HSC   NaN  12:10.5   \n",
       "4                                                   HSC   NaN  05:30.6   \n",
       "...                                                 ...   ...      ...   \n",
       "9908                                                BBS   NaN  11:27.5   \n",
       "9909                         Reason : lane infringement   NaN      NaN   \n",
       "9910  Reason : 1st to 2nd runner baton passed out of...   NaN      NaN   \n",
       "9911  Reason : 1st runner lane infringement @150m curve   NaN      NaN   \n",
       "9912             Reason : Replaced Shuen Ho (He Shu'an)   NaN      NaN   \n",
       "\n",
       "     QUALIFICATION  HEAT  LANE  WIND  ... DOB GROUP CATEGORY_EVENT ATHLETE_ID  \\\n",
       "0                    8.0   5.0   NaN  ... NaN               Sprint        NaN   \n",
       "1                    1.0   5.0   NaN  ... NaN                  Mid        NaN   \n",
       "2                    3.0  15.0   NaN  ... NaN                 Long        NaN   \n",
       "3                    1.0   3.0   NaN  ... NaN                 Long        NaN   \n",
       "4                    NaN   2.0   NaN  ... NaN                  Mid        NaN   \n",
       "...            ...   ...   ...   ...  ...  ..   ...            ...        ...   \n",
       "9908                 NaN  10.0   NaN  ... NaN                 Long        NaN   \n",
       "9909                 NaN   NaN   NaN  ... NaN               Sprint        NaN   \n",
       "9910                 NaN   NaN   NaN  ... NaN                Relay        NaN   \n",
       "9911                 NaN   NaN   NaN  ... NaN                Relay        NaN   \n",
       "9912                 NaN   NaN   NaN  ... NaN                 Jump        NaN   \n",
       "\n",
       "      SOURCE REMARKS TIMESTAMP FREE_FIELD FREE_FIELD2  FREE_FIELD3  \n",
       "0        PDF     NaN                                                \n",
       "1        PDF     DNF                                                \n",
       "2        PDF     NaN                                                \n",
       "3        PDF     NaN                                                \n",
       "4        PDF     NaN                                                \n",
       "...      ...     ...       ...        ...         ...          ...  \n",
       "9908     PDF     NaN                                                \n",
       "9909     PDF     NaN                                                \n",
       "9910     PDF     NaN                                                \n",
       "9911     PDF     NaN                                                \n",
       "9912     PDF     NaN                                                \n",
       "\n",
       "[9913 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d253191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NSG_202324_processed.csv', sep=',', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9b732",
   "metadata": {},
   "source": [
    "## Convert new schema file to old schema in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8372f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and processing output from 2022 NSG CSV for uploading into BigQuery\n",
    "# Basing on latest SCHEMA taken from Alph's extraction\n",
    "# Pending my own export code using latest schema\n",
    "# SUB_EVENT=shot put or javelin under decathlon\n",
    "# EVENT_CLASS=weight or height for javelin (600g) , hurdles (0.762m or 0.840m) for example\n",
    "# DATE=DDMM format\n",
    "\n",
    "os.chdir('/Users/veesheenyuen/Desktop/DataScience/SAA/NSG/NSG2022/')\n",
    "\n",
    "df = pd.read_csv(\"NSG2022_NEW_SCHEMA.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49aa4c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>QUALIFICATION</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>WIND</th>\n",
       "      <th>...</th>\n",
       "      <th>ATHLETE_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>VENUE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SUB_EVENT</th>\n",
       "      <th>SESSION</th>\n",
       "      <th>EVENT_CLASS</th>\n",
       "      <th>Remarks_Corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>719</td>\n",
       "      <td>WONG CHOONG YIN</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>337</td>\n",
       "      <td>ONG YI JUN RAYMUS</td>\n",
       "      <td>HCI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>499</td>\n",
       "      <td>LEAM TEO JIN TZE</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>695</td>\n",
       "      <td>LEROY ANDRE CHNG CHONG KAI</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>585</td>\n",
       "      <td>KEANE WONG JEN QUIN</td>\n",
       "      <td>SJI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>HAYDEN TAN LI ERN</td>\n",
       "      <td>ACJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S0904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>24</td>\n",
       "      <td>431</td>\n",
       "      <td>NG LIN YEE CAYLYNE</td>\n",
       "      <td>PLMGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>16</td>\n",
       "      <td>250</td>\n",
       "      <td>NUR HAERYL IHSAN BIN CHAIRILYANY</td>\n",
       "      <td>JSS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>BUKIT VIEW SECONDARY SCHOOL</td>\n",
       "      <td>BIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF3</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>BUKIT VIEW SECONDARY SCHOOL</td>\n",
       "      <td>BIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S20A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4523 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RANK  TAG_ID                              NAME   TEAM  SEED   RESULT  \\\n",
       "0       1     719                   WONG CHOONG YIN     VS   NaN    38.77   \n",
       "1       2     337                 ONG YI JUN RAYMUS    HCI   NaN    37.56   \n",
       "2       3     499                  LEAM TEO JIN TZE     RI   NaN    36.92   \n",
       "3       4     695        LEROY ANDRE CHNG CHONG KAI     VS   NaN    35.21   \n",
       "4       5     585               KEANE WONG JEN QUIN    SJI   NaN    34.78   \n",
       "...   ...     ...                               ...    ...   ...      ...   \n",
       "4518    8      15                 HAYDEN TAN LI ERN   ACJC   NaN      DNS   \n",
       "4519   24     431                NG LIN YEE CAYLYNE  PLMGS   NaN      DNS   \n",
       "4520   16     250  NUR HAERYL IHSAN BIN CHAIRILYANY    JSS   NaN  12:16.0   \n",
       "4521   23      41       BUKIT VIEW SECONDARY SCHOOL    BIV   NaN       DQ   \n",
       "4522   22      94       BUKIT VIEW SECONDARY SCHOOL    BIV   NaN      DNS   \n",
       "\n",
       "     QUALIFICATION    HEAT  LANE  WIND  ... ATHLETE_ID  \\\n",
       "0              NaN  Finals     5   NaN  ...        NaN   \n",
       "1              NaN  Finals     4   NaN  ...        NaN   \n",
       "2              NaN  Finals    14   NaN  ...        NaN   \n",
       "3              NaN  Finals    12   NaN  ...        NaN   \n",
       "4              NaN  Finals    11   NaN  ...        NaN   \n",
       "...            ...     ...   ...   ...  ...        ...   \n",
       "4518           NaN  Finals     3  -0.1  ...        NaN   \n",
       "4519           NaN     SF3     7   1.2  ...        NaN   \n",
       "4520           NaN  Finals    16   NaN  ...        NaN   \n",
       "4521           NaN     SF3     7   NaN  ...        NaN   \n",
       "4522           NaN      h1     6   NaN  ...        NaN   \n",
       "\n",
       "                                    SOURCE REMARKS  TIMESTAMP  VENUE DATE  \\\n",
       "0     https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "1     https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "2     https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "3     https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "4     https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "...                                    ...     ...        ...    ...  ...   \n",
       "4518  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "4519  https://nsg.moe.edu.sg/sssc/archives     DNS        NaN    NaN  NaN   \n",
       "4520  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "4521  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN    NaN  NaN   \n",
       "4522  https://nsg.moe.edu.sg/sssc/archives     DNS        NaN    NaN  NaN   \n",
       "\n",
       "      SUB_EVENT  SESSION  EVENT_CLASS  Remarks_Corrected  \n",
       "0           NaN    S0101          NaN                NaN  \n",
       "1           NaN    S0101          NaN                NaN  \n",
       "2           NaN    S0101          NaN                NaN  \n",
       "3           NaN    S0101          NaN                NaN  \n",
       "4           NaN    S0101          NaN                NaN  \n",
       "...         ...      ...          ...                ...  \n",
       "4518        NaN    S0904          NaN                NaN  \n",
       "4519        NaN    S1005          NaN                NaN  \n",
       "4520        NaN    S1202          NaN                NaN  \n",
       "4521        NaN    S1508          NaN                NaN  \n",
       "4522        NaN   S20A01          NaN                NaN  \n",
       "\n",
       "[4523 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62f6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENDER'] = df['GENDER'].replace(regex=r'Men', value='Male')\n",
    "df['GENDER'] = df['GENDER'].replace(regex=r'Women', value='Female')\n",
    "df['COMPETITION'] = df['COMPETITION'].replace(regex=r'National School Games', value='NSG')\n",
    "df['SOURCE'] = df['SOURCE'].replace(regex=r'https://nsg.moe.edu.sg/sssc/archives', value='PDF')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0df759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop new columns under latest schema to conform with existing BQ schema\n",
    "\n",
    "df = df.drop(['Remarks_Corrected', 'EVENT_CLASS', 'SESSION', 'SUB_EVENT', 'DATE', 'VENUE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd0e8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename(columns={'YEAR': 'DATE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2a9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add back columns required by current BQ schema\n",
    "# Need to update BQ schema to latest\n",
    "\n",
    "df['REGION']='Local'\n",
    "df['FREE_FIELD']=''\n",
    "df['FREE_FIELD2']=''\n",
    "df['FREE_FIELD3']=''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b9fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove control characters re.sub(r'[\\x00-\\x1F\\x7F]', ' ', value)\n",
    "\n",
    "def control_char(string):\n",
    "    \n",
    "    string=re.sub(r'[\\x00-\\x1F\\x7F]', ' ', string)\n",
    "    \n",
    "    return string\n",
    "    \n",
    "\n",
    "df['NAME'] = df['NAME'].apply(control_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d13ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>QUALIFICATION</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>WIND</th>\n",
       "      <th>...</th>\n",
       "      <th>DOB</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>CATEGORY_EVENT</th>\n",
       "      <th>ATHLETE_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FREE_FIELD</th>\n",
       "      <th>FREE_FIELD2</th>\n",
       "      <th>FREE_FIELD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>719</td>\n",
       "      <td>WONG CHOONG YIN</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Throw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>337</td>\n",
       "      <td>ONG YI JUN RAYMUS</td>\n",
       "      <td>HCI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Throw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>499</td>\n",
       "      <td>LEAM TEO JIN TZE</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Throw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>695</td>\n",
       "      <td>LEROY ANDRE CHNG CHONG KAI</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Throw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>585</td>\n",
       "      <td>KEANE WONG JEN QUIN</td>\n",
       "      <td>SJI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Throw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>HAYDEN TAN LI ERN</td>\n",
       "      <td>ACJC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hurdles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>24</td>\n",
       "      <td>431</td>\n",
       "      <td>NG LIN YEE CAYLYNE</td>\n",
       "      <td>PLMGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>16</td>\n",
       "      <td>250</td>\n",
       "      <td>NUR HAERYL IHSAN BIN CHAIRILYANY</td>\n",
       "      <td>JSS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Long</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>BUKIT VIEW SECONDARY SCHOOL</td>\n",
       "      <td>BIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF3</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>BUKIT VIEW SECONDARY SCHOOL</td>\n",
       "      <td>BIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDF</td>\n",
       "      <td>DNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4523 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RANK  TAG_ID                              NAME   TEAM  SEED   RESULT  \\\n",
       "0       1     719                   WONG CHOONG YIN     VS   NaN    38.77   \n",
       "1       2     337                 ONG YI JUN RAYMUS    HCI   NaN    37.56   \n",
       "2       3     499                  LEAM TEO JIN TZE     RI   NaN    36.92   \n",
       "3       4     695        LEROY ANDRE CHNG CHONG KAI     VS   NaN    35.21   \n",
       "4       5     585               KEANE WONG JEN QUIN    SJI   NaN    34.78   \n",
       "...   ...     ...                               ...    ...   ...      ...   \n",
       "4518    8      15                 HAYDEN TAN LI ERN   ACJC   NaN      DNS   \n",
       "4519   24     431                NG LIN YEE CAYLYNE  PLMGS   NaN      DNS   \n",
       "4520   16     250  NUR HAERYL IHSAN BIN CHAIRILYANY    JSS   NaN  12:16.0   \n",
       "4521   23      41       BUKIT VIEW SECONDARY SCHOOL    BIV   NaN       DQ   \n",
       "4522   22      94       BUKIT VIEW SECONDARY SCHOOL    BIV   NaN      DNS   \n",
       "\n",
       "     QUALIFICATION    HEAT  LANE  WIND  ... DOB GROUP CATEGORY_EVENT  \\\n",
       "0              NaN  Finals     5   NaN  ... NaN   NaN          Throw   \n",
       "1              NaN  Finals     4   NaN  ... NaN   NaN          Throw   \n",
       "2              NaN  Finals    14   NaN  ... NaN   NaN          Throw   \n",
       "3              NaN  Finals    12   NaN  ... NaN   NaN          Throw   \n",
       "4              NaN  Finals    11   NaN  ... NaN   NaN          Throw   \n",
       "...            ...     ...   ...   ...  ...  ..   ...            ...   \n",
       "4518           NaN  Finals     3  -0.1  ... NaN   NaN        Hurdles   \n",
       "4519           NaN     SF3     7   1.2  ... NaN   NaN         Sprint   \n",
       "4520           NaN  Finals    16   NaN  ... NaN   NaN           Long   \n",
       "4521           NaN     SF3     7   NaN  ... NaN   NaN          Relay   \n",
       "4522           NaN      h1     6   NaN  ... NaN   NaN          Relay   \n",
       "\n",
       "      ATHLETE_ID  SOURCE REMARKS  TIMESTAMP  FREE_FIELD  FREE_FIELD2  \\\n",
       "0            NaN     PDF     NaN        NaN                            \n",
       "1            NaN     PDF     NaN        NaN                            \n",
       "2            NaN     PDF     NaN        NaN                            \n",
       "3            NaN     PDF     NaN        NaN                            \n",
       "4            NaN     PDF     NaN        NaN                            \n",
       "...          ...     ...     ...        ...         ...          ...   \n",
       "4518         NaN     PDF     NaN        NaN                            \n",
       "4519         NaN     PDF     DNS        NaN                            \n",
       "4520         NaN     PDF     NaN        NaN                            \n",
       "4521         NaN     PDF     NaN        NaN                            \n",
       "4522         NaN     PDF     DNS        NaN                            \n",
       "\n",
       "      FREE_FIELD3  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "...           ...  \n",
       "4518               \n",
       "4519               \n",
       "4520               \n",
       "4521               \n",
       "4522               \n",
       "\n",
       "[4523 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2bd49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.reindex(columns= ['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION', 'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', \n",
    "#                            'POINTS', 'AGE', 'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'DATE', 'COMPETITION', 'REGION', 'DOB','GROUP', 'CATEGORY_EVENT', \n",
    "#                            'ATHLETE_ID', 'SOURCE', 'REMARKS', 'TIMESTAMP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d38a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise descriptions to be consistent with database\n",
    "\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Hurdles', value='hurdles')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Walk', value='walk')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'SC', value='steeplechase')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Jump', value='jump')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Relay', value='relay')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Vault', value='vault')\n",
    "df['EVENT'] = df['EVENT'].replace(regex=r'Put', value='put')\n",
    "df['DIVISION'] = df['DIVISION'].replace(regex=r'_DIVISION', value='')\n",
    "\n",
    "mask = df['EVENT'].str.contains(r'walk', na=True)\n",
    "df.loc[mask, 'CATEGORY_EVENT'] = 'Walk'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99ad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'YEAR': 'DATE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6110d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NSG_2022_processed.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10996e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
