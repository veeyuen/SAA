{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import tkinter\n",
    "import glob\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import camelot\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841.91998\n",
      "594.95996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'60_LEE_XIN_YU_ERLYNA_526_US_h1_6_073595'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the PDF file\n",
    "pdf_path = \"C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Session_1.pdf\"\n",
    " \n",
    "# Output directory for CSV files\n",
    "output_dir = \"C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Tables\"\n",
    "image_dir = \"C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Images\"\n",
    "\n",
    "r_directory = \"C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022\"\n",
    "\n",
    "#Clear the files in a folder\n",
    "[os.remove(file) for file in glob.glob(os.path.join(image_dir, '*')) if os.path.isfile(file)]\n",
    "\n",
    "\n",
    "PDF = pdfplumber.open(pdf_path)\n",
    "# Go the page\n",
    "first_page = PDF.pages[4]\n",
    "print(first_page.height)\n",
    "print(first_page.width)\n",
    "\n",
    "# def get_event_session(page):\n",
    "        \n",
    "# Get the Event and the stage\n",
    "crop_box_date = (0, 0.03*first_page.height, 0.75*first_page.width, 0.06*first_page.height) #Left, Top, Right, Bottom -> Crop to the event details\n",
    "\n",
    "imEvent = first_page.crop(crop_box_date)\n",
    "\n",
    "words = imEvent.extract_words()\n",
    "\n",
    "# Extract the 'text' values from the extracted words and join them with '_'\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "text_string = '_'.join(word['text'].translate(translator) for word in words)\n",
    "\n",
    "\n",
    "#     # # print(first_page.extract_table(table_settings={\"horizontal_strategy\": \"text\"}))\n",
    "imEvent = imEvent.to_image(resolution=150)\n",
    "\n",
    "# # Draw rectangles around the words\n",
    "imEvent.draw_rects(words)\n",
    "\n",
    "# Show the image\n",
    "imEvent.show()\n",
    "\n",
    "text_string\n",
    "    # return text_string\n",
    "\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_session(page):\n",
    "        \n",
    "    # Get the Event and the stage\n",
    "    crop_box_date = (0, 0.03*page.height, 0.75*page.width, 0.06*page.height) #Left, Top, Right, Bottom -> Crop to the event details\n",
    "\n",
    "    imEvent = page.crop(crop_box_date)\n",
    "\n",
    "    words = imEvent.extract_words()\n",
    "\n",
    "    # Extract the 'text' values from the extracted words and join them with '_'\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_string = '_'.join(word['text'].translate(translator) for word in words)\n",
    "\n",
    "\n",
    "    # #     # # print(first_page.extract_table(table_settings={\"horizontal_strategy\": \"text\"}))\n",
    "    # imEvent = imEvent.to_image(resolution=150)\n",
    "\n",
    "    # # # Draw rectangles around the words\n",
    "    # imEvent.draw_rects(words)\n",
    "\n",
    "    # # Show the image\n",
    "    # imEvent.show()\n",
    "\n",
    "# text_string\n",
    "    return text_string\n",
    "\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(page):\n",
    "\n",
    "    # Get the Event and the stage\n",
    "    crop_box_date = (0.6*page.width, 0.01*page.height, 0.95*page.width, 0.04*page.height) #Left, Bottom, Right, Top -> Crop to the event details\n",
    "\n",
    "    imEvent = page.crop(crop_box_date)\n",
    "\n",
    "    words = imEvent.extract_words()\n",
    "\n",
    "    # Extract the 'text' values from the extracted words and join them with '_'\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_string = '_'.join(word['text'].translate(translator) for word in words)\n",
    "\n",
    "\n",
    "    # # text_string\n",
    "    # #     # # print(first_page.extract_table(table_settings={\"horizontal_strategy\": \"text\"}))\n",
    "    # imEvent = imEvent.to_image(resolution=150)\n",
    "\n",
    "    # # # Draw rectangles around the words\n",
    "    # imEvent.draw_rects(words)\n",
    "\n",
    "    # # Show the image\n",
    "    # imEvent.show()\n",
    "\n",
    "# text_string\n",
    "\n",
    "    if 'Published' in text_string:\n",
    "        return text_string\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number: 1 done.\n",
      "Image of 1 saved as image_1.png\n",
      "\n",
      "Page number: 2 done.\n",
      "Image of 2 saved as image_2.png\n",
      "\n",
      "Page number: 3 done.\n",
      "Image of 3 saved as image_3.png\n",
      "\n",
      "Page number: 4 done.\n",
      "Image of 4 saved as image_4.png\n",
      "\n",
      "Page number: 5 done.\n",
      "Image of 5 saved as image_5.png\n",
      "\n",
      "Page number: 6 done.\n",
      "Image of 6 saved as image_6.png\n",
      "\n",
      "Page number: 7 done.\n",
      "Image of 7 saved as image_7.png\n",
      "\n",
      "Page number: 8 done.\n",
      "Image of 8 saved as image_8.png\n",
      "\n",
      "Page number: 9 done.\n",
      "Image of 9 saved as image_9.png\n",
      "\n",
      "Page number: 10 done.\n",
      "Image of 10 saved as image_10.png\n",
      "\n",
      "Page number: 11 done.\n",
      "Image of 11 saved as image_11.png\n",
      "\n",
      "Page number: 12 done.\n",
      "Image of 12 saved as image_12.png\n",
      "\n",
      "Page number: 13 done.\n",
      "Image of 13 saved as image_13.png\n",
      "\n",
      "Page number: 14 done.\n",
      "Image of 14 saved as image_14.png\n",
      "\n",
      "Page number: 15 done.\n",
      "Image of 15 saved as image_15.png\n",
      "\n",
      "Page number: 16 done.\n",
      "Image of 16 saved as image_16.png\n",
      "\n",
      "Page number: 17 done.\n",
      "Image of 17 saved as image_17.png\n",
      "\n",
      "Page number: 18 done.\n",
      "Image of 18 saved as image_18.png\n",
      "\n",
      "Page number: 19 done.\n",
      "Image of 19 saved as image_19.png\n",
      "\n",
      "Page number: 20 done.\n",
      "Image of 20 saved as image_20.png\n",
      "\n",
      "Page number: 21 done.\n",
      "Image of 21 saved as image_21.png\n",
      "\n",
      "Page number: 22 done.\n",
      "Image of 22 saved as image_22.png\n",
      "\n",
      "Page number: 23 done.\n",
      "Image of 23 saved as image_23.png\n",
      "\n",
      "Page number: 24 done.\n",
      "Image of 24 saved as image_24.png\n",
      "\n",
      "Page number: 25 done.\n",
      "Image of 25 saved as image_25.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def extract_tables(pdf_path):\n",
    "    # Create a list to store tables\n",
    "    tables = []\n",
    "\n",
    "    # Open the PDF with pdfplumber to extract text\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            print(f\"Page number: {page_num} done.\")\n",
    "\n",
    "            # Extract tables on the current page\n",
    "            page_tables = camelot.read_pdf(pdf_path, pages=str(page_num))\n",
    "\n",
    "            for table in page_tables:\n",
    "                # Append the table to the list\n",
    "                tables.append(table.df)\n",
    "\n",
    "            page_image = page.to_image(resolution=300)\n",
    "            page_image.save(f\"{image_dir}/image_{page_num}.png\")\n",
    "            print(f\"Image of {page_num} saved as image_{page_num}.png\\n\")\n",
    "\n",
    "    return tables\n",
    "\n",
    "def save_tables_to_excel(tables, output_excel_path):\n",
    "    # Create an Excel writer object\n",
    "    writer = pd.ExcelWriter(output_excel_path, engine='xlsxwriter')\n",
    "\n",
    "    # Iterate over the tables and save each to a different sheet\n",
    "    for i, table in enumerate(tables):\n",
    "        sheet_name = f'Table {i+1}'\n",
    "        table.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Save the Excel file\n",
    "    writer.save()\n",
    "\n",
    "tables = extract_tables(pdf_path)\n",
    "\n",
    "# Save the extracted tables to an Excel file\n",
    "save_tables_to_excel(tables, output_dir + \"/session1-1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_sheets(input_excel, output_excel):\n",
    "    # Load the workbook\n",
    "    wb = openpyxl.load_workbook(input_excel)\n",
    "    \n",
    "    # Create a new workbook to store the combined data\n",
    "    combined_wb = openpyxl.Workbook()\n",
    "    combined_sheet = combined_wb.active\n",
    "    combined_sheet.title = 'Combined'\n",
    "    \n",
    "    # Iterate through all sheets in the workbook\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        \n",
    "        # Iterate through all rows in the current sheet\n",
    "        for row in ws.iter_rows(values_only=True):\n",
    "            combined_sheet.append(row)\n",
    "    \n",
    "    # Save the combined workbook\n",
    "    combined_wb.save(output_excel)\n",
    "\n",
    "# Example usage\n",
    "input_excel = r_directory+\"/Tables/session1-1.xlsx\"\n",
    "output_excel = r_directory+'/Tables/session1-2.xlsx'\n",
    "combine_all_sheets(input_excel, output_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Event_S0101_Discus_B_DIVISION_BOYS_Finals': 'Published_Date_06042022_105248',\n",
       " 'Audited_List_Published_Date_0': 'Published_Date_06042022_105248',\n",
       " 'Event_S0102_Long_Jump__A_DIVISION_GIRLS_Finals': 'Published_Date_06042022_133020',\n",
       " 'Event_S0103_1500m__B_DIVISION_GIRLS_Heats': 'Published_Date_12042022_144015',\n",
       " '28_XAVIER_VETHAMUTHU_LAURA_303_JSS_h5_2_062601': None,\n",
       " '60_LEE_XIN_YU_ERLYNA_526_US_h1_6_073595': None,\n",
       " 'Event_S0104_1500m__B_DIVISION_BOYS_Heats': 'Published_Date_06042022_124822',\n",
       " '26_PHOON_YU_CHEN_292_GYS_h1_11_050065': None,\n",
       " '56_MUHAMMAD_ALIF_SYAHMI_BIN_371_JSS_h2_10_054135_MUHAMMAD_SHAIFULAH': None,\n",
       " 'BIN_ABDUL_RAHIM_87_LIM_CHEN_KAI_726_WDL_h3_10_065548': None,\n",
       " 'Event_S0105_100m__C_DIVISION_GIRLS_Heats': 'Published_Date_06042022_130413',\n",
       " '26_GWENDOLYN_CHAN_YU_HUI_288_NJC_h8_2_001504': None,\n",
       " '57_AARSHIYA_JAIN_318_NUSHS_h2_8_001662': None,\n",
       " '86_YEE_CHEN_XIN_193_CRS_h1_6_001866': None,\n",
       " 'Event_S0106_100m__C_DIVISION_BOYS_Heats': 'Published_Date_06042022_175048',\n",
       " '27_NG_KHAI_JUN_RHYS_501_VS_h8_2_001323': None,\n",
       " '59_RYAN_HAZIQUE_BIN_ALIF_HAIQAL_23_AIS_h9_2_001429': None,\n",
       " '88_MUHAMAD_IRSYAD_BIN_JUNAIDI_527_WDL_h12_4_001683': None,\n",
       " 'Event_S0107_100m__B_DIVISION_GIRLS_Heats': 'Published_Date_06042022_145116',\n",
       " '26_OOI_YIWEI_258_DHS_h7_5_001442': None,\n",
       " '58_MELODY_KOO_WAI_YEAN_123_KC_h5_2_001565': None,\n",
       " '87_SAPPHIRE_LEE_JIA_YING_289_HY_h5_4_001771': None,\n",
       " 'Event_S0108_100m__B_DIVISION_BOYS_Heats': 'Published_Date_06042022_151859',\n",
       " '27_NG_JUN_YI_703_VS_h6_1_001227': None,\n",
       " '57_WAYNE_GOH_RUI_XI_672_US_h10_1_001301': None,\n",
       " '87_NAING_PHONE_HTUT_542_SST_h9_1_001389': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_stuff = {'Event_S0101_Discus_B_DIVISION_BOYS_Finals': 'Published_Date_06042022_105248'}\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Iterate through each page\n",
    "    for i, page in enumerate(pdf.pages, start=0):\n",
    "        session = get_event_session(page)\n",
    "        date = get_date(page)\n",
    "\n",
    "        add_stuff[session] = date\n",
    "\n",
    "add_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Event_S0101_Discus_B_DIVISION_BOYS_Finals': 'Published_Date_06042022_105248',\n",
       " 'Event_S0102_Long_Jump__A_DIVISION_GIRLS_Finals': 'Published_Date_06042022_133020',\n",
       " 'Event_S0103_1500m__B_DIVISION_GIRLS_Heats': 'Published_Date_12042022_144015',\n",
       " 'Event_S0104_1500m__B_DIVISION_BOYS_Heats': 'Published_Date_06042022_124822',\n",
       " 'Event_S0105_100m__C_DIVISION_GIRLS_Heats': 'Published_Date_06042022_130413',\n",
       " 'Event_S0106_100m__C_DIVISION_BOYS_Heats': 'Published_Date_06042022_175048',\n",
       " 'Event_S0107_100m__B_DIVISION_GIRLS_Heats': 'Published_Date_06042022_145116',\n",
       " 'Event_S0108_100m__B_DIVISION_BOYS_Heats': 'Published_Date_06042022_151859'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_stuff_filtered = {k: v for k, v in add_stuff.items() if k is not None and 'Event' in k}\n",
    "\n",
    "# add_stuff_filtered.pop('Event_S1319_3000m__B_DIVISION_BOYS_Finals')\n",
    "\n",
    "add_stuff_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_excel(r_directory + \"/Tables/session1-2.xlsx\")\n",
    "\n",
    "# Initialize lists for event and date\n",
    "event = []\n",
    "date = []\n",
    "counter = 0\n",
    "\n",
    "# Convert keys and values of the dictionary to lists\n",
    "keys_list = list(add_stuff_filtered.keys())\n",
    "values_list = list(add_stuff_filtered.values())\n",
    "\n",
    "# Iterate over DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    if row['POS'] == 'POS':\n",
    "        counter += 1  # Corrected increment\n",
    "    \n",
    "    # Append the appropriate event and date to the lists\n",
    "    event.append(keys_list[counter])\n",
    "    date.append(values_list[counter])\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['Date'] = date\n",
    "df['Session and Event'] = event\n",
    "\n",
    "# Print or return the DataFrame\n",
    "df.to_excel(r_directory+\"/Tables/session1-3.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Session   Event    Division     Session Date\n",
      "0     S0101  Discus  B_DIVISION  06042022_105248\n",
      "1     S0101  Discus  B_DIVISION  06042022_105248\n",
      "2     S0101  Discus  B_DIVISION  06042022_105248\n",
      "3     S0101  Discus  B_DIVISION  06042022_105248\n",
      "4     S0101  Discus  B_DIVISION  06042022_105248\n",
      "..      ...     ...         ...              ...\n",
      "596   S0108    100m  B_DIVISION  06042022_151859\n",
      "597   S0108    100m  B_DIVISION  06042022_151859\n",
      "598   S0108    100m  B_DIVISION  06042022_151859\n",
      "599   S0108    100m  B_DIVISION  06042022_151859\n",
      "600   S0108    100m  B_DIVISION  06042022_151859\n",
      "\n",
      "[601 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r_directory+\"/Tables/session1-3.xlsx\")\n",
    "\n",
    "\n",
    "# Split the 'Session and Event' column by '_' and create a new 'Session' column with the first part\n",
    "df['Session'] = df['Session and Event'].str.split('_').str[1]\n",
    "df['Event'] = df['Session and Event'].str.split('_').apply(lambda x: '_'.join([item for item in x[2:-4] if item]))\n",
    "df['Division'] = df['Session and Event'].str.split('_').apply(lambda x: '_'.join([item for item in x[-4:-2] if item]))\n",
    "df['Session Date'] = df['Date'].str.split('_').apply(lambda x: '_'.join([item for item in x[2:4] if item]))\n",
    "\n",
    "# Display the 'Session' column to verify the result\n",
    "print(df[['Session', 'Event', 'Division', 'Session Date']])\n",
    "\n",
    "df.to_excel(r_directory+\"/Tables/session1-4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame({})\n",
    "\n",
    "\n",
    "for file in glob.glob(os.path.join(r_directory+\"/Done\", '*')):\n",
    "    df = pd.read_excel(file)\n",
    "    frames = [df, total_df]\n",
    "\n",
    "    total_df = pd.concat(frames)\n",
    "\n",
    "total_df.to_excel(r_directory+\"/Done/Combined.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:108: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['NAME'] = df['Competitor'].str.replace(r\"[\\\"\\'\\]\\[,]\", '')\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:109: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['TEAM'] = df['Team'].str.replace(r\"[\\\"\\',]\", '')  # Assuming 'Team' column has country codes\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:110: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['RESULT'] = df['Result'].str.replace(r\"[\\\"\\'\\]\\[,]\", '')\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:114: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['EVENT'] = df['Event'].str.replace(r\"[\\\"\\'\\_,]\", ' ')\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:116: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['DIVISION'] = df['Division'].str.replace(r\"[\\\"\\',]\", '')  # Assuming this is the relevant date\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:123: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['CATEGORY_EVENT'] = df['Event'].str.replace(r\"\\_\", ' ').apply(map_event_to_category)\n",
      "C:\\Users\\Singapore Athletic\\AppData\\Local\\Temp\\ipykernel_17700\\3858963992.py:125: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df['SUB_EVENT'] = df['Event'].str.replace(r\"\\_\", ' ').apply(get_events)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>TAG_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>QUALIFICATION</th>\n",
       "      <th>HEAT</th>\n",
       "      <th>LANE</th>\n",
       "      <th>WIND</th>\n",
       "      <th>...</th>\n",
       "      <th>ATHLETE_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>REMARKS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>VENUE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SUB_EVENT</th>\n",
       "      <th>SESSION</th>\n",
       "      <th>EVENT_CLASS</th>\n",
       "      <th>Remarks_Corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>BOBBI VICTORIA YANG YEN\\n(WENG XUAN)</td>\n",
       "      <td>HIJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0401</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>201</td>\n",
       "      <td>ANGELA TAN SHI JIN</td>\n",
       "      <td>DHS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0401</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>121</td>\n",
       "      <td>ALLYSON CHOO JIA YI</td>\n",
       "      <td>SNG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0401</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>263</td>\n",
       "      <td>AMANDA CHUA JIA YING (CAI\\nJIAYING)</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0401</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>267</td>\n",
       "      <td>FAITH WONG YU JIA</td>\n",
       "      <td>NYGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0401</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.0</td>\n",
       "      <td>150</td>\n",
       "      <td>CHIA FENG ZHOU</td>\n",
       "      <td>CH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:19:09.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6.0</td>\n",
       "      <td>179</td>\n",
       "      <td>QUEK ZI YANG DAMIAN</td>\n",
       "      <td>CH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:19:15.890000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>7.0</td>\n",
       "      <td>694</td>\n",
       "      <td>KRISHAN THILAK</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:22:12.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>8.0</td>\n",
       "      <td>165</td>\n",
       "      <td>LIM KIAT YU RHAINES</td>\n",
       "      <td>CH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:23:01.780000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>9.0</td>\n",
       "      <td>707</td>\n",
       "      <td>RAIYN AYDIN BIN HARRIS\\nMULYADI</td>\n",
       "      <td>VS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:23:03.330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finals</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nsg.moe.edu.sg/sssc/archives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown Event</td>\n",
       "      <td>S0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RANK  TAG_ID                                  NAME  TEAM SEED  \\\n",
       "0     1.0     100  BOBBI VICTORIA YANG YEN\\n(WENG XUAN)   HIJ  NaN   \n",
       "1     2.0     201                    ANGELA TAN SHI JIN   DHS  NaN   \n",
       "2     3.0     121                   ALLYSON CHOO JIA YI   SNG  NaN   \n",
       "3     4.0     263   AMANDA CHUA JIA YING (CAI\\nJIAYING)  NYGH  NaN   \n",
       "4     4.0     267                     FAITH WONG YU JIA  NYGH  NaN   \n",
       "..    ...     ...                                   ...   ...  ...   \n",
       "117   5.0     150                        CHIA FENG ZHOU    CH  NaN   \n",
       "118   6.0     179                   QUEK ZI YANG DAMIAN    CH  NaN   \n",
       "119   7.0     694                        KRISHAN THILAK    VS  NaN   \n",
       "120   8.0     165                   LIM KIAT YU RHAINES    CH  NaN   \n",
       "121   9.0     707       RAIYN AYDIN BIN HARRIS\\nMULYADI    VS  NaN   \n",
       "\n",
       "              RESULT QUALIFICATION    HEAT  LANE  WIND  ... ATHLETE_ID  \\\n",
       "0                NaN           NaN  Finals     5   NaN  ...        NaN   \n",
       "1                NaN           NaN  Finals    12   NaN  ...        NaN   \n",
       "2                NaN           NaN  Finals    16   NaN  ...        NaN   \n",
       "3                NaN           NaN  Finals     6   NaN  ...        NaN   \n",
       "4                NaN           NaN  Finals     3   NaN  ...        NaN   \n",
       "..               ...           ...     ...   ...   ...  ...        ...   \n",
       "117  00:19:09.300000           NaN  Finals     2   NaN  ...        NaN   \n",
       "118  00:19:15.890000           NaN  Finals     4   NaN  ...        NaN   \n",
       "119  00:22:12.200000           NaN  Finals     8   NaN  ...        NaN   \n",
       "120  00:23:01.780000           NaN  Finals     3   NaN  ...        NaN   \n",
       "121  00:23:03.330000           NaN  Finals     9   NaN  ...        NaN   \n",
       "\n",
       "                                   SOURCE REMARKS  TIMESTAMP VENUE DATE  \\\n",
       "0    https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "1    https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "2    https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "3    https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "4    https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "..                                    ...     ...        ...   ...  ...   \n",
       "117  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "118  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "119  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "120  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "121  https://nsg.moe.edu.sg/sssc/archives     NaN        NaN   NaN  NaN   \n",
       "\n",
       "         SUB_EVENT SESSION EVENT_CLASS Remarks_Corrected  \n",
       "0    Unknown Event   S0401         NaN                    \n",
       "1    Unknown Event   S0401         NaN                    \n",
       "2    Unknown Event   S0401         NaN                    \n",
       "3    Unknown Event   S0401         NaN                    \n",
       "4    Unknown Event   S0401         NaN                    \n",
       "..             ...     ...         ...               ...  \n",
       "117  Unknown Event   S0409         NaN                    \n",
       "118  Unknown Event   S0409         NaN                    \n",
       "119  Unknown Event   S0409         NaN                    \n",
       "120  Unknown Event   S0409         NaN                    \n",
       "121  Unknown Event   S0409         NaN                    \n",
       "\n",
       "[122 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_stage(check):\n",
    "    if 'final' in check.lower():\n",
    "        return \"Finals\"\n",
    "    elif 'sf' in check.lower():\n",
    "        return \"Semi-Finals\"\n",
    "    else:\n",
    "        return \"Heats\"\n",
    "\n",
    "def get_events(event_code):\n",
    "    event_mapping = {\n",
    "        'Discus': 'Discus',\n",
    "        'Long_Jump': 'Long jump',\n",
    "        '1500m': '1500m',\n",
    "        '100m': '100m',\n",
    "        '200m': '200m',\n",
    "        'Javelin': 'Javelin',\n",
    "        '400m_Hurdles': '400m hurdles',\n",
    "        '800m': '800m',\n",
    "        '5000m_Walk': '5000m walk',\n",
    "        '3000m': '3000m',\n",
    "        '4_X_100m_Relay': '4 X 100m relay',\n",
    "        'Shot_Put': 'Shot put',\n",
    "        '400m': '400m',\n",
    "        '5000m': '5000m',\n",
    "        'High_Jump': 'High jump',\n",
    "        '2000m_SC': '2000m steeplechase',\n",
    "        '3000m_SC': '3000m steeplechase',\n",
    "        'Triple_Jump': 'Triple jump',\n",
    "        '1500m_Walk': '1500m walk',\n",
    "        '200m_Hurdles': '200m hurdles',\n",
    "        'Pole_Vault': 'Pole vault',\n",
    "        '4_X_400m_Relay': '4 X 400m relay',\n",
    "        '110m_Hurdles': '110m hurdles',\n",
    "        '100m_Hurdles': '100m hurdles',\n",
    "        '80m_Hurdles': '80m hurdles'\n",
    "    }\n",
    "    \n",
    "    return event_mapping.get(event_code, 'Unknown Event')\n",
    "\n",
    "def get_gender(gender):\n",
    "    if \"GIRLS\" in gender.upper():\n",
    "        return 'Women'\n",
    "    else:\n",
    "        return \"Men\"\n",
    "\n",
    "def map_event_to_category(event_code):\n",
    "    category_mapping = {\n",
    "        '100m': 'Sprint',\n",
    "        '200m': 'Sprint',\n",
    "        '400m': 'Sprint',\n",
    "        '800m': 'Mid',\n",
    "        '1500m': 'Mid',\n",
    "        '5000m': 'Long',\n",
    "        '100m Hurdles': 'Hurdles',\n",
    "        '110m Hurdles': 'Hurdles',\n",
    "        '80m Hurdles': 'Hurdles',\n",
    "        '200m Hurdles': 'Hurdles',\n",
    "        '400m Hurdles': 'Hurdles',\n",
    "        '1500m Walk': 'Walk',\n",
    "        '5000m Walk': 'Walk',\n",
    "        '2000m SC': 'Steeple',\n",
    "        '3000m SC': 'Steeple',\n",
    "        '4x100m Relay': 'Relay',\n",
    "        '4x400m Relay': 'Relay',\n",
    "        'High Jump': 'Jump',\n",
    "        'Pole Vault': 'Jump',\n",
    "        'Long Jump': 'Jump',\n",
    "        'Triple Jump': 'Jump',\n",
    "        'Shot Put': 'Throw',\n",
    "        'Discus': 'Throw',\n",
    "        'Hammer Throw': 'Throw',\n",
    "        'Javelin Throw': 'Throw',\n",
    "        'Heptathlon': 'Heptathlon',\n",
    "        'Decathlon': 'Decathlon'\n",
    "    }\n",
    "    return category_mapping.get(event_code, 'Unknown Category')\n",
    "\n",
    "# Define the new schema\n",
    "seag_23_headers = ['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION',\n",
    "       'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', 'POINTS', 'AGE',\n",
    "       'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'YEAR', 'COMPETITION',\n",
    "       'REGION', 'DOB', 'GROUP', 'CATEGORY_EVENT', 'ATHLETE_ID', 'SOURCE',\n",
    "       'REMARKS', 'TIMESTAMP', 'VENUE', 'DATE', 'SUB_EVENT', 'SESSION',\n",
    "       'EVENT_CLASS']\n",
    "\n",
    "# Load the data from the existing Excel file\n",
    "df = pd.read_excel(\"C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Tables/session4_test_4_v2.xlsx\")\n",
    "\n",
    "# Create a new DataFrame with the new schema\n",
    "new_df = pd.DataFrame(columns=seag_23_headers)\n",
    "# ['', '', '', '', 'SEED', '', '',\n",
    "#        '', '', '', '', '', '', '', 'AGE',\n",
    "#        '', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', '', '',\n",
    "#        '', 'DOB', 'GROUP', '', 'ATHLETE_ID', '',\n",
    "#        '', 'TIMESTAMP', 'VENUE', 'DATE', '', '',\n",
    "#        'EVENT_CLASS']\n",
    "\n",
    "# 'Unnamed: 0', 'POS', 'Competitor', 'Q', 'Tag', 'Team', 'Heat', 'Ln',\n",
    "#        'Result', 'Pts', 'W/G', 'Remarks', 'NR', 'Date', 'Session and Event',\n",
    "#        'Session', 'Event', 'Division', 'Session Date\n",
    "# Map the existing columns to the new schema\n",
    "new_df['RANK'] = df['POS']\n",
    "new_df['QUALIFICATION'] = df['Q']\n",
    "new_df['POINTS'] = df['Pts']\n",
    "new_df['TAG_ID'] = df['Tag']  # Add empty values for 'Tag'\n",
    "new_df['NAME'] = df['Competitor'].str.replace(r\"[\\\"\\'\\]\\[,]\", '')\n",
    "new_df['TEAM'] = df['Team'].str.replace(r\"[\\\"\\',]\", '')  # Assuming 'Team' column has country codes\n",
    "new_df['RESULT'] = df['Result'].str.replace(r\"[\\\"\\'\\]\\[,]\", '')\n",
    "new_df['HEAT'] = df['Heat']  # Example of adding empty values\n",
    "new_df['LANE'] = df['Ln']  # Add empty values for 'Lane Number'\n",
    "new_df['REMARKS'] = df['Remarks']  # .str.replace(r\"[\\\"\\',]\", '')\n",
    "new_df['EVENT'] = df['Event'].str.replace(r\"[\\\"\\'\\_,]\", ' ')\n",
    "new_df['GENDER'] = df['Session and Event'].apply(get_gender)  # Assume gender column if exists or leave it blank\n",
    "new_df['DIVISION'] = df['Division'].str.replace(r\"[\\\"\\',]\", '')  # Assuming this is the relevant date\n",
    "new_df['STAGE'] = df['Heat'].apply(get_stage)\n",
    "new_df['YEAR'] = \"2022\"  # Assume year if available or leave it blank\n",
    "new_df['COMPETITION'] = \"National School Games\"\n",
    "new_df['REGION'] = ''  # Add empty values for 'Region'\n",
    "new_df['WIND'] = df['W/G']\n",
    "new_df['SOURCE'] = \"https://nsg.moe.edu.sg/sssc/archives\"\n",
    "new_df['CATEGORY_EVENT'] = df['Event'].str.replace(r\"\\_\", ' ').apply(map_event_to_category)\n",
    "new_df['Remarks_Corrected'] = ''\n",
    "new_df['SUB_EVENT'] = df['Event'].str.replace(r\"\\_\", ' ').apply(get_events)\n",
    "new_df['SESSION'] = df['Session']  # Add empty values for 'Session'\n",
    "\n",
    "# Display the new DataFrame\n",
    "display(new_df)\n",
    "\n",
    "# Save the new DataFrame to an Excel file\n",
    "new_df.to_excel(r_directory+\"/Tables/session1-5.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFullSchema = pd.read_csv(r_directory+\"/Collated/FULL_SCHEMA.csv\")\n",
    "\n",
    "# Load the data from the existing Excel file\n",
    "dfCombined = pd.read_excel(r_directory + \"/Done/Combined.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RANK', 'TAG_ID', 'NAME', 'TEAM', 'SEED', 'RESULT', 'QUALIFICATION',\n",
       "       'HEAT', 'LANE', 'WIND', 'EVENT', 'DIVISION', 'STAGE', 'POINTS', 'AGE',\n",
       "       'GENDER', 'UNIQUE_ID', 'COUNTRY', 'DICT_RESULTS', 'YEAR', 'COMPETITION',\n",
       "       'REGION', 'DOB', 'GROUP', 'CATEGORY_EVENT', 'ATHLETE_ID', 'SOURCE',\n",
       "       'REMARKS', 'TIMESTAMP', 'VENUE', 'DATE', 'SUB_EVENT', 'SESSION',\n",
       "       'EVENT_CLASS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFullSchema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfCombined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdfCombined\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfCombined' is not defined"
     ]
    }
   ],
   "source": [
    "dfCombined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFullSchema['QUALIFICATION'] = dfCombined['Q']\n",
    "dfFullSchema['POINTS'] = dfCombined['Pts']\n",
    "dfFullSchema['YEAR'] = 2022\n",
    "dfFullSchema['SESSION'] = dfCombined['Session']\n",
    "dfFullSchema['DATE'] = dfCombined['Session Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFullSchema.to_excel(r_directory+\"/Collated/Test1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Done/doneAgain/combined_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the Excel files\n",
    "directory = r'C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Done/doneAgain'\n",
    "\n",
    "# List to hold data from each Excel file\n",
    "all_data = []\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        # Append the data to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine all the data into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new Excel file\n",
    "output_file = r'C:/Users/Singapore Athletic/Desktop/SAA_DB_Construction/NSG/2022/Done/doneAgain/combined_data.xlsx'\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Combined data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'POS', 'Competitor', 'Q', 'Tag', 'Team', 'Heat', 'Ln',\n",
       "       'Result', 'Pts', 'W/G', 'Remarks', 'NR', 'Date', 'Session and Event',\n",
       "       'Session', 'Event', 'Division', 'Session Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(output_file)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(output_file)\n",
    "\n",
    "df['Result'] = df['Result'].fillna(df['Remarks'])\n",
    "\n",
    "df.to_excel(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r_directory+\"/Done/doneAgain/combined2.xlsx\")\n",
    "\n",
    "pd.DataFrame(df['SESSION'].value_counts()).to_csv(r_directory+\"/Done/doneAgain/checker1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"C:/Users/Singapore Athletic/Downloads/NSG_2022_processed.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove newline characters from the NAME column\n",
    "df['NAME'] = df['NAME'].str.replace('\\n', ' ', regex=False).str.upper()\n",
    "\n",
    "# Save the updated DataFrame back to Excel\n",
    "df.to_csv(\"C:/Users/Singapore Athletic/Downloads/NSG_2022_processed_v2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Function to replace invisible control characters with spaces\n",
    "def replace_control_chars(value):\n",
    "    if isinstance(value, str):\n",
    "        # Replace control characters (ASCII codes 0-31) with a space\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', ' ', value)\n",
    "    return value\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"C:/Users/Singapore Athletic/Downloads/NSG_2022_processed.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace blank cells with np.nan and control characters with spaces\n",
    "df = df.applymap(lambda x: replace_control_chars(x))\n",
    "\n",
    "# Replace any cells that are still empty (after control character replacement) with np.nan\n",
    "df.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Optionally, save the modified DataFrame back to a CSV file\n",
    "df.to_csv(\"C:/Users/Singapore Athletic/Downloads/NSG_2022_processed_v3.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
